{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6fc1e0b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "import os\n",
    "import pickle\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.gridspec import GridSpec\n",
    "import seaborn as sn\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# %matplotlib qt\n",
    "# warnings.filterwarnings(\"ignore\")  # supress warnings from matplotlib\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5c4eaa07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set variables\n",
    "global use_seed\n",
    "use_seed = False\n",
    "threshold = 5  # possible values are: 1, 2, 5, 10\n",
    "# set the number of epochs you want to train the network (default = 300)\n",
    "epochs = 300 # 400\n",
    "save_fig = False  # set True to save the plots\n",
    "\n",
    "global use_trainable_out\n",
    "use_trainable_out = False\n",
    "global use_trainable_tc\n",
    "use_trainable_tc = False\n",
    "global use_dropout\n",
    "use_dropout = False\n",
    "global batch_size\n",
    "batch_size = 128  # 512\n",
    "global lr\n",
    "lr = 0.0015\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c8c451f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create folder to safe plots later\n",
    "if save_fig:\n",
    "    path = '../plots'\n",
    "    isExist = os.path.exists(path)\n",
    "\n",
    "    if not isExist:\n",
    "        os.makedirs(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f6ff6b13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multiple GPUs detected but single GPU selected. Setting up the simulation on cuda:1\n"
     ]
    }
   ],
   "source": [
    "# check for available GPU and distribute work\n",
    "\n",
    "share_GPU = False # True if multiple GPUs are to be used to share memory\n",
    "gpu_sel = 1 # selected (single) GPU to be used if memory is not to be shared\n",
    "gpu_mem_frac = 0.6 # memory fraction limit\n",
    "\n",
    "global device\n",
    "if (torch.cuda.device_count()>=1) & (share_GPU):\n",
    "    gpu_av = [torch.cuda.is_available() for ii in range(torch.cuda.device_count())]\n",
    "    print(\"Detected {} GPUs. The load will be shared.\".format(torch.cuda.device_count()))\n",
    "    for gpu in range(len(gpu_av)):\n",
    "        if True in gpu_av:\n",
    "            if gpu_av[gpu_sel]:\n",
    "                device = torch.device(\"cuda:\"+str(gpu))\n",
    "                print(\"Selected GPUs: {}\" .format(\"cuda:\"+str(gpu)))\n",
    "            else:\n",
    "                device = torch.device(\"cuda:\"+str(gpu_av.index(True)))\n",
    "        else:\n",
    "            device = torch.device(\"cpu\")\n",
    "            print(\"No GPU detected. Running on CPU.\")\n",
    "elif (torch.cuda.device_count()>=1) & (not share_GPU):\n",
    "    print(\"Multiple GPUs detected but single GPU selected. Setting up the simulation on {}\".format(\"cuda:\"+str(gpu_sel)))\n",
    "    device = torch.device(\"cuda:\"+str(gpu_sel))\n",
    "    torch.cuda.set_per_process_memory_fraction(gpu_mem_frac, device=device) # decrese or comment out memory fraction if more is available (the smaller the better)\n",
    "else:\n",
    "    if torch.cuda.is_available():\n",
    "        print(\"Single GPU detected. Setting up the simulation there.\")\n",
    "        device = torch.device(\"cuda\")\n",
    "        # thr 1: None, thr 2: 0.8, thr 5: 0.5, thr 10: None\n",
    "        torch.cuda.set_per_process_memory_fraction(gpu_mem_frac, device=device) # decrese or comment out memory fraction if more is available (the smaller the better)\n",
    "    else:\n",
    "        device = torch.device(\"cpu\")\n",
    "        print(\"No GPU detected. Running on CPU.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a2291f6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use fixed seed for reproducible results\n",
    "if use_seed:\n",
    "    seed = 42 # \"Answer to the Ultimate Question of Life, the Universe, and Everything\"\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    print(\"Seed set to {}\".format(seed))\n",
    "\n",
    "    def seed_worker(worker_id):\n",
    "        worker_seed = torch.initial_seed() % 2**32\n",
    "        np.random.seed(worker_seed)\n",
    "        random.seed(worker_seed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "88a7d1c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "dtype = torch.float"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "03bcccc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "letters = ['Space', 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K',\n",
    "           'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "55106de7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_extract_events(params, file_name, ratios=[0.8, 0, 0.2], taxels=None, letter_written=letters):\n",
    "\n",
    "    if np.sum(ratios) != 1:\n",
    "        raise ValueError('Check the correct ratios are used: got sum > 1')\n",
    "    \n",
    "    # max_time = int(54*25) #ms\n",
    "    max_time = int(350*10) #ms\n",
    "    time_bin_size = int(params['time_bin_size']) # ms\n",
    "    global time\n",
    "    time = range(0,max_time,time_bin_size)\n",
    "    # Increase max_time to make sure no timestep is cut due to fractional amount of steps\n",
    "    global time_step\n",
    "    time_step = time_bin_size*0.001\n",
    "    data_steps = len(time)\n",
    "    \n",
    "    \"\"\"\n",
    "    infile = open(file_name, 'rb')\n",
    "    data_dict = pickle.load(infile)\n",
    "    infile.close()\n",
    "    # Extract data\n",
    "    data = []\n",
    "    labels = []\n",
    "    bins = 1000  # [ms] \n",
    "    nchan = len(data_dict[1]['events']) # number of channels/sensors\n",
    "    \"\"\"\n",
    "    dataset = pd.read_pickle(file_name)\n",
    "    data_dict = dataset.copy()\n",
    "    data = []\n",
    "    labels = []\n",
    "    bins = 1000  # [ms] \n",
    "    nchan = len(data_dict['events'][1]) # number of channels/sensors\n",
    "    for i, sample in enumerate(data_dict['events']):\n",
    "        dat = (sample[:])\n",
    "        events_array = np.zeros([nchan,round((max_time/time_bin_size)+0.5),2])\n",
    "        for taxel in range(len(dat)):\n",
    "            for event_type in range(len(dat[taxel])):\n",
    "                if dat[taxel][event_type]:\n",
    "                    indx = bins*(np.array(dat[taxel][event_type]))\n",
    "                    indx = np.array((indx/time_bin_size).round(), dtype=int)\n",
    "                    events_array[taxel,indx,event_type] = 1\n",
    "        if taxels != None:\n",
    "            events_array = np.reshape(np.transpose(events_array, (1,0,2))[:,taxels,:],(events_array.shape[1],-1))\n",
    "            selected_chans = 2*len(taxels)\n",
    "        else:\n",
    "            events_array = np.reshape(np.transpose(events_array, (1,0,2)),(events_array.shape[1],-1))\n",
    "            selected_chans = 2*nchan\n",
    "        data.append(events_array)\n",
    "        labels.append(letter_written.index(data_dict['letter'][i]))\n",
    "\n",
    "    data = torch.tensor(data, dtype=dtype)    \n",
    "    labels = torch.tensor(labels,dtype=torch.long)\n",
    "\n",
    "    train, val, test = ratios\n",
    "\n",
    "    if val > 0:\n",
    "        split_1 = 1-train\n",
    "        split_2 = 1- val/(val+test)\n",
    "        x_train, x_valtest, y_train, y_valtest = train_test_split(data, labels, test_size=split_1, shuffle=True, stratify=labels, random_state=42)\n",
    "        x_val, x_test, y_val, y_test = train_test_split(x_valtest, y_valtest, test_size=split_2, shuffle=True, stratify=y_valtest, random_state=42)\n",
    "        ds_train = TensorDataset(x_train,y_train)\n",
    "        ds_val = TensorDataset(x_val,y_val)\n",
    "        ds_test = TensorDataset(x_test,y_test)\n",
    "    else:\n",
    "        x_train, x_test, y_train, y_test = train_test_split(data, labels, test_size=test, shuffle=True, stratify=labels, random_state=42)\n",
    "        ds_train = TensorDataset(x_train,y_train)\n",
    "        ds_val = []\n",
    "        ds_test = TensorDataset(x_test,y_test)\n",
    "    \n",
    "    return ds_train, ds_val, ds_test, labels, selected_chans, data_steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ebfd634a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_snn(inputs, layers):\n",
    "\n",
    "    if use_trainable_out and use_trainable_tc:\n",
    "        w1, w2, v1, alpha1, beta1, alpha2, beta2, out_scale, out_offset = layers\n",
    "    elif use_trainable_tc:\n",
    "        w1, w2, v1, alpha1, beta1, alpha2, beta2 = layers\n",
    "    elif use_trainable_out:\n",
    "        w1, w2, v1, out_scale, out_offset = layers\n",
    "    else:\n",
    "        w1, w2, v1 = layers\n",
    "    if use_dropout:\n",
    "        dropout = nn.Dropout(p = 0.25) # using dropout on n % of spikes\n",
    "    if use_trainable_tc:\n",
    "        alpha1, beta1 = torch.abs(alpha1), torch.abs(beta1)\n",
    "        alpha2, beta2 = torch.abs(alpha2), torch.abs(beta2)\n",
    "\n",
    "    bs = inputs.shape[0]\n",
    "    \n",
    "    h1 = torch.einsum(\n",
    "        \"abc,cd->abd\", (inputs.tile((nb_input_copies,)), w1))\n",
    "    if use_dropout:\n",
    "        h1 = dropout(h1)\n",
    "    if use_trainable_tc:\n",
    "        spk_rec, mem_rec = recurrent_layer.compute_activity_tc(bs, nb_hidden, h1, v1, alpha1, beta1, nb_steps)\n",
    "    else:\n",
    "        spk_rec, mem_rec = recurrent_layer.compute_activity(bs, nb_hidden, h1, v1, nb_steps)\n",
    "    \n",
    "    # Readout layer\n",
    "    h2 = torch.einsum(\"abc,cd->abd\", (spk_rec, w2))\n",
    "    if use_dropout:\n",
    "        h2 = dropout(h2)\n",
    "    if use_trainable_tc:\n",
    "        s_out_rec, out_rec = feedforward_layer.compute_activity_tc(bs, nb_outputs, h2, alpha2, beta2, nb_steps)\n",
    "    else:\n",
    "        s_out_rec, out_rec = feedforward_layer.compute_activity(bs, nb_outputs, h2, nb_steps)\n",
    "\n",
    "    if use_trainable_out:\n",
    "        # trainable output spike scaling\n",
    "        # mean_firing_rate = torch.div(torch.sum(s_out_rec,1), s_out_rec.shape[1]) # mean firing rate\n",
    "        # s_out_rec = mean_firing_rate*layers[5] + layers[6]\n",
    "        s_out_rec = torch.sum(s_out_rec, 1)*out_scale + \\\n",
    "            out_offset  # sum spikes\n",
    "\n",
    "    other_recs = [mem_rec, spk_rec, out_rec]\n",
    "    layers_update = layers\n",
    "\n",
    "    return s_out_rec, other_recs, layers_update\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5c4b7f8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_layers(file, map_location, requires_grad=True, variable=False):\n",
    "\n",
    "    if variable:\n",
    "        lays = file\n",
    "        for ii in lays:\n",
    "            ii.requires_grad = requires_grad\n",
    "    else:\n",
    "        lays = torch.load(file, map_location=map_location)\n",
    "        for ii in lays:\n",
    "            ii.requires_grad = requires_grad\n",
    "    return lays\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "42d208c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(params, dataset, lr=0.0015, nb_epochs=300, opt_parameters=None, layers=None, dataset_test=None):\n",
    "\n",
    "    if (opt_parameters != None) & (layers != None):\n",
    "        parameters = opt_parameters  # The paramters we want to optimize\n",
    "        layers = layers\n",
    "    elif (opt_parameters != None) & (layers == None):\n",
    "        parameters = opt_parameters\n",
    "        if use_trainable_out and use_trainable_tc:\n",
    "            layers = [w1, w2, v1, alpha1, beta1, alpha2, out_scale, out_offset]\n",
    "        elif use_trainable_out:\n",
    "            layers = [w1, w2, v1, out_scale, out_offset]\n",
    "        elif use_trainable_tc:\n",
    "            layers = [w1, w2, v1, alpha1, beta1, alpha2, beta2]\n",
    "        else:\n",
    "            layers = [w1, w2, v1, alpha1, beta1, alpha2, beta2,]\n",
    "    elif (opt_parameters == None) & (layers != None):\n",
    "        if use_trainable_out and use_trainable_tc:\n",
    "            layers = [w1, w2, v1, alpha1, beta1, alpha2,\n",
    "                        beta2, out_scale, out_offset]\n",
    "        elif use_trainable_out:\n",
    "            layers = [w1, w2, v1, out_scale, out_offset]\n",
    "        elif use_trainable_tc:\n",
    "            layers = [w1, w2, v1, alpha1, beta1, alpha2, beta2]\n",
    "        else:\n",
    "            layers = [w1, w2, v1, alpha1, beta1, alpha2, beta2]\n",
    "        layers = layers\n",
    "    elif (opt_parameters == None) & (layers == None):\n",
    "        if use_trainable_out and use_trainable_tc:\n",
    "            parameters = [w1, w2, v1, alpha1, beta1, alpha2,\n",
    "                        beta2, out_scale, out_offset]\n",
    "            layers = [w1, w2, v1, alpha1, beta1, alpha2,\n",
    "                        beta2, out_scale, out_offset]\n",
    "        elif use_trainable_out:\n",
    "            parameters = [w1, w2, v1, out_scale, out_offset]\n",
    "            layers = [w1, w2, v1, out_scale, out_offset]\n",
    "        elif use_trainable_tc:\n",
    "            parameters = [w1, w2, v1, alpha1, beta1, alpha2, beta2]\n",
    "            layers = [w1, w2, v1, alpha1, beta1, alpha2, beta2]\n",
    "        else:\n",
    "            parameters = [w1, w2, v1, alpha1, beta1,\n",
    "                        alpha2, beta2]\n",
    "            layers = [w1, w2, v1, alpha1, beta1,\n",
    "                        alpha2, beta2]\n",
    "\n",
    "    if use_seed:\n",
    "        g = torch.Generator()\n",
    "        g.manual_seed(42)\n",
    "        generator = DataLoader(\n",
    "                               dataset,\n",
    "                               batch_size=128,\n",
    "                               shuffle=True,\n",
    "                               num_workers=2,\n",
    "                               worker_init_fn=seed_worker,\n",
    "                               generator=g,\n",
    "                              )\n",
    "\n",
    "    else:\n",
    "        generator = DataLoader(\n",
    "                               dataset,\n",
    "                               batch_size=128,\n",
    "                               shuffle=True,\n",
    "                               num_workers=2,\n",
    "                              )\n",
    "\n",
    "    # The log softmax function across output units\n",
    "    log_softmax_fn = nn.LogSoftmax(dim=1)\n",
    "    loss_fn = nn.NLLLoss()  # The negative log likelihood loss function\n",
    "\n",
    "    # The optimization loop\n",
    "    loss_hist = []\n",
    "    accs_hist = [[], []]\n",
    "    for e in range(nb_epochs):\n",
    "        # learning rate decreases over epochs\n",
    "        optimizer = torch.optim.Adamax(parameters, lr=lr, betas=(0.9, 0.995))\n",
    "        # if e > nb_epochs/2:\n",
    "        #     lr = lr * 0.9\n",
    "        local_loss = []\n",
    "        # accs: mean training accuracies for each batch\n",
    "        accs = []\n",
    "        for x_local, y_local in generator:\n",
    "            x_local, y_local = x_local.to(device), y_local.to(device)\n",
    "            spks_out, recs, layers_update = run_snn(x_local, layers)\n",
    "            # [mem_rec, spk_rec, out_rec]\n",
    "            _, spk_rec, _ = recs\n",
    "\n",
    "            # with output spikes\n",
    "            if use_trainable_out:\n",
    "                m = spks_out\n",
    "            else:\n",
    "                m = torch.sum(spks_out, 1)  # sum over time\n",
    "            # cross entropy loss on the active read-out layer\n",
    "            log_p_y = log_softmax_fn(m)\n",
    "\n",
    "            # TODO change to loop!\n",
    "            # Here we can set up our regularizer loss\n",
    "            # reg_loss = params['reg_spikes']*torch.mean(torch.sum(spks1,1)) # L1 loss on spikes per neuron (original)\n",
    "            # L1 loss on total number of spikes (hidden layer 1)\n",
    "            reg_loss = params['reg_spikes']*torch.mean(torch.sum(spk_rec, 1))\n",
    "            # L1 loss on total number of spikes (output layer)\n",
    "            # reg_loss += params['reg_spikes']*torch.mean(torch.sum(spks_out, 1))\n",
    "            # print(\"L1: \", reg_loss)\n",
    "            # reg_loss += params['reg_neurons']*torch.mean(torch.sum(torch.sum(spks1,dim=0),dim=0)**2) # e.g., L2 loss on total number of spikes (original)\n",
    "            # L2 loss on spikes per neuron (hidden layer 1)\n",
    "            reg_loss += params['reg_neurons'] * \\\n",
    "                torch.mean(torch.sum(torch.sum(spk_rec, dim=0), dim=0)**2)\n",
    "            # L2 loss on spikes per neuron (output layer)\n",
    "            # reg_loss += params['reg_neurons'] * \\\n",
    "            #     torch.mean(torch.sum(torch.sum(spks_out, dim=0), dim=0)**2)\n",
    "            # print(\"L1 + L2: \", reg_loss)\n",
    "\n",
    "            # Here we combine supervised loss and the regularizer\n",
    "            loss_val = loss_fn(log_p_y, y_local) + reg_loss\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss_val.backward()\n",
    "            optimizer.step()\n",
    "            local_loss.append(loss_val.item())\n",
    "\n",
    "            # compare to labels\n",
    "            _, am = torch.max(m, 1)  # argmax over output units\n",
    "            tmp = np.mean((y_local == am).detach().cpu().numpy())\n",
    "            accs.append(tmp)\n",
    "\n",
    "        mean_loss = np.mean(local_loss)\n",
    "        loss_hist.append(mean_loss)\n",
    "\n",
    "        # mean_accs: mean training accuracy of current epoch (average over all batches)\n",
    "        mean_accs = np.mean(accs)\n",
    "        accs_hist[0].append(mean_accs)\n",
    "\n",
    "        # Calculate test accuracy in each epoch\n",
    "        if dataset_test is not None:\n",
    "            test_acc = compute_classification_accuracy(\n",
    "                params,\n",
    "                dataset_test,\n",
    "                layers=layers_update,\n",
    "                early=True\n",
    "            )\n",
    "            accs_hist[1].append(test_acc)  # only safe best test\n",
    "\n",
    "        if dataset_test is None:\n",
    "            # save best training\n",
    "            if mean_accs >= np.max(accs_hist[0]):\n",
    "                best_acc_layers = []\n",
    "                for ii in layers_update:\n",
    "                    best_acc_layers.append(ii.detach().clone())\n",
    "        else:\n",
    "            # save best test\n",
    "            if np.max(test_acc) >= np.max(accs_hist[1]):\n",
    "                best_acc_layers = []\n",
    "                for ii in layers_update:\n",
    "                    best_acc_layers.append(ii.detach().clone())\n",
    "\n",
    "        # plt.figure(\"live plot\")\n",
    "        # plt.title(\"Epoch: {}\" .format(e+1))\n",
    "        # plt.subplot(1, 2, 1)\n",
    "        # plt.plot(range(1, len(accs_hist[0])+1),\n",
    "        #          100*np.array(accs_hist[0]), color='blue')\n",
    "        # plt.plot(range(1, len(accs_hist[1])+1),\n",
    "        #          100*np.array(accs_hist[1]), color='orange')\n",
    "        # plt.xlabel(\"Epoch\")\n",
    "        # plt.ylabel(\"Accuracy (%)\")\n",
    "        # plt.ylim(0, 105)\n",
    "        # plt.legend([\"Training\", \"Test\"], loc='lower right')\n",
    "        # plt.subplot(1, 2, 2)\n",
    "        # plt.plot(range(1, len(loss_hist)+1), np.array(loss_hist), color='blue')\n",
    "        # plt.xlabel(\"Epoch\")\n",
    "        # plt.ylabel(\"Loss\")\n",
    "        # plt.legend([\"Training\"], loc='lower right')\n",
    "        # # to avoid clearing last plot\n",
    "        # if (e != epochs-1):\n",
    "        #     plt.draw()\n",
    "        #     plt.pause(0.1)\n",
    "        #     plt.cla()\n",
    "        # else:\n",
    "        #     plt.close(\"live plot\")\n",
    "\n",
    "        print(\"Epoch {}/{} done. Train accuracy: {:.2f}%, Test accuracy: {:.2f}%, Loss: {:.5f}.\".format(\n",
    "            e + 1, nb_epochs, accs_hist[0][-1]*100, accs_hist[1][-1]*100, loss_hist[-1]))\n",
    "\n",
    "    return loss_hist, accs_hist, best_acc_layers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cb74d6b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_and_train(params, ds_train, ds_test, epochs=epochs):\n",
    "\n",
    "    global nb_input_copies\n",
    "    # Num of spiking neurons used to encode each channel\n",
    "    nb_input_copies = params['nb_input_copies']\n",
    "\n",
    "    # Network parameters\n",
    "    global nb_inputs\n",
    "    nb_inputs = nb_channels*nb_input_copies\n",
    "    global nb_outputs\n",
    "    nb_outputs = len(np.unique(labels))\n",
    "    global nb_hidden\n",
    "    nb_hidden = 450\n",
    "    global nb_steps\n",
    "    nb_steps = data_steps\n",
    "\n",
    "    tau_mem = params['tau_mem']  # ms\n",
    "    tau_syn = tau_mem/params['tau_ratio']\n",
    "    \n",
    "    if not use_trainable_tc:\n",
    "        global alpha\n",
    "        global beta\n",
    "    alpha = float(np.exp(-time_step/tau_syn))\n",
    "    beta = float(np.exp(-time_step/tau_mem))\n",
    "\n",
    "    fwd_weight_scale = params['fwd_weight_scale']\n",
    "    rec_weight_scale = fwd_weight_scale*params['weight_scale_factor']\n",
    "\n",
    "    # Spiking network\n",
    "    layers = []\n",
    "    \n",
    "    # recurrent layer\n",
    "    w1, v1 = recurrent_layer.create_layer(\n",
    "        nb_inputs, nb_hidden, fwd_weight_scale, rec_weight_scale)\n",
    "\n",
    "    # readout layer\n",
    "    w2 = feedforward_layer.create_layer(\n",
    "        nb_hidden, nb_outputs, fwd_weight_scale)\n",
    "    \n",
    "    if use_trainable_tc:\n",
    "        # time constants\n",
    "        alpha1, beta1 = trainable_time_constants.create_time_constants(\n",
    "            nb_hidden, alpha, beta, use_trainable_tc)\n",
    "\n",
    "        alpha2, beta2 = trainable_time_constants.create_time_constants(\n",
    "            nb_outputs, alpha, beta, use_trainable_tc)\n",
    "\n",
    "\n",
    "    layers.append(w1), layers.append(w2), layers.append(v1)\n",
    "    if use_trainable_tc:\n",
    "        layers.append(alpha1), layers.append(beta1), layers.append(alpha2), layers.append(beta2)\n",
    "\n",
    "    if use_trainable_out:\n",
    "        # include trainable output for readout layer (linear: y = out_scale * x + out_offset)\n",
    "        out_scale = torch.empty(\n",
    "            (nb_outputs),  device=device, dtype=dtype, requires_grad=True)\n",
    "        torch.nn.init.ones_(out_scale)\n",
    "        layers.append(out_scale)\n",
    "        out_offset = torch.empty(\n",
    "            (nb_outputs),  device=device, dtype=dtype, requires_grad=True)\n",
    "        torch.nn.init.zeros_(out_offset)\n",
    "        layers.append(out_offset)\n",
    "\n",
    "    layers_init = []\n",
    "    for ii in layers:\n",
    "        layers_init.append(ii.detach().clone())\n",
    "\n",
    "    if use_trainable_out and use_trainable_tc:\n",
    "        opt_parameters = [w1, w2, v1, alpha1, beta1, alpha2, beta2, out_scale, out_offset]\n",
    "    elif use_trainable_tc:\n",
    "        opt_parameters = [w1, w2, v1, alpha1, beta1, alpha2, beta2]\n",
    "    elif use_trainable_out:\n",
    "        opt_parameters = [w1, w2, v1, out_scale, out_offset]\n",
    "    else:\n",
    "        opt_parameters = [w1, w2, v1]\n",
    "\n",
    "    # a fixed learning rate is already defined within the train function, that's why here it is omitted\n",
    "    loss_hist, accs_hist, best_layers = train(\n",
    "        params, ds_train, lr=lr, nb_epochs=epochs, opt_parameters=opt_parameters, layers=layers, dataset_test=ds_test)\n",
    "\n",
    "    # best training and test at best training\n",
    "    acc_best_train = np.max(accs_hist[0])  # returns max value\n",
    "    acc_best_train = acc_best_train*100\n",
    "    idx_best_train = np.argmax(accs_hist[0])  # returns index of max value\n",
    "    acc_test_at_best_train = accs_hist[1][idx_best_train]*100\n",
    "\n",
    "    # best test and training at best test\n",
    "    acc_best_test = np.max(accs_hist[1])\n",
    "    acc_best_test = acc_best_test*100\n",
    "    idx_best_test = np.argmax(accs_hist[1])\n",
    "    acc_train_at_best_test = accs_hist[0][idx_best_test]*100\n",
    "\n",
    "    # TODO track time constants!!!\n",
    "    print(\"Final results: \")\n",
    "    print(\"Best training accuracy: {:.2f}% and according test accuracy: {:.2f}% at epoch: {}\".format(\n",
    "        acc_best_train, acc_test_at_best_train, idx_best_train+1))\n",
    "    print(\"Best test accuracy: {:.2f}% and according train accuracy: {:.2f}% at epoch: {}\".format(\n",
    "        acc_best_test, acc_train_at_best_test, idx_best_test+1))\n",
    "    print(\"------------------------------------------------------------------------------------\\n\")\n",
    "    return loss_hist, accs_hist, best_layers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9f786ab0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_classification_accuracy(params, dataset, layers=None, early=False):\n",
    "    \"\"\" Computes classification accuracy on supplied data in batches. \"\"\"\n",
    "\n",
    "    if use_seed:\n",
    "        g = torch.Generator()\n",
    "        g.manual_seed(42)\n",
    "        generator = DataLoader(\n",
    "                               dataset,\n",
    "                               batch_size=128,\n",
    "                               shuffle=True,\n",
    "                               num_workers=2,\n",
    "                               worker_init_fn=seed_worker,\n",
    "                               generator=g,\n",
    "                              )\n",
    "\n",
    "    else:\n",
    "        generator = DataLoader(\n",
    "                               dataset,\n",
    "                               batch_size=128,\n",
    "                               shuffle=True,\n",
    "                               num_workers=2,\n",
    "                              )\n",
    "                              \n",
    "    accs = []\n",
    "\n",
    "    for x_local, y_local in generator:\n",
    "        x_local, y_local = x_local.to(device), y_local.to(device)\n",
    "        if layers == None:\n",
    "            if use_trainable_out and use_trainable_tc:\n",
    "                layers = [w1, w2, v1, alpha1, beta1, alpha2,\n",
    "                          beta2, out_scale, out_offset]\n",
    "            elif use_trainable_out:\n",
    "                layers = [w1, w2, v1, out_scale, out_offset]\n",
    "            elif use_trainable_tc:\n",
    "                layers = [w1, w2, v1, alpha1, beta1, alpha2, beta2]\n",
    "            else:\n",
    "                layers = [w1, w2, v1, alpha1, beta1, alpha2, beta2]\n",
    "            spks_out, _, _ = run_snn(x_local, layers)\n",
    "        else:\n",
    "            spks_out, _, _ = run_snn(x_local, layers)\n",
    "        # with output spikes\n",
    "        if use_trainable_out:\n",
    "            m = spks_out\n",
    "        else:\n",
    "            m = torch.sum(spks_out, 1)  # sum over time\n",
    "        _, am = torch.max(m, 1)     # argmax over output units\n",
    "        # compare to labels\n",
    "        tmp = np.mean((y_local == am).detach().cpu().numpy())\n",
    "        accs.append(tmp)\n",
    "\n",
    "    return np.mean(accs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0fe0a143",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ConfusionMatrix(dataset, save, layers=None, labels=letters):\n",
    "\n",
    "    generator = DataLoader(dataset, batch_size=batch_size,\n",
    "                           shuffle=False, num_workers=2)\n",
    "    accs = []\n",
    "    trues = []\n",
    "    preds = []\n",
    "    for x_local, y_local in generator:\n",
    "        x_local, y_local = x_local.to(device), y_local.to(device)\n",
    "        if layers == None:\n",
    "            if use_trainable_out and use_trainable_tc:\n",
    "                layers = [w1, w2, v1, alpha1, beta1, alpha2,\n",
    "                          beta2, out_scale, out_offset]\n",
    "            elif use_trainable_out:\n",
    "                layers = [w1, w2, v1, out_scale, out_offset]\n",
    "            elif use_trainable_tc:\n",
    "                layers = [w1, w2, v1, alpha1, beta1, alpha2, beta2]\n",
    "            else:\n",
    "                layers = [w1, w2, v1, alpha1, beta1, alpha2, beta2]\n",
    "            spks_out, _, _ = run_snn(x_local, layers)\n",
    "        else:\n",
    "            spks_out, _, _ = run_snn(x_local, layers)\n",
    "        # with output spikes\n",
    "        if use_trainable_out:\n",
    "            m = spks_out\n",
    "        else:\n",
    "            m = torch.sum(spks_out, 1)  # sum over time\n",
    "        _, am = torch.max(m, 1)     # argmax over output units\n",
    "        # compare to labels\n",
    "        tmp = np.mean((y_local == am).detach().cpu().numpy())\n",
    "        accs.append(tmp)\n",
    "        trues.extend(y_local.detach().cpu().numpy())\n",
    "        preds.extend(am.detach().cpu().numpy())\n",
    "\n",
    "    cm = confusion_matrix(trues, preds, normalize='true')\n",
    "    cm_df = pd.DataFrame(cm, index=[ii for ii in labels], columns=[\n",
    "                         jj for jj in labels])\n",
    "    plt.figure(figsize=(12, 9))\n",
    "    sn.heatmap(cm_df,\n",
    "               annot=True,\n",
    "               fmt='.1g',\n",
    "               cbar=False,\n",
    "               square=False,\n",
    "               cmap=\"YlGnBu\")\n",
    "    plt.xlabel('\\nPredicted')\n",
    "    plt.ylabel('True\\n')\n",
    "    plt.xticks(rotation=0)\n",
    "    if save:\n",
    "        if use_trainable_out:\n",
    "            plt.savefig(\"../plots/rsnn_1layers_train_tc_output_optimized_thr_\" +\n",
    "                        str(threshold) + \"_cm.png\", dpi=300)\n",
    "        else:\n",
    "            plt.savefig(\"../plots/rsnn_1layers_train_tc_thr_\" +\n",
    "                        str(threshold) + \"_cm.png\", dpi=300)\n",
    "    else:\n",
    "        plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6bfd799d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def NetworkActivity(dataset, save, layers=None, labels=letters):\n",
    "\n",
    "    generator = DataLoader(dataset, batch_size=batch_size,\n",
    "                           shuffle=False, num_workers=2)\n",
    "    accs = []\n",
    "    trues = []\n",
    "    preds = []\n",
    "    for x_local, y_local in generator:\n",
    "        x_local, y_local = x_local.to(device), y_local.to(device)\n",
    "        if layers == None:\n",
    "            if use_trainable_out and use_trainable_tc:\n",
    "                layers = [w1, w2, v1, alpha1, beta1, alpha2,\n",
    "                          beta2, out_scale, out_offset]\n",
    "            elif use_trainable_out:\n",
    "                layers = [w1, w2, v1, out_scale, out_offset]\n",
    "            elif use_trainable_tc:\n",
    "                layers = [w1, w2, v1, alpha1, beta1, alpha2, beta2]\n",
    "            else:\n",
    "                layers = [w1, w2, v1, alpha1, beta1, alpha2, beta2]\n",
    "            spks_out, recs, _ = run_snn(x_local, layers)\n",
    "        else:\n",
    "            spks_out, recs, _ = run_snn(x_local, layers)\n",
    "\n",
    "        # [mem_rec, spk_rec, mem_rec2, spk_rec2, out_rec]\n",
    "        _, spk_rec, _, spk_rec3, _ = recs\n",
    "\n",
    "    nb_plt = 4\n",
    "    gs = GridSpec(1, nb_plt)\n",
    "\n",
    "    # hidden layer\n",
    "    fig = plt.figure(figsize=(7, 3), dpi=150)\n",
    "    plt.title(\"Hidden layer 1\")\n",
    "    for i in range(nb_plt):\n",
    "        plt.subplot(gs[i])\n",
    "        plt.imshow(spk_rec[i].detach().cpu().numpy().T,\n",
    "                   cmap=plt.cm.gray_r, origin=\"lower\")\n",
    "        if i == 0:\n",
    "            plt.xlabel(\"Time\")\n",
    "            plt.ylabel(\"Units\")\n",
    "        sn.despine()\n",
    "    if save:\n",
    "        if use_trainable_out:\n",
    "            plt.savefig(\"../plots/rsnn_1layers_train_tc_output\" +\n",
    "                        \"_thr_\" + str(threshold) + \"_rp_layer_1.png\", dpi=300)\n",
    "        else:\n",
    "            plt.savefig(\"../plots/rsnn_1layers_train_tc_thr_\" +\n",
    "                        str(threshold) + \"_rp_layer_1.png\", dpi=300)\n",
    "\n",
    "    # output layer\n",
    "    fig = plt.figure(figsize=(7, 3), dpi=150)\n",
    "    plt.title(\"Output layer\")\n",
    "    for i in range(nb_plt):\n",
    "        plt.subplot(gs[i])\n",
    "        plt.imshow(spks_out[i].detach().cpu().numpy().T,\n",
    "                   cmap=plt.cm.gray_r, origin=\"lower\")\n",
    "        if i == 0:\n",
    "            plt.xlabel(\"Time\")\n",
    "            plt.ylabel(\"Units\")\n",
    "        sn.despine()\n",
    "    if save:\n",
    "        if use_trainable_out:\n",
    "            plt.savefig(\"../plots/rsnn_1layers_train_tc_output\" +\n",
    "                        \"_thr_\" + str(threshold) + \"_rp_output_layer.png\", dpi=300)\n",
    "        else:\n",
    "            plt.savefig(\"../plots/rsnn_1layers_train_tc_thr_\" +\n",
    "                        str(threshold) + \"_rp_output_layer.png\", dpi=300)\n",
    "    else:\n",
    "        plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9b201b6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data and parameters\n",
    "file_dir_data = '../../data/'\n",
    "file_freq = 100 #40\n",
    "file_type = 'data_braille_letters_th_'\n",
    "#file_type = 'data_braille_letters_events_augmented_th'\n",
    "file_thr = str(threshold)\n",
    "file_name = file_dir_data + str(file_freq) + 'Hz/' + file_type + file_thr + '.pkl' #'_rpNull'\n",
    "\n",
    "file_dir_params = '../parameters/'\n",
    "param_filename = 'parameters_th' + str(threshold) + '.txt'\n",
    "file_name_parameters = file_dir_params + param_filename\n",
    "params = {}\n",
    "with open(file_name_parameters) as file:\n",
    "    for line in file:\n",
    "        (key, value) = line.split()\n",
    "        if key == 'time_bin_size' or key == 'nb_input_copies':\n",
    "            params[key] = int(value)\n",
    "        else:\n",
    "            params[key] = np.double(value)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "faabd621",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SurrGradSpike(torch.autograd.Function):\n",
    "    \"\"\"\n",
    "    Here we implement our spiking nonlinearity which also implements \n",
    "    the surrogate gradient. By subclassing torch.autograd.Function, \n",
    "    we will be able to use all of PyTorch's autograd functionality.\n",
    "    Here we use the normalized negative part of a fast sigmoid \n",
    "    as this was done in Zenke & Ganguli (2018).\n",
    "    \"\"\"\n",
    "\n",
    "    scale = params['scale']\n",
    "\n",
    "    @staticmethod\n",
    "    def forward(ctx, input):\n",
    "        \"\"\"\n",
    "        In the forward pass we compute a step function of the input Tensor\n",
    "        and return it. ctx is a context object that we use to stash information which \n",
    "        we need to later backpropagate our error signals. To achieve this we use the \n",
    "        ctx.save_for_backward method.\n",
    "        \"\"\"\n",
    "        ctx.save_for_backward(input)\n",
    "        out = torch.zeros_like(input)\n",
    "        out[input > 0] = 1.0\n",
    "        return out\n",
    "\n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_output):\n",
    "        \"\"\"\n",
    "        In the backward pass we receive a Tensor we need to compute the \n",
    "        surrogate gradient of the loss with respect to the input. \n",
    "        Here we use the normalized negative part of a fast sigmoid \n",
    "        as this was done in Zenke & Ganguli (2018).\n",
    "        \"\"\"\n",
    "        input, = ctx.saved_tensors\n",
    "        grad_input = grad_output.clone()\n",
    "        grad = grad_input/(SurrGradSpike.scale*torch.abs(input)+1.0)**2\n",
    "        return grad\n",
    "\n",
    "\n",
    "spike_fn = SurrGradSpike.apply\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d7be3b46",
   "metadata": {},
   "outputs": [],
   "source": [
    "class feedforward_layer:\n",
    "    '''\n",
    "    class to initialize and compute spiking feedforward layer\n",
    "    '''\n",
    "    def create_layer(nb_inputs, nb_outputs, scale):\n",
    "        ff_layer = torch.empty((nb_inputs, nb_outputs),  device=device, dtype=dtype, requires_grad=True)\n",
    "        torch.nn.init.normal_(ff_layer, mean=0.0, std=scale/np.sqrt(nb_inputs))\n",
    "        return ff_layer\n",
    "    \n",
    "    def compute_activity(nb_input, nb_neurons, input_activity, nb_steps):\n",
    "        syn = torch.zeros((nb_input,nb_neurons), device=device, dtype=dtype)\n",
    "        mem = torch.zeros((nb_input,nb_neurons), device=device, dtype=dtype)\n",
    "        out = torch.zeros((nb_input, nb_neurons), device=device, dtype=dtype)\n",
    "        mem_rec = []\n",
    "        spk_rec = []\n",
    "\n",
    "        # Compute feedforward layer activity\n",
    "        for t in range(nb_steps):\n",
    "            mthr = mem-1.0\n",
    "            out = spike_fn(mthr)\n",
    "            rst_out = out.detach()\n",
    "\n",
    "            new_syn = alpha*syn + input_activity[:,t]\n",
    "            new_mem = (beta*mem + syn)*(1.0-rst_out)\n",
    "\n",
    "            mem_rec.append(mem)\n",
    "            spk_rec.append(out)\n",
    "\n",
    "            mem = new_mem\n",
    "            syn = new_syn\n",
    "\n",
    "        # Now we merge the recorded membrane potentials into a single tensor\n",
    "        mem_rec = torch.stack(mem_rec,dim=1)\n",
    "        spk_rec = torch.stack(spk_rec,dim=1)\n",
    "        return spk_rec, mem_rec\n",
    "    \n",
    "    def compute_activity_tc(nb_input, nb_neurons, input_activity, alpha, beta, nb_steps):\n",
    "        syn = torch.zeros((nb_input,nb_neurons), device=device, dtype=dtype)\n",
    "        mem = torch.zeros((nb_input,nb_neurons), device=device, dtype=dtype)\n",
    "        out = torch.zeros((nb_input, nb_neurons), device=device, dtype=dtype)\n",
    "        mem_rec = []\n",
    "        spk_rec = []\n",
    "\n",
    "        # Compute feedforward layer activity\n",
    "        for t in range(nb_steps):\n",
    "            mthr = mem-1.0\n",
    "            out = spike_fn(mthr)\n",
    "            rst_out = out.detach()\n",
    "\n",
    "            new_syn = torch.abs(alpha)*syn + input_activity[:,t]\n",
    "            new_mem = (torch.abs(beta)*mem + syn)*(1.0-rst_out)\n",
    "\n",
    "            mem_rec.append(mem)\n",
    "            spk_rec.append(out)\n",
    "\n",
    "            mem = new_mem\n",
    "            syn = new_syn\n",
    "\n",
    "        # Now we merge the recorded membrane potentials into a single tensor\n",
    "        mem_rec = torch.stack(mem_rec,dim=1)\n",
    "        spk_rec = torch.stack(spk_rec,dim=1)\n",
    "        return spk_rec, mem_rec\n",
    "\n",
    "\n",
    "class recurrent_layer:\n",
    "    '''\n",
    "    class to initialize and compute spiking recurrent layer\n",
    "    '''\n",
    "    def create_layer(nb_inputs, nb_outputs, fwd_scale, rec_scale):\n",
    "        ff_layer = torch.empty((nb_inputs, nb_outputs),  device=device, dtype=dtype, requires_grad=True)\n",
    "        torch.nn.init.normal_(ff_layer, mean=0.0, std=fwd_scale/np.sqrt(nb_inputs))\n",
    "        \n",
    "        rec_layer = torch.empty((nb_outputs, nb_outputs),  device=device, dtype=dtype, requires_grad=True)\n",
    "        torch.nn.init.normal_(rec_layer, mean=0.0, std=rec_scale/np.sqrt(nb_inputs))\n",
    "        return ff_layer,  rec_layer\n",
    "    \n",
    "    def compute_activity(nb_input, nb_neurons, input_activity, layer, nb_steps):\n",
    "        syn = torch.zeros((nb_input,nb_neurons), device=device, dtype=dtype)\n",
    "        mem = torch.zeros((nb_input,nb_neurons), device=device, dtype=dtype)\n",
    "        out = torch.zeros((nb_input, nb_neurons), device=device, dtype=dtype)\n",
    "        mem_rec = []\n",
    "        spk_rec = []\n",
    "\n",
    "        # Compute recurrent layer activity\n",
    "        for t in range(nb_steps):\n",
    "            # input activity plus last step output activity\n",
    "            h1 = input_activity[:,t] + torch.einsum(\"ab,bc->ac\", (out, layer))\n",
    "            mthr = mem-1.0\n",
    "            out = spike_fn(mthr)\n",
    "            rst = out.detach() # We do not want to backprop through the reset\n",
    "\n",
    "            new_syn = alpha*syn + h1\n",
    "            new_mem = (beta*mem + syn)*(1.0-rst)\n",
    "\n",
    "            mem_rec.append(mem)\n",
    "            spk_rec.append(out)\n",
    "        \n",
    "            mem = new_mem\n",
    "            syn = new_syn\n",
    "\n",
    "        # Now we merge the recorded membrane potentials into a single tensor\n",
    "        mem_rec = torch.stack(mem_rec,dim=1)\n",
    "        spk_rec = torch.stack(spk_rec,dim=1)\n",
    "        return spk_rec, mem_rec\n",
    "    \n",
    "    def compute_activity_tc(nb_input, nb_neurons, input_activity, layer, alpha, beta, nb_steps):\n",
    "        syn = torch.zeros((nb_input,nb_neurons), device=device, dtype=dtype)\n",
    "        mem = torch.zeros((nb_input,nb_neurons), device=device, dtype=dtype)\n",
    "        out = torch.zeros((nb_input, nb_neurons), device=device, dtype=dtype)\n",
    "        mem_rec = []\n",
    "        spk_rec = []\n",
    "\n",
    "        # Compute recurrent layer activity\n",
    "        for t in range(nb_steps):\n",
    "            # input activity plus last step output activity\n",
    "            h1 = input_activity[:,t] + torch.einsum(\"ab,bc->ac\", (out, layer))\n",
    "            mthr = mem-1.0\n",
    "            out = spike_fn(mthr)\n",
    "            rst = out.detach() # We do not want to backprop through the reset\n",
    "\n",
    "            new_syn = torch.abs(alpha)*syn + h1\n",
    "            new_mem = (torch.abs(beta)*mem + syn)*(1.0-rst)\n",
    "\n",
    "            mem_rec.append(mem)\n",
    "            spk_rec.append(out)\n",
    "        \n",
    "            mem = new_mem\n",
    "            syn = new_syn\n",
    "\n",
    "        # Now we merge the recorded membrane potentials into a single tensor\n",
    "        mem_rec = torch.stack(mem_rec,dim=1)\n",
    "        spk_rec = torch.stack(spk_rec,dim=1)\n",
    "        return spk_rec, mem_rec\n",
    "\n",
    "\n",
    "class trainable_time_constants:\n",
    "    def create_time_constants(nb_neurons, alpha_mean, beta_mean, trainable):\n",
    "        alpha = torch.empty((nb_neurons),  device=device,\n",
    "                             dtype=dtype, requires_grad=trainable)\n",
    "        torch.nn.init.normal_(\n",
    "            alpha, mean=alpha_mean, std=alpha_mean/10)\n",
    "        \n",
    "        beta = torch.empty((nb_neurons),  device=device,\n",
    "                            dtype=dtype, requires_grad=trainable)\n",
    "        torch.nn.init.normal_(\n",
    "            beta, mean=beta_mean, std=beta_mean/10)\n",
    "        return alpha, beta"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f8fff8c",
   "metadata": {},
   "source": [
    "### Train and test the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cd9869ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_19024/910255790.py:50: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
      "  data = torch.tensor(data, dtype=dtype)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training data 6480\n",
      "Number of testing data 1620\n",
      "Number of outputs 27\n",
      "Number of timesteps 1167\n",
      "Input duration 3.501000s\n",
      "---------------------------\n",
      "\n",
      "Epoch 1/300 done. Train accuracy: 9.19%, Test accuracy: 15.30%, Loss: 17.98430.\n",
      "Epoch 2/300 done. Train accuracy: 15.37%, Test accuracy: 24.73%, Loss: 6.85765.\n",
      "Epoch 3/300 done. Train accuracy: 32.10%, Test accuracy: 47.86%, Loss: 2.99233.\n",
      "Epoch 4/300 done. Train accuracy: 43.05%, Test accuracy: 54.58%, Loss: 2.58211.\n",
      "Epoch 5/300 done. Train accuracy: 52.77%, Test accuracy: 66.60%, Loss: 1.88018.\n",
      "Epoch 6/300 done. Train accuracy: 62.40%, Test accuracy: 71.81%, Loss: 1.55787.\n",
      "Epoch 7/300 done. Train accuracy: 68.97%, Test accuracy: 79.70%, Loss: 1.15863.\n",
      "Epoch 8/300 done. Train accuracy: 76.64%, Test accuracy: 86.10%, Loss: 0.81050.\n",
      "Epoch 9/300 done. Train accuracy: 82.22%, Test accuracy: 88.84%, Loss: 0.69791.\n",
      "Epoch 10/300 done. Train accuracy: 85.07%, Test accuracy: 91.76%, Loss: 0.54818.\n",
      "Epoch 11/300 done. Train accuracy: 87.39%, Test accuracy: 92.54%, Loss: 0.49755.\n",
      "Epoch 12/300 done. Train accuracy: 91.08%, Test accuracy: 92.45%, Loss: 0.32151.\n",
      "Epoch 13/300 done. Train accuracy: 91.70%, Test accuracy: 94.08%, Loss: 0.30751.\n",
      "Epoch 14/300 done. Train accuracy: 92.44%, Test accuracy: 94.34%, Loss: 0.27623.\n",
      "Epoch 15/300 done. Train accuracy: 93.21%, Test accuracy: 95.10%, Loss: 0.25067.\n",
      "Epoch 16/300 done. Train accuracy: 93.70%, Test accuracy: 94.94%, Loss: 0.33055.\n",
      "Epoch 17/300 done. Train accuracy: 95.09%, Test accuracy: 95.43%, Loss: 0.18245.\n",
      "Epoch 18/300 done. Train accuracy: 95.23%, Test accuracy: 96.33%, Loss: 0.18382.\n",
      "Epoch 19/300 done. Train accuracy: 95.49%, Test accuracy: 96.06%, Loss: 0.16380.\n",
      "Epoch 20/300 done. Train accuracy: 95.99%, Test accuracy: 96.42%, Loss: 0.16246.\n",
      "Epoch 21/300 done. Train accuracy: 96.11%, Test accuracy: 96.96%, Loss: 0.14222.\n",
      "Epoch 22/300 done. Train accuracy: 96.64%, Test accuracy: 95.57%, Loss: 0.14375.\n",
      "Epoch 23/300 done. Train accuracy: 96.67%, Test accuracy: 96.39%, Loss: 0.12322.\n",
      "Epoch 24/300 done. Train accuracy: 96.85%, Test accuracy: 97.20%, Loss: 0.12560.\n",
      "Epoch 25/300 done. Train accuracy: 95.98%, Test accuracy: 96.24%, Loss: 0.15594.\n",
      "Epoch 26/300 done. Train accuracy: 97.27%, Test accuracy: 96.84%, Loss: 0.09633.\n",
      "Epoch 27/300 done. Train accuracy: 97.42%, Test accuracy: 96.84%, Loss: 0.11240.\n",
      "Epoch 28/300 done. Train accuracy: 96.99%, Test accuracy: 97.56%, Loss: 0.13544.\n",
      "Epoch 29/300 done. Train accuracy: 97.47%, Test accuracy: 96.63%, Loss: 0.09211.\n",
      "Epoch 30/300 done. Train accuracy: 97.22%, Test accuracy: 96.51%, Loss: 0.09754.\n",
      "Epoch 31/300 done. Train accuracy: 97.52%, Test accuracy: 96.90%, Loss: 0.09354.\n",
      "Epoch 32/300 done. Train accuracy: 97.59%, Test accuracy: 96.72%, Loss: 0.09477.\n",
      "Epoch 33/300 done. Train accuracy: 97.59%, Test accuracy: 97.23%, Loss: 0.08797.\n",
      "Epoch 34/300 done. Train accuracy: 97.09%, Test accuracy: 97.38%, Loss: 0.13828.\n",
      "Epoch 35/300 done. Train accuracy: 97.49%, Test accuracy: 96.69%, Loss: 0.09369.\n",
      "Epoch 36/300 done. Train accuracy: 97.63%, Test accuracy: 97.20%, Loss: 0.08657.\n",
      "Epoch 37/300 done. Train accuracy: 98.04%, Test accuracy: 97.59%, Loss: 0.07004.\n",
      "Epoch 38/300 done. Train accuracy: 97.99%, Test accuracy: 97.11%, Loss: 0.07362.\n",
      "Epoch 39/300 done. Train accuracy: 97.66%, Test accuracy: 97.59%, Loss: 0.10061.\n",
      "Epoch 40/300 done. Train accuracy: 97.95%, Test accuracy: 97.44%, Loss: 0.08290.\n",
      "Epoch 41/300 done. Train accuracy: 97.90%, Test accuracy: 97.29%, Loss: 0.09054.\n",
      "Epoch 42/300 done. Train accuracy: 98.07%, Test accuracy: 97.11%, Loss: 0.07190.\n",
      "Epoch 43/300 done. Train accuracy: 97.94%, Test accuracy: 97.38%, Loss: 0.07996.\n",
      "Epoch 44/300 done. Train accuracy: 98.27%, Test accuracy: 97.50%, Loss: 0.06196.\n",
      "Epoch 45/300 done. Train accuracy: 97.89%, Test accuracy: 97.56%, Loss: 0.08395.\n",
      "Epoch 46/300 done. Train accuracy: 98.05%, Test accuracy: 97.35%, Loss: 0.07869.\n",
      "Epoch 47/300 done. Train accuracy: 98.31%, Test accuracy: 97.23%, Loss: 0.06201.\n",
      "Epoch 48/300 done. Train accuracy: 98.08%, Test accuracy: 97.62%, Loss: 0.06804.\n",
      "Epoch 49/300 done. Train accuracy: 98.11%, Test accuracy: 97.17%, Loss: 0.06794.\n",
      "Epoch 50/300 done. Train accuracy: 98.14%, Test accuracy: 97.42%, Loss: 0.07041.\n",
      "Epoch 51/300 done. Train accuracy: 98.28%, Test accuracy: 96.99%, Loss: 0.06310.\n",
      "Epoch 52/300 done. Train accuracy: 98.28%, Test accuracy: 97.20%, Loss: 0.06810.\n",
      "Epoch 53/300 done. Train accuracy: 98.44%, Test accuracy: 97.44%, Loss: 0.05610.\n",
      "Epoch 54/300 done. Train accuracy: 98.31%, Test accuracy: 97.20%, Loss: 0.05640.\n",
      "Epoch 55/300 done. Train accuracy: 98.20%, Test accuracy: 97.20%, Loss: 0.06868.\n",
      "Epoch 56/300 done. Train accuracy: 98.28%, Test accuracy: 97.11%, Loss: 0.06265.\n",
      "Epoch 57/300 done. Train accuracy: 98.33%, Test accuracy: 97.38%, Loss: 0.06056.\n",
      "Epoch 58/300 done. Train accuracy: 98.33%, Test accuracy: 97.36%, Loss: 0.05953.\n",
      "Epoch 59/300 done. Train accuracy: 98.37%, Test accuracy: 96.96%, Loss: 0.05884.\n",
      "Epoch 60/300 done. Train accuracy: 98.28%, Test accuracy: 97.29%, Loss: 0.06208.\n",
      "Epoch 61/300 done. Train accuracy: 98.40%, Test accuracy: 97.62%, Loss: 0.05579.\n",
      "Epoch 62/300 done. Train accuracy: 98.50%, Test accuracy: 97.32%, Loss: 0.05466.\n",
      "Epoch 63/300 done. Train accuracy: 98.28%, Test accuracy: 97.44%, Loss: 0.06384.\n",
      "Epoch 64/300 done. Train accuracy: 98.38%, Test accuracy: 97.59%, Loss: 0.06136.\n",
      "Epoch 65/300 done. Train accuracy: 98.53%, Test accuracy: 97.44%, Loss: 0.05581.\n",
      "Epoch 66/300 done. Train accuracy: 98.38%, Test accuracy: 97.44%, Loss: 0.05675.\n",
      "Epoch 67/300 done. Train accuracy: 98.41%, Test accuracy: 97.53%, Loss: 0.05875.\n",
      "Epoch 68/300 done. Train accuracy: 98.50%, Test accuracy: 97.50%, Loss: 0.05271.\n",
      "Epoch 69/300 done. Train accuracy: 98.33%, Test accuracy: 96.69%, Loss: 0.05760.\n",
      "Epoch 70/300 done. Train accuracy: 98.43%, Test accuracy: 97.08%, Loss: 0.05379.\n",
      "Epoch 71/300 done. Train accuracy: 98.50%, Test accuracy: 97.20%, Loss: 0.05612.\n",
      "Epoch 72/300 done. Train accuracy: 98.47%, Test accuracy: 97.17%, Loss: 0.05408.\n",
      "Epoch 73/300 done. Train accuracy: 98.45%, Test accuracy: 97.53%, Loss: 0.05450.\n",
      "Epoch 74/300 done. Train accuracy: 98.43%, Test accuracy: 97.35%, Loss: 0.05555.\n",
      "Epoch 75/300 done. Train accuracy: 98.62%, Test accuracy: 97.90%, Loss: 0.04917.\n",
      "Epoch 76/300 done. Train accuracy: 98.56%, Test accuracy: 97.38%, Loss: 0.05382.\n",
      "Epoch 77/300 done. Train accuracy: 98.61%, Test accuracy: 97.47%, Loss: 0.05201.\n",
      "Epoch 78/300 done. Train accuracy: 98.62%, Test accuracy: 97.47%, Loss: 0.04868.\n",
      "Epoch 79/300 done. Train accuracy: 98.69%, Test accuracy: 97.20%, Loss: 0.04721.\n",
      "Epoch 80/300 done. Train accuracy: 98.32%, Test accuracy: 97.26%, Loss: 0.05593.\n",
      "Epoch 81/300 done. Train accuracy: 98.37%, Test accuracy: 97.32%, Loss: 0.05564.\n",
      "Epoch 82/300 done. Train accuracy: 98.33%, Test accuracy: 97.29%, Loss: 0.05851.\n",
      "Epoch 83/300 done. Train accuracy: 98.38%, Test accuracy: 97.44%, Loss: 0.05283.\n",
      "Epoch 84/300 done. Train accuracy: 98.70%, Test accuracy: 97.56%, Loss: 0.04930.\n",
      "Epoch 85/300 done. Train accuracy: 98.49%, Test accuracy: 97.47%, Loss: 0.05262.\n",
      "Epoch 86/300 done. Train accuracy: 98.56%, Test accuracy: 97.17%, Loss: 0.04846.\n",
      "Epoch 87/300 done. Train accuracy: 98.54%, Test accuracy: 97.59%, Loss: 0.05283.\n",
      "Epoch 88/300 done. Train accuracy: 98.38%, Test accuracy: 97.26%, Loss: 0.05820.\n",
      "Epoch 89/300 done. Train accuracy: 98.47%, Test accuracy: 97.81%, Loss: 0.05126.\n",
      "Epoch 90/300 done. Train accuracy: 98.57%, Test accuracy: 97.41%, Loss: 0.05138.\n",
      "Epoch 91/300 done. Train accuracy: 98.54%, Test accuracy: 97.05%, Loss: 0.05056.\n",
      "Epoch 92/300 done. Train accuracy: 98.58%, Test accuracy: 97.56%, Loss: 0.05073.\n",
      "Epoch 93/300 done. Train accuracy: 98.54%, Test accuracy: 97.62%, Loss: 0.05412.\n",
      "Epoch 94/300 done. Train accuracy: 98.58%, Test accuracy: 97.41%, Loss: 0.05103.\n",
      "Epoch 95/300 done. Train accuracy: 98.51%, Test accuracy: 97.50%, Loss: 0.05052.\n",
      "Epoch 96/300 done. Train accuracy: 98.58%, Test accuracy: 97.05%, Loss: 0.05027.\n",
      "Epoch 97/300 done. Train accuracy: 98.61%, Test accuracy: 97.50%, Loss: 0.04916.\n",
      "Epoch 98/300 done. Train accuracy: 98.58%, Test accuracy: 97.26%, Loss: 0.05315.\n",
      "Epoch 99/300 done. Train accuracy: 98.55%, Test accuracy: 97.29%, Loss: 0.05108.\n",
      "Epoch 100/300 done. Train accuracy: 98.59%, Test accuracy: 97.32%, Loss: 0.05009.\n",
      "Epoch 101/300 done. Train accuracy: 98.54%, Test accuracy: 97.30%, Loss: 0.05163.\n",
      "Epoch 102/300 done. Train accuracy: 98.54%, Test accuracy: 97.05%, Loss: 0.05060.\n",
      "Epoch 103/300 done. Train accuracy: 98.60%, Test accuracy: 97.20%, Loss: 0.04946.\n",
      "Epoch 104/300 done. Train accuracy: 98.61%, Test accuracy: 97.66%, Loss: 0.05162.\n",
      "Epoch 105/300 done. Train accuracy: 98.43%, Test accuracy: 97.14%, Loss: 0.05700.\n",
      "Epoch 106/300 done. Train accuracy: 98.62%, Test accuracy: 97.68%, Loss: 0.04714.\n",
      "Epoch 107/300 done. Train accuracy: 98.63%, Test accuracy: 97.66%, Loss: 0.05142.\n",
      "Epoch 108/300 done. Train accuracy: 98.73%, Test accuracy: 97.50%, Loss: 0.04598.\n",
      "Epoch 109/300 done. Train accuracy: 98.66%, Test accuracy: 97.56%, Loss: 0.04795.\n",
      "Epoch 110/300 done. Train accuracy: 98.64%, Test accuracy: 97.50%, Loss: 0.04773.\n",
      "Epoch 111/300 done. Train accuracy: 98.71%, Test accuracy: 97.47%, Loss: 0.04682.\n",
      "Epoch 112/300 done. Train accuracy: 98.59%, Test accuracy: 97.59%, Loss: 0.05092.\n",
      "Epoch 113/300 done. Train accuracy: 98.60%, Test accuracy: 97.35%, Loss: 0.05148.\n",
      "Epoch 114/300 done. Train accuracy: 98.67%, Test accuracy: 97.20%, Loss: 0.04771.\n",
      "Epoch 115/300 done. Train accuracy: 98.68%, Test accuracy: 97.42%, Loss: 0.04758.\n",
      "Epoch 116/300 done. Train accuracy: 98.68%, Test accuracy: 96.99%, Loss: 0.04600.\n",
      "Epoch 117/300 done. Train accuracy: 98.49%, Test accuracy: 97.32%, Loss: 0.05429.\n",
      "Epoch 118/300 done. Train accuracy: 98.59%, Test accuracy: 97.29%, Loss: 0.04801.\n",
      "Epoch 119/300 done. Train accuracy: 98.50%, Test accuracy: 97.17%, Loss: 0.05120.\n",
      "Epoch 120/300 done. Train accuracy: 98.70%, Test accuracy: 97.59%, Loss: 0.04704.\n",
      "Epoch 121/300 done. Train accuracy: 98.63%, Test accuracy: 97.59%, Loss: 0.04711.\n",
      "Epoch 122/300 done. Train accuracy: 98.67%, Test accuracy: 97.47%, Loss: 0.04749.\n",
      "Epoch 123/300 done. Train accuracy: 98.55%, Test accuracy: 97.47%, Loss: 0.04977.\n",
      "Epoch 124/300 done. Train accuracy: 98.64%, Test accuracy: 97.35%, Loss: 0.04631.\n",
      "Epoch 125/300 done. Train accuracy: 98.70%, Test accuracy: 97.56%, Loss: 0.04633.\n",
      "Epoch 126/300 done. Train accuracy: 98.70%, Test accuracy: 97.65%, Loss: 0.04498.\n",
      "Epoch 127/300 done. Train accuracy: 98.77%, Test accuracy: 97.35%, Loss: 0.04377.\n",
      "Epoch 128/300 done. Train accuracy: 98.57%, Test accuracy: 97.41%, Loss: 0.05127.\n",
      "Epoch 129/300 done. Train accuracy: 98.58%, Test accuracy: 97.53%, Loss: 0.05037.\n",
      "Epoch 130/300 done. Train accuracy: 98.56%, Test accuracy: 97.41%, Loss: 0.05096.\n",
      "Epoch 131/300 done. Train accuracy: 98.62%, Test accuracy: 97.36%, Loss: 0.04857.\n",
      "Epoch 132/300 done. Train accuracy: 98.59%, Test accuracy: 97.05%, Loss: 0.04963.\n",
      "Epoch 133/300 done. Train accuracy: 98.70%, Test accuracy: 97.29%, Loss: 0.04640.\n",
      "Epoch 134/300 done. Train accuracy: 98.58%, Test accuracy: 97.26%, Loss: 0.04924.\n",
      "Epoch 135/300 done. Train accuracy: 98.68%, Test accuracy: 97.26%, Loss: 0.04695.\n",
      "Epoch 136/300 done. Train accuracy: 98.59%, Test accuracy: 97.32%, Loss: 0.05148.\n",
      "Epoch 137/300 done. Train accuracy: 98.67%, Test accuracy: 97.18%, Loss: 0.04638.\n",
      "Epoch 138/300 done. Train accuracy: 98.66%, Test accuracy: 97.02%, Loss: 0.04597.\n",
      "Epoch 139/300 done. Train accuracy: 98.66%, Test accuracy: 97.17%, Loss: 0.04686.\n",
      "Epoch 140/300 done. Train accuracy: 98.64%, Test accuracy: 97.20%, Loss: 0.04570.\n",
      "Epoch 141/300 done. Train accuracy: 98.66%, Test accuracy: 97.30%, Loss: 0.04663.\n",
      "Epoch 142/300 done. Train accuracy: 98.66%, Test accuracy: 97.17%, Loss: 0.04657.\n",
      "Epoch 143/300 done. Train accuracy: 98.64%, Test accuracy: 97.48%, Loss: 0.04865.\n",
      "Epoch 144/300 done. Train accuracy: 98.78%, Test accuracy: 97.62%, Loss: 0.04425.\n",
      "Epoch 145/300 done. Train accuracy: 98.74%, Test accuracy: 97.11%, Loss: 0.04427.\n",
      "Epoch 146/300 done. Train accuracy: 98.70%, Test accuracy: 97.20%, Loss: 0.04540.\n",
      "Epoch 147/300 done. Train accuracy: 98.70%, Test accuracy: 97.41%, Loss: 0.04610.\n",
      "Epoch 148/300 done. Train accuracy: 98.62%, Test accuracy: 97.23%, Loss: 0.04836.\n",
      "Epoch 149/300 done. Train accuracy: 98.70%, Test accuracy: 97.32%, Loss: 0.04445.\n",
      "Epoch 150/300 done. Train accuracy: 98.62%, Test accuracy: 97.41%, Loss: 0.04809.\n",
      "Epoch 151/300 done. Train accuracy: 98.64%, Test accuracy: 97.62%, Loss: 0.04572.\n",
      "Epoch 152/300 done. Train accuracy: 98.69%, Test accuracy: 97.56%, Loss: 0.04796.\n",
      "Epoch 153/300 done. Train accuracy: 98.76%, Test accuracy: 97.20%, Loss: 0.04392.\n",
      "Epoch 154/300 done. Train accuracy: 98.80%, Test accuracy: 97.35%, Loss: 0.04301.\n",
      "Epoch 155/300 done. Train accuracy: 98.74%, Test accuracy: 97.38%, Loss: 0.04342.\n",
      "Epoch 156/300 done. Train accuracy: 98.76%, Test accuracy: 97.50%, Loss: 0.04478.\n",
      "Epoch 157/300 done. Train accuracy: 98.71%, Test accuracy: 97.41%, Loss: 0.04384.\n",
      "Epoch 158/300 done. Train accuracy: 98.71%, Test accuracy: 97.24%, Loss: 0.04527.\n",
      "Epoch 159/300 done. Train accuracy: 98.60%, Test accuracy: 97.44%, Loss: 0.04536.\n",
      "Epoch 160/300 done. Train accuracy: 98.74%, Test accuracy: 97.14%, Loss: 0.04381.\n",
      "Epoch 161/300 done. Train accuracy: 98.70%, Test accuracy: 97.68%, Loss: 0.04503.\n",
      "Epoch 162/300 done. Train accuracy: 98.69%, Test accuracy: 97.44%, Loss: 0.04573.\n",
      "Epoch 163/300 done. Train accuracy: 98.69%, Test accuracy: 97.18%, Loss: 0.04474.\n",
      "Epoch 164/300 done. Train accuracy: 98.70%, Test accuracy: 97.08%, Loss: 0.04434.\n",
      "Epoch 165/300 done. Train accuracy: 98.71%, Test accuracy: 97.23%, Loss: 0.04362.\n",
      "Epoch 166/300 done. Train accuracy: 98.79%, Test accuracy: 97.17%, Loss: 0.04285.\n",
      "Epoch 167/300 done. Train accuracy: 98.74%, Test accuracy: 96.87%, Loss: 0.04479.\n",
      "Epoch 168/300 done. Train accuracy: 98.70%, Test accuracy: 97.26%, Loss: 0.04383.\n",
      "Epoch 169/300 done. Train accuracy: 98.70%, Test accuracy: 97.23%, Loss: 0.04608.\n",
      "Epoch 170/300 done. Train accuracy: 98.76%, Test accuracy: 97.14%, Loss: 0.04400.\n",
      "Epoch 171/300 done. Train accuracy: 98.73%, Test accuracy: 97.20%, Loss: 0.04441.\n",
      "Epoch 172/300 done. Train accuracy: 98.68%, Test accuracy: 97.47%, Loss: 0.04576.\n",
      "Epoch 173/300 done. Train accuracy: 98.63%, Test accuracy: 97.50%, Loss: 0.04671.\n",
      "Epoch 174/300 done. Train accuracy: 98.69%, Test accuracy: 97.20%, Loss: 0.04477.\n",
      "Epoch 175/300 done. Train accuracy: 98.66%, Test accuracy: 97.20%, Loss: 0.04674.\n",
      "Epoch 176/300 done. Train accuracy: 98.77%, Test accuracy: 97.11%, Loss: 0.04349.\n",
      "Epoch 177/300 done. Train accuracy: 98.71%, Test accuracy: 97.26%, Loss: 0.04569.\n",
      "Epoch 178/300 done. Train accuracy: 98.69%, Test accuracy: 97.29%, Loss: 0.04522.\n",
      "Epoch 179/300 done. Train accuracy: 98.70%, Test accuracy: 96.90%, Loss: 0.04356.\n",
      "Epoch 180/300 done. Train accuracy: 98.70%, Test accuracy: 97.17%, Loss: 0.04620.\n",
      "Epoch 181/300 done. Train accuracy: 98.69%, Test accuracy: 97.29%, Loss: 0.04503.\n",
      "Epoch 182/300 done. Train accuracy: 98.83%, Test accuracy: 97.47%, Loss: 0.04144.\n",
      "Epoch 183/300 done. Train accuracy: 98.79%, Test accuracy: 97.56%, Loss: 0.04186.\n",
      "Epoch 184/300 done. Train accuracy: 98.76%, Test accuracy: 97.47%, Loss: 0.04257.\n",
      "Epoch 185/300 done. Train accuracy: 98.66%, Test accuracy: 97.41%, Loss: 0.04670.\n",
      "Epoch 186/300 done. Train accuracy: 98.80%, Test accuracy: 97.29%, Loss: 0.04309.\n",
      "Epoch 187/300 done. Train accuracy: 98.71%, Test accuracy: 97.17%, Loss: 0.04466.\n",
      "Epoch 188/300 done. Train accuracy: 98.73%, Test accuracy: 97.42%, Loss: 0.04277.\n",
      "Epoch 189/300 done. Train accuracy: 98.56%, Test accuracy: 96.99%, Loss: 0.04807.\n",
      "Epoch 190/300 done. Train accuracy: 98.61%, Test accuracy: 97.02%, Loss: 0.04782.\n",
      "Epoch 191/300 done. Train accuracy: 98.68%, Test accuracy: 97.50%, Loss: 0.04477.\n",
      "Epoch 192/300 done. Train accuracy: 98.81%, Test accuracy: 97.20%, Loss: 0.04203.\n",
      "Epoch 193/300 done. Train accuracy: 98.77%, Test accuracy: 97.11%, Loss: 0.04240.\n",
      "Epoch 194/300 done. Train accuracy: 98.82%, Test accuracy: 97.02%, Loss: 0.04168.\n",
      "Epoch 195/300 done. Train accuracy: 98.78%, Test accuracy: 97.59%, Loss: 0.04200.\n",
      "Epoch 196/300 done. Train accuracy: 98.74%, Test accuracy: 97.29%, Loss: 0.04328.\n",
      "Epoch 197/300 done. Train accuracy: 98.73%, Test accuracy: 97.23%, Loss: 0.04350.\n",
      "Epoch 198/300 done. Train accuracy: 98.65%, Test accuracy: 97.32%, Loss: 0.04426.\n",
      "Epoch 199/300 done. Train accuracy: 98.62%, Test accuracy: 97.54%, Loss: 0.04811.\n",
      "Epoch 200/300 done. Train accuracy: 98.66%, Test accuracy: 97.29%, Loss: 0.04556.\n",
      "Epoch 201/300 done. Train accuracy: 98.76%, Test accuracy: 97.54%, Loss: 0.04341.\n",
      "Epoch 202/300 done. Train accuracy: 98.73%, Test accuracy: 97.23%, Loss: 0.04313.\n",
      "Epoch 203/300 done. Train accuracy: 98.74%, Test accuracy: 97.32%, Loss: 0.04317.\n",
      "Epoch 204/300 done. Train accuracy: 98.71%, Test accuracy: 97.38%, Loss: 0.04383.\n",
      "Epoch 205/300 done. Train accuracy: 98.63%, Test accuracy: 97.05%, Loss: 0.04551.\n",
      "Epoch 206/300 done. Train accuracy: 98.73%, Test accuracy: 97.42%, Loss: 0.04373.\n",
      "Epoch 207/300 done. Train accuracy: 98.69%, Test accuracy: 97.29%, Loss: 0.04542.\n",
      "Epoch 208/300 done. Train accuracy: 98.71%, Test accuracy: 97.42%, Loss: 0.04414.\n",
      "Epoch 209/300 done. Train accuracy: 98.70%, Test accuracy: 97.35%, Loss: 0.04398.\n",
      "Epoch 210/300 done. Train accuracy: 98.72%, Test accuracy: 96.96%, Loss: 0.04309.\n",
      "Epoch 211/300 done. Train accuracy: 98.69%, Test accuracy: 97.14%, Loss: 0.04554.\n",
      "Epoch 212/300 done. Train accuracy: 98.75%, Test accuracy: 96.87%, Loss: 0.04292.\n",
      "Epoch 213/300 done. Train accuracy: 98.63%, Test accuracy: 97.20%, Loss: 0.04748.\n",
      "Epoch 214/300 done. Train accuracy: 98.77%, Test accuracy: 97.53%, Loss: 0.04218.\n",
      "Epoch 215/300 done. Train accuracy: 98.73%, Test accuracy: 97.38%, Loss: 0.04292.\n",
      "Epoch 216/300 done. Train accuracy: 98.66%, Test accuracy: 97.35%, Loss: 0.04464.\n",
      "Epoch 217/300 done. Train accuracy: 98.77%, Test accuracy: 96.99%, Loss: 0.04342.\n",
      "Epoch 218/300 done. Train accuracy: 98.71%, Test accuracy: 97.44%, Loss: 0.04317.\n",
      "Epoch 219/300 done. Train accuracy: 98.81%, Test accuracy: 97.05%, Loss: 0.04234.\n",
      "Epoch 220/300 done. Train accuracy: 98.78%, Test accuracy: 97.14%, Loss: 0.04174.\n",
      "Epoch 221/300 done. Train accuracy: 98.70%, Test accuracy: 97.02%, Loss: 0.04441.\n",
      "Epoch 222/300 done. Train accuracy: 98.64%, Test accuracy: 97.17%, Loss: 0.04630.\n",
      "Epoch 223/300 done. Train accuracy: 98.65%, Test accuracy: 97.35%, Loss: 0.04642.\n",
      "Epoch 224/300 done. Train accuracy: 98.74%, Test accuracy: 97.11%, Loss: 0.04277.\n",
      "Epoch 225/300 done. Train accuracy: 98.72%, Test accuracy: 97.14%, Loss: 0.04431.\n",
      "Epoch 226/300 done. Train accuracy: 98.73%, Test accuracy: 97.35%, Loss: 0.04313.\n",
      "Epoch 227/300 done. Train accuracy: 98.66%, Test accuracy: 96.93%, Loss: 0.04459.\n",
      "Epoch 228/300 done. Train accuracy: 98.81%, Test accuracy: 97.08%, Loss: 0.04139.\n",
      "Epoch 229/300 done. Train accuracy: 98.80%, Test accuracy: 97.12%, Loss: 0.04182.\n",
      "Epoch 230/300 done. Train accuracy: 98.74%, Test accuracy: 97.23%, Loss: 0.04511.\n",
      "Epoch 231/300 done. Train accuracy: 98.78%, Test accuracy: 97.12%, Loss: 0.04277.\n",
      "Epoch 232/300 done. Train accuracy: 98.69%, Test accuracy: 97.18%, Loss: 0.04428.\n",
      "Epoch 233/300 done. Train accuracy: 98.71%, Test accuracy: 96.75%, Loss: 0.04540.\n",
      "Epoch 234/300 done. Train accuracy: 98.76%, Test accuracy: 96.84%, Loss: 0.04552.\n",
      "Epoch 235/300 done. Train accuracy: 98.66%, Test accuracy: 96.93%, Loss: 0.04534.\n",
      "Epoch 236/300 done. Train accuracy: 98.67%, Test accuracy: 97.20%, Loss: 0.04463.\n",
      "Epoch 237/300 done. Train accuracy: 98.72%, Test accuracy: 97.23%, Loss: 0.04489.\n",
      "Epoch 238/300 done. Train accuracy: 98.65%, Test accuracy: 97.32%, Loss: 0.04603.\n",
      "Epoch 239/300 done. Train accuracy: 98.73%, Test accuracy: 97.23%, Loss: 0.04362.\n",
      "Epoch 240/300 done. Train accuracy: 98.76%, Test accuracy: 96.87%, Loss: 0.04284.\n",
      "Epoch 241/300 done. Train accuracy: 98.69%, Test accuracy: 96.90%, Loss: 0.04477.\n",
      "Epoch 242/300 done. Train accuracy: 98.70%, Test accuracy: 96.87%, Loss: 0.04404.\n",
      "Epoch 243/300 done. Train accuracy: 98.81%, Test accuracy: 97.17%, Loss: 0.04139.\n",
      "Epoch 244/300 done. Train accuracy: 98.77%, Test accuracy: 97.17%, Loss: 0.04248.\n",
      "Epoch 245/300 done. Train accuracy: 98.73%, Test accuracy: 96.75%, Loss: 0.04407.\n",
      "Epoch 246/300 done. Train accuracy: 98.72%, Test accuracy: 97.29%, Loss: 0.04289.\n",
      "Epoch 247/300 done. Train accuracy: 98.65%, Test accuracy: 97.11%, Loss: 0.04630.\n",
      "Epoch 248/300 done. Train accuracy: 98.69%, Test accuracy: 96.84%, Loss: 0.04482.\n",
      "Epoch 249/300 done. Train accuracy: 98.78%, Test accuracy: 97.35%, Loss: 0.04175.\n",
      "Epoch 250/300 done. Train accuracy: 98.80%, Test accuracy: 97.14%, Loss: 0.04194.\n",
      "Epoch 251/300 done. Train accuracy: 98.79%, Test accuracy: 97.12%, Loss: 0.04190.\n",
      "Epoch 252/300 done. Train accuracy: 98.64%, Test accuracy: 97.66%, Loss: 0.04631.\n",
      "Epoch 253/300 done. Train accuracy: 98.76%, Test accuracy: 97.05%, Loss: 0.04253.\n",
      "Epoch 254/300 done. Train accuracy: 98.70%, Test accuracy: 97.11%, Loss: 0.04457.\n",
      "Epoch 255/300 done. Train accuracy: 98.73%, Test accuracy: 97.29%, Loss: 0.04286.\n",
      "Epoch 256/300 done. Train accuracy: 98.68%, Test accuracy: 97.08%, Loss: 0.04314.\n",
      "Epoch 257/300 done. Train accuracy: 98.77%, Test accuracy: 97.17%, Loss: 0.04275.\n",
      "Epoch 258/300 done. Train accuracy: 98.68%, Test accuracy: 97.05%, Loss: 0.04408.\n",
      "Epoch 259/300 done. Train accuracy: 98.82%, Test accuracy: 97.26%, Loss: 0.04101.\n",
      "Epoch 260/300 done. Train accuracy: 98.72%, Test accuracy: 97.41%, Loss: 0.04345.\n",
      "Epoch 261/300 done. Train accuracy: 98.73%, Test accuracy: 97.11%, Loss: 0.04358.\n",
      "Epoch 262/300 done. Train accuracy: 98.66%, Test accuracy: 96.93%, Loss: 0.04551.\n",
      "Epoch 263/300 done. Train accuracy: 98.66%, Test accuracy: 97.23%, Loss: 0.04523.\n",
      "Epoch 264/300 done. Train accuracy: 98.57%, Test accuracy: 97.26%, Loss: 0.04783.\n",
      "Epoch 265/300 done. Train accuracy: 98.82%, Test accuracy: 97.08%, Loss: 0.04186.\n",
      "Epoch 266/300 done. Train accuracy: 98.70%, Test accuracy: 96.78%, Loss: 0.04393.\n",
      "Epoch 267/300 done. Train accuracy: 98.75%, Test accuracy: 96.78%, Loss: 0.04261.\n",
      "Epoch 268/300 done. Train accuracy: 98.73%, Test accuracy: 97.48%, Loss: 0.04328.\n",
      "Epoch 269/300 done. Train accuracy: 98.71%, Test accuracy: 97.14%, Loss: 0.04345.\n",
      "Epoch 270/300 done. Train accuracy: 98.65%, Test accuracy: 97.20%, Loss: 0.04469.\n",
      "Epoch 271/300 done. Train accuracy: 98.75%, Test accuracy: 96.93%, Loss: 0.04407.\n",
      "Epoch 272/300 done. Train accuracy: 98.70%, Test accuracy: 97.29%, Loss: 0.04370.\n",
      "Epoch 273/300 done. Train accuracy: 98.74%, Test accuracy: 96.57%, Loss: 0.04269.\n",
      "Epoch 274/300 done. Train accuracy: 98.70%, Test accuracy: 96.51%, Loss: 0.04434.\n",
      "Epoch 275/300 done. Train accuracy: 98.69%, Test accuracy: 96.87%, Loss: 0.04783.\n",
      "Epoch 276/300 done. Train accuracy: 98.71%, Test accuracy: 96.77%, Loss: 0.04445.\n",
      "Epoch 277/300 done. Train accuracy: 98.77%, Test accuracy: 97.12%, Loss: 0.04265.\n",
      "Epoch 278/300 done. Train accuracy: 98.70%, Test accuracy: 97.29%, Loss: 0.04451.\n",
      "Epoch 279/300 done. Train accuracy: 98.75%, Test accuracy: 96.87%, Loss: 0.04318.\n",
      "Epoch 280/300 done. Train accuracy: 98.74%, Test accuracy: 96.90%, Loss: 0.04389.\n",
      "Epoch 281/300 done. Train accuracy: 98.70%, Test accuracy: 97.05%, Loss: 0.04488.\n",
      "Epoch 282/300 done. Train accuracy: 98.62%, Test accuracy: 97.35%, Loss: 0.04567.\n",
      "Epoch 283/300 done. Train accuracy: 98.73%, Test accuracy: 97.08%, Loss: 0.04316.\n",
      "Epoch 284/300 done. Train accuracy: 98.57%, Test accuracy: 96.87%, Loss: 0.04602.\n",
      "Epoch 285/300 done. Train accuracy: 98.65%, Test accuracy: 97.23%, Loss: 0.04494.\n",
      "Epoch 286/300 done. Train accuracy: 98.70%, Test accuracy: 96.87%, Loss: 0.04369.\n",
      "Epoch 287/300 done. Train accuracy: 98.79%, Test accuracy: 97.42%, Loss: 0.04138.\n",
      "Epoch 288/300 done. Train accuracy: 98.77%, Test accuracy: 97.50%, Loss: 0.04203.\n",
      "Epoch 289/300 done. Train accuracy: 98.63%, Test accuracy: 96.51%, Loss: 0.04697.\n",
      "Epoch 290/300 done. Train accuracy: 98.77%, Test accuracy: 97.29%, Loss: 0.04292.\n",
      "Epoch 291/300 done. Train accuracy: 98.74%, Test accuracy: 97.14%, Loss: 0.04296.\n",
      "Epoch 292/300 done. Train accuracy: 98.74%, Test accuracy: 97.20%, Loss: 0.04390.\n",
      "Epoch 293/300 done. Train accuracy: 98.76%, Test accuracy: 97.44%, Loss: 0.04207.\n",
      "Epoch 294/300 done. Train accuracy: 98.64%, Test accuracy: 96.81%, Loss: 0.04410.\n",
      "Epoch 295/300 done. Train accuracy: 98.74%, Test accuracy: 96.90%, Loss: 0.04537.\n",
      "Epoch 296/300 done. Train accuracy: 98.69%, Test accuracy: 96.84%, Loss: 0.04495.\n",
      "Epoch 297/300 done. Train accuracy: 98.72%, Test accuracy: 96.66%, Loss: 0.04436.\n",
      "Epoch 298/300 done. Train accuracy: 98.73%, Test accuracy: 96.99%, Loss: 0.04280.\n",
      "Epoch 299/300 done. Train accuracy: 98.66%, Test accuracy: 97.24%, Loss: 0.04489.\n",
      "Epoch 300/300 done. Train accuracy: 98.64%, Test accuracy: 97.08%, Loss: 0.04749.\n",
      "Final results: \n",
      "Best training accuracy: 98.83% and according test accuracy: 97.47% at epoch: 182\n",
      "Best test accuracy: 97.90% and according train accuracy: 98.62% at epoch: 75\n",
      "------------------------------------------------------------------------------------\n",
      "\n",
      "Epoch 1/300 done. Train accuracy: 10.62%, Test accuracy: 17.96%, Loss: 22.29177.\n",
      "Epoch 2/300 done. Train accuracy: 23.60%, Test accuracy: 35.61%, Loss: 8.10813.\n",
      "Epoch 3/300 done. Train accuracy: 39.31%, Test accuracy: 56.56%, Loss: 2.78275.\n",
      "Epoch 4/300 done. Train accuracy: 51.67%, Test accuracy: 65.98%, Loss: 2.10159.\n",
      "Epoch 5/300 done. Train accuracy: 67.33%, Test accuracy: 78.31%, Loss: 1.13176.\n",
      "Epoch 6/300 done. Train accuracy: 76.51%, Test accuracy: 85.71%, Loss: 0.84299.\n",
      "Epoch 7/300 done. Train accuracy: 80.72%, Test accuracy: 89.14%, Loss: 0.73500.\n",
      "Epoch 8/300 done. Train accuracy: 85.95%, Test accuracy: 91.28%, Loss: 0.47771.\n",
      "Epoch 9/300 done. Train accuracy: 88.41%, Test accuracy: 93.57%, Loss: 0.47020.\n",
      "Epoch 10/300 done. Train accuracy: 89.54%, Test accuracy: 93.62%, Loss: 0.39987.\n",
      "Epoch 11/300 done. Train accuracy: 91.44%, Test accuracy: 94.65%, Loss: 0.31750.\n",
      "Epoch 12/300 done. Train accuracy: 92.67%, Test accuracy: 95.07%, Loss: 0.26118.\n",
      "Epoch 13/300 done. Train accuracy: 94.00%, Test accuracy: 95.49%, Loss: 0.21683.\n",
      "Epoch 14/300 done. Train accuracy: 93.86%, Test accuracy: 95.64%, Loss: 0.22574.\n",
      "Epoch 15/300 done. Train accuracy: 94.92%, Test accuracy: 95.52%, Loss: 0.18003.\n",
      "Epoch 16/300 done. Train accuracy: 95.90%, Test accuracy: 95.18%, Loss: 0.14803.\n",
      "Epoch 17/300 done. Train accuracy: 95.82%, Test accuracy: 96.09%, Loss: 0.17579.\n",
      "Epoch 18/300 done. Train accuracy: 95.78%, Test accuracy: 96.27%, Loss: 0.15546.\n",
      "Epoch 19/300 done. Train accuracy: 96.12%, Test accuracy: 96.36%, Loss: 0.14432.\n",
      "Epoch 20/300 done. Train accuracy: 96.05%, Test accuracy: 96.33%, Loss: 0.16467.\n",
      "Epoch 21/300 done. Train accuracy: 96.41%, Test accuracy: 96.81%, Loss: 0.13510.\n",
      "Epoch 22/300 done. Train accuracy: 96.39%, Test accuracy: 96.39%, Loss: 0.14580.\n",
      "Epoch 23/300 done. Train accuracy: 96.27%, Test accuracy: 96.84%, Loss: 0.17713.\n",
      "Epoch 24/300 done. Train accuracy: 97.01%, Test accuracy: 96.63%, Loss: 0.11541.\n",
      "Epoch 25/300 done. Train accuracy: 97.18%, Test accuracy: 96.41%, Loss: 0.10438.\n",
      "Epoch 26/300 done. Train accuracy: 97.43%, Test accuracy: 97.41%, Loss: 0.10125.\n",
      "Epoch 27/300 done. Train accuracy: 97.37%, Test accuracy: 96.84%, Loss: 0.10823.\n",
      "Epoch 28/300 done. Train accuracy: 96.99%, Test accuracy: 97.60%, Loss: 0.13411.\n",
      "Epoch 29/300 done. Train accuracy: 96.52%, Test accuracy: 96.63%, Loss: 0.16712.\n",
      "Epoch 30/300 done. Train accuracy: 97.38%, Test accuracy: 97.35%, Loss: 0.10192.\n",
      "Epoch 31/300 done. Train accuracy: 97.52%, Test accuracy: 97.35%, Loss: 0.09490.\n",
      "Epoch 32/300 done. Train accuracy: 97.56%, Test accuracy: 97.17%, Loss: 0.09657.\n",
      "Epoch 33/300 done. Train accuracy: 97.82%, Test accuracy: 96.93%, Loss: 0.08177.\n",
      "Epoch 34/300 done. Train accuracy: 97.95%, Test accuracy: 97.26%, Loss: 0.07580.\n",
      "Epoch 35/300 done. Train accuracy: 97.98%, Test accuracy: 97.23%, Loss: 0.07249.\n",
      "Epoch 36/300 done. Train accuracy: 97.92%, Test accuracy: 97.41%, Loss: 0.09152.\n",
      "Epoch 37/300 done. Train accuracy: 98.12%, Test accuracy: 97.41%, Loss: 0.06805.\n",
      "Epoch 38/300 done. Train accuracy: 97.83%, Test accuracy: 97.65%, Loss: 0.07812.\n",
      "Epoch 39/300 done. Train accuracy: 98.05%, Test accuracy: 97.78%, Loss: 0.07040.\n",
      "Epoch 40/300 done. Train accuracy: 98.20%, Test accuracy: 97.53%, Loss: 0.06577.\n",
      "Epoch 41/300 done. Train accuracy: 97.33%, Test accuracy: 97.50%, Loss: 0.12702.\n",
      "Epoch 42/300 done. Train accuracy: 98.14%, Test accuracy: 97.11%, Loss: 0.07062.\n",
      "Epoch 43/300 done. Train accuracy: 98.05%, Test accuracy: 97.38%, Loss: 0.07544.\n",
      "Epoch 44/300 done. Train accuracy: 98.22%, Test accuracy: 97.56%, Loss: 0.06649.\n",
      "Epoch 45/300 done. Train accuracy: 98.55%, Test accuracy: 97.20%, Loss: 0.05349.\n",
      "Epoch 46/300 done. Train accuracy: 98.08%, Test accuracy: 97.65%, Loss: 0.07495.\n",
      "Epoch 47/300 done. Train accuracy: 98.31%, Test accuracy: 97.29%, Loss: 0.06147.\n",
      "Epoch 48/300 done. Train accuracy: 98.09%, Test accuracy: 97.08%, Loss: 0.06865.\n",
      "Epoch 49/300 done. Train accuracy: 98.28%, Test accuracy: 97.12%, Loss: 0.06235.\n",
      "Epoch 50/300 done. Train accuracy: 98.17%, Test accuracy: 97.44%, Loss: 0.07746.\n",
      "Epoch 51/300 done. Train accuracy: 98.31%, Test accuracy: 97.50%, Loss: 0.06139.\n",
      "Epoch 52/300 done. Train accuracy: 98.15%, Test accuracy: 97.20%, Loss: 0.07347.\n",
      "Epoch 53/300 done. Train accuracy: 98.43%, Test accuracy: 97.56%, Loss: 0.05696.\n",
      "Epoch 54/300 done. Train accuracy: 98.28%, Test accuracy: 97.05%, Loss: 0.06740.\n",
      "Epoch 55/300 done. Train accuracy: 98.41%, Test accuracy: 97.32%, Loss: 0.06005.\n",
      "Epoch 56/300 done. Train accuracy: 98.07%, Test accuracy: 97.35%, Loss: 0.06794.\n",
      "Epoch 57/300 done. Train accuracy: 98.25%, Test accuracy: 97.38%, Loss: 0.06758.\n",
      "Epoch 58/300 done. Train accuracy: 98.50%, Test accuracy: 97.02%, Loss: 0.05667.\n",
      "Epoch 59/300 done. Train accuracy: 98.54%, Test accuracy: 97.36%, Loss: 0.05199.\n",
      "Epoch 60/300 done. Train accuracy: 98.14%, Test accuracy: 97.72%, Loss: 0.06893.\n",
      "Epoch 61/300 done. Train accuracy: 98.36%, Test accuracy: 97.56%, Loss: 0.06160.\n",
      "Epoch 62/300 done. Train accuracy: 98.29%, Test accuracy: 97.48%, Loss: 0.06376.\n",
      "Epoch 63/300 done. Train accuracy: 98.41%, Test accuracy: 97.62%, Loss: 0.05876.\n",
      "Epoch 64/300 done. Train accuracy: 98.40%, Test accuracy: 97.72%, Loss: 0.05530.\n",
      "Epoch 65/300 done. Train accuracy: 98.54%, Test accuracy: 97.20%, Loss: 0.05064.\n",
      "Epoch 66/300 done. Train accuracy: 98.44%, Test accuracy: 96.99%, Loss: 0.05463.\n",
      "Epoch 67/300 done. Train accuracy: 98.23%, Test accuracy: 97.62%, Loss: 0.06157.\n",
      "Epoch 68/300 done. Train accuracy: 98.62%, Test accuracy: 97.47%, Loss: 0.05043.\n",
      "Epoch 69/300 done. Train accuracy: 98.30%, Test accuracy: 97.50%, Loss: 0.06181.\n",
      "Epoch 70/300 done. Train accuracy: 98.48%, Test accuracy: 97.66%, Loss: 0.05570.\n",
      "Epoch 71/300 done. Train accuracy: 98.53%, Test accuracy: 97.23%, Loss: 0.05028.\n",
      "Epoch 72/300 done. Train accuracy: 98.40%, Test accuracy: 97.50%, Loss: 0.05893.\n",
      "Epoch 73/300 done. Train accuracy: 98.64%, Test accuracy: 97.56%, Loss: 0.04862.\n",
      "Epoch 74/300 done. Train accuracy: 98.47%, Test accuracy: 97.62%, Loss: 0.05286.\n",
      "Epoch 75/300 done. Train accuracy: 98.60%, Test accuracy: 97.44%, Loss: 0.04968.\n",
      "Epoch 76/300 done. Train accuracy: 98.51%, Test accuracy: 97.60%, Loss: 0.05559.\n",
      "Epoch 77/300 done. Train accuracy: 98.59%, Test accuracy: 97.62%, Loss: 0.05121.\n",
      "Epoch 78/300 done. Train accuracy: 98.57%, Test accuracy: 97.93%, Loss: 0.05109.\n",
      "Epoch 79/300 done. Train accuracy: 98.63%, Test accuracy: 97.81%, Loss: 0.04857.\n",
      "Epoch 80/300 done. Train accuracy: 98.52%, Test accuracy: 97.56%, Loss: 0.05346.\n",
      "Epoch 81/300 done. Train accuracy: 98.44%, Test accuracy: 97.60%, Loss: 0.05390.\n",
      "Epoch 82/300 done. Train accuracy: 98.43%, Test accuracy: 97.35%, Loss: 0.05527.\n",
      "Epoch 83/300 done. Train accuracy: 98.28%, Test accuracy: 97.26%, Loss: 0.06405.\n",
      "Epoch 84/300 done. Train accuracy: 98.59%, Test accuracy: 97.68%, Loss: 0.05322.\n",
      "Epoch 85/300 done. Train accuracy: 98.59%, Test accuracy: 97.47%, Loss: 0.04956.\n",
      "Epoch 86/300 done. Train accuracy: 98.61%, Test accuracy: 97.16%, Loss: 0.05244.\n",
      "Epoch 87/300 done. Train accuracy: 98.69%, Test accuracy: 97.17%, Loss: 0.04679.\n",
      "Epoch 88/300 done. Train accuracy: 98.27%, Test accuracy: 97.35%, Loss: 0.06301.\n",
      "Epoch 89/300 done. Train accuracy: 98.67%, Test accuracy: 97.56%, Loss: 0.04886.\n",
      "Epoch 90/300 done. Train accuracy: 98.53%, Test accuracy: 97.62%, Loss: 0.05408.\n",
      "Epoch 91/300 done. Train accuracy: 98.47%, Test accuracy: 97.65%, Loss: 0.05522.\n",
      "Epoch 92/300 done. Train accuracy: 98.56%, Test accuracy: 97.71%, Loss: 0.05164.\n",
      "Epoch 93/300 done. Train accuracy: 98.66%, Test accuracy: 97.50%, Loss: 0.04799.\n",
      "Epoch 94/300 done. Train accuracy: 98.52%, Test accuracy: 97.50%, Loss: 0.05202.\n",
      "Epoch 95/300 done. Train accuracy: 98.43%, Test accuracy: 97.62%, Loss: 0.05669.\n",
      "Epoch 96/300 done. Train accuracy: 98.61%, Test accuracy: 97.59%, Loss: 0.04830.\n",
      "Epoch 97/300 done. Train accuracy: 98.54%, Test accuracy: 97.53%, Loss: 0.05085.\n",
      "Epoch 98/300 done. Train accuracy: 98.74%, Test accuracy: 97.56%, Loss: 0.04562.\n",
      "Epoch 99/300 done. Train accuracy: 98.63%, Test accuracy: 97.72%, Loss: 0.04845.\n",
      "Epoch 100/300 done. Train accuracy: 98.65%, Test accuracy: 97.47%, Loss: 0.04954.\n",
      "Epoch 101/300 done. Train accuracy: 98.60%, Test accuracy: 97.32%, Loss: 0.05203.\n",
      "Epoch 102/300 done. Train accuracy: 98.64%, Test accuracy: 97.48%, Loss: 0.04678.\n",
      "Epoch 103/300 done. Train accuracy: 98.55%, Test accuracy: 97.59%, Loss: 0.05211.\n",
      "Epoch 104/300 done. Train accuracy: 98.77%, Test accuracy: 97.87%, Loss: 0.04511.\n",
      "Epoch 105/300 done. Train accuracy: 98.58%, Test accuracy: 97.54%, Loss: 0.05094.\n",
      "Epoch 106/300 done. Train accuracy: 98.67%, Test accuracy: 97.68%, Loss: 0.04747.\n",
      "Epoch 107/300 done. Train accuracy: 98.54%, Test accuracy: 97.90%, Loss: 0.04822.\n",
      "Epoch 108/300 done. Train accuracy: 98.61%, Test accuracy: 97.56%, Loss: 0.04988.\n",
      "Epoch 109/300 done. Train accuracy: 98.73%, Test accuracy: 97.87%, Loss: 0.04948.\n",
      "Epoch 110/300 done. Train accuracy: 98.60%, Test accuracy: 97.56%, Loss: 0.04921.\n",
      "Epoch 111/300 done. Train accuracy: 98.62%, Test accuracy: 97.72%, Loss: 0.04750.\n",
      "Epoch 112/300 done. Train accuracy: 98.74%, Test accuracy: 97.59%, Loss: 0.04464.\n",
      "Epoch 113/300 done. Train accuracy: 98.70%, Test accuracy: 97.62%, Loss: 0.04630.\n",
      "Epoch 114/300 done. Train accuracy: 98.71%, Test accuracy: 97.78%, Loss: 0.04674.\n",
      "Epoch 115/300 done. Train accuracy: 98.67%, Test accuracy: 97.87%, Loss: 0.04511.\n",
      "Epoch 116/300 done. Train accuracy: 98.66%, Test accuracy: 97.62%, Loss: 0.04660.\n",
      "Epoch 117/300 done. Train accuracy: 98.67%, Test accuracy: 97.30%, Loss: 0.04587.\n",
      "Epoch 118/300 done. Train accuracy: 98.56%, Test accuracy: 97.32%, Loss: 0.05021.\n",
      "Epoch 119/300 done. Train accuracy: 98.75%, Test accuracy: 97.38%, Loss: 0.04624.\n",
      "Epoch 120/300 done. Train accuracy: 98.65%, Test accuracy: 97.35%, Loss: 0.04745.\n",
      "Epoch 121/300 done. Train accuracy: 98.65%, Test accuracy: 97.68%, Loss: 0.04694.\n",
      "Epoch 122/300 done. Train accuracy: 98.67%, Test accuracy: 97.60%, Loss: 0.04765.\n",
      "Epoch 123/300 done. Train accuracy: 98.70%, Test accuracy: 97.38%, Loss: 0.04788.\n",
      "Epoch 124/300 done. Train accuracy: 98.69%, Test accuracy: 97.56%, Loss: 0.04570.\n",
      "Epoch 125/300 done. Train accuracy: 98.59%, Test accuracy: 97.11%, Loss: 0.05001.\n",
      "Epoch 126/300 done. Train accuracy: 98.70%, Test accuracy: 97.62%, Loss: 0.04608.\n",
      "Epoch 127/300 done. Train accuracy: 98.70%, Test accuracy: 97.56%, Loss: 0.04503.\n",
      "Epoch 128/300 done. Train accuracy: 98.71%, Test accuracy: 97.20%, Loss: 0.04599.\n",
      "Epoch 129/300 done. Train accuracy: 98.74%, Test accuracy: 97.32%, Loss: 0.04508.\n",
      "Epoch 130/300 done. Train accuracy: 98.66%, Test accuracy: 97.35%, Loss: 0.04828.\n",
      "Epoch 131/300 done. Train accuracy: 98.57%, Test accuracy: 97.65%, Loss: 0.04913.\n",
      "Epoch 132/300 done. Train accuracy: 98.53%, Test accuracy: 97.56%, Loss: 0.05327.\n",
      "Epoch 133/300 done. Train accuracy: 98.47%, Test accuracy: 97.32%, Loss: 0.05228.\n",
      "Epoch 134/300 done. Train accuracy: 98.67%, Test accuracy: 97.32%, Loss: 0.04724.\n",
      "Epoch 135/300 done. Train accuracy: 98.66%, Test accuracy: 97.68%, Loss: 0.04759.\n",
      "Epoch 136/300 done. Train accuracy: 98.62%, Test accuracy: 97.32%, Loss: 0.04804.\n",
      "Epoch 137/300 done. Train accuracy: 98.70%, Test accuracy: 97.74%, Loss: 0.04555.\n",
      "Epoch 138/300 done. Train accuracy: 98.71%, Test accuracy: 97.44%, Loss: 0.04574.\n",
      "Epoch 139/300 done. Train accuracy: 98.71%, Test accuracy: 97.20%, Loss: 0.04467.\n",
      "Epoch 140/300 done. Train accuracy: 98.65%, Test accuracy: 97.53%, Loss: 0.04641.\n",
      "Epoch 141/300 done. Train accuracy: 98.70%, Test accuracy: 97.41%, Loss: 0.04387.\n",
      "Epoch 142/300 done. Train accuracy: 98.62%, Test accuracy: 97.05%, Loss: 0.04645.\n",
      "Epoch 143/300 done. Train accuracy: 98.66%, Test accuracy: 97.47%, Loss: 0.04784.\n",
      "Epoch 144/300 done. Train accuracy: 98.62%, Test accuracy: 97.41%, Loss: 0.04659.\n",
      "Epoch 145/300 done. Train accuracy: 98.73%, Test accuracy: 97.83%, Loss: 0.04382.\n",
      "Epoch 146/300 done. Train accuracy: 98.70%, Test accuracy: 97.78%, Loss: 0.04810.\n",
      "Epoch 147/300 done. Train accuracy: 98.76%, Test accuracy: 97.50%, Loss: 0.04392.\n",
      "Epoch 148/300 done. Train accuracy: 98.63%, Test accuracy: 97.74%, Loss: 0.05064.\n",
      "Epoch 149/300 done. Train accuracy: 98.75%, Test accuracy: 97.68%, Loss: 0.04416.\n",
      "Epoch 150/300 done. Train accuracy: 98.75%, Test accuracy: 97.72%, Loss: 0.04478.\n",
      "Epoch 151/300 done. Train accuracy: 98.73%, Test accuracy: 97.72%, Loss: 0.04515.\n",
      "Epoch 152/300 done. Train accuracy: 98.63%, Test accuracy: 97.44%, Loss: 0.04572.\n",
      "Epoch 153/300 done. Train accuracy: 98.70%, Test accuracy: 97.38%, Loss: 0.04489.\n",
      "Epoch 154/300 done. Train accuracy: 98.80%, Test accuracy: 97.54%, Loss: 0.04389.\n",
      "Epoch 155/300 done. Train accuracy: 98.70%, Test accuracy: 97.47%, Loss: 0.04540.\n",
      "Epoch 156/300 done. Train accuracy: 98.69%, Test accuracy: 97.62%, Loss: 0.04552.\n",
      "Epoch 157/300 done. Train accuracy: 98.64%, Test accuracy: 97.44%, Loss: 0.04593.\n",
      "Epoch 158/300 done. Train accuracy: 98.73%, Test accuracy: 97.35%, Loss: 0.04373.\n",
      "Epoch 159/300 done. Train accuracy: 98.63%, Test accuracy: 97.59%, Loss: 0.04717.\n",
      "Epoch 160/300 done. Train accuracy: 98.70%, Test accuracy: 97.08%, Loss: 0.04401.\n",
      "Epoch 161/300 done. Train accuracy: 98.67%, Test accuracy: 97.32%, Loss: 0.04511.\n",
      "Epoch 162/300 done. Train accuracy: 98.64%, Test accuracy: 97.56%, Loss: 0.04635.\n",
      "Epoch 163/300 done. Train accuracy: 98.75%, Test accuracy: 97.47%, Loss: 0.04378.\n",
      "Epoch 164/300 done. Train accuracy: 98.76%, Test accuracy: 97.44%, Loss: 0.04356.\n",
      "Epoch 165/300 done. Train accuracy: 98.70%, Test accuracy: 97.41%, Loss: 0.04548.\n",
      "Epoch 166/300 done. Train accuracy: 98.70%, Test accuracy: 97.32%, Loss: 0.04467.\n",
      "Epoch 167/300 done. Train accuracy: 98.64%, Test accuracy: 97.32%, Loss: 0.04834.\n",
      "Epoch 168/300 done. Train accuracy: 98.66%, Test accuracy: 97.32%, Loss: 0.04505.\n",
      "Epoch 169/300 done. Train accuracy: 98.65%, Test accuracy: 97.35%, Loss: 0.04599.\n",
      "Epoch 170/300 done. Train accuracy: 98.67%, Test accuracy: 97.32%, Loss: 0.04596.\n",
      "Epoch 171/300 done. Train accuracy: 98.64%, Test accuracy: 97.47%, Loss: 0.04694.\n",
      "Epoch 172/300 done. Train accuracy: 98.72%, Test accuracy: 96.96%, Loss: 0.04459.\n",
      "Epoch 173/300 done. Train accuracy: 98.71%, Test accuracy: 97.50%, Loss: 0.04371.\n",
      "Epoch 174/300 done. Train accuracy: 98.73%, Test accuracy: 97.17%, Loss: 0.04470.\n",
      "Epoch 175/300 done. Train accuracy: 98.76%, Test accuracy: 97.08%, Loss: 0.04343.\n",
      "Epoch 176/300 done. Train accuracy: 98.68%, Test accuracy: 97.23%, Loss: 0.04574.\n",
      "Epoch 177/300 done. Train accuracy: 98.73%, Test accuracy: 97.24%, Loss: 0.04734.\n",
      "Epoch 178/300 done. Train accuracy: 98.70%, Test accuracy: 97.59%, Loss: 0.04476.\n",
      "Epoch 179/300 done. Train accuracy: 98.72%, Test accuracy: 97.08%, Loss: 0.04457.\n",
      "Epoch 180/300 done. Train accuracy: 98.72%, Test accuracy: 97.24%, Loss: 0.04533.\n",
      "Epoch 181/300 done. Train accuracy: 98.73%, Test accuracy: 97.23%, Loss: 0.04389.\n",
      "Epoch 182/300 done. Train accuracy: 98.77%, Test accuracy: 97.17%, Loss: 0.04263.\n",
      "Epoch 183/300 done. Train accuracy: 98.69%, Test accuracy: 97.14%, Loss: 0.04481.\n",
      "Epoch 184/300 done. Train accuracy: 98.70%, Test accuracy: 97.05%, Loss: 0.04515.\n",
      "Epoch 185/300 done. Train accuracy: 98.65%, Test accuracy: 97.38%, Loss: 0.04541.\n",
      "Epoch 186/300 done. Train accuracy: 98.74%, Test accuracy: 97.02%, Loss: 0.04378.\n",
      "Epoch 187/300 done. Train accuracy: 98.63%, Test accuracy: 97.14%, Loss: 0.04720.\n",
      "Epoch 188/300 done. Train accuracy: 98.77%, Test accuracy: 97.02%, Loss: 0.04298.\n",
      "Epoch 189/300 done. Train accuracy: 98.69%, Test accuracy: 97.29%, Loss: 0.04577.\n",
      "Epoch 190/300 done. Train accuracy: 98.70%, Test accuracy: 97.32%, Loss: 0.04401.\n",
      "Epoch 191/300 done. Train accuracy: 98.84%, Test accuracy: 97.47%, Loss: 0.04253.\n",
      "Epoch 192/300 done. Train accuracy: 98.69%, Test accuracy: 97.20%, Loss: 0.04734.\n",
      "Epoch 193/300 done. Train accuracy: 98.73%, Test accuracy: 97.38%, Loss: 0.04496.\n",
      "Epoch 194/300 done. Train accuracy: 98.61%, Test accuracy: 97.44%, Loss: 0.04782.\n",
      "Epoch 195/300 done. Train accuracy: 98.67%, Test accuracy: 97.11%, Loss: 0.04636.\n",
      "Epoch 196/300 done. Train accuracy: 98.73%, Test accuracy: 97.29%, Loss: 0.04424.\n",
      "Epoch 197/300 done. Train accuracy: 98.76%, Test accuracy: 97.44%, Loss: 0.04619.\n",
      "Epoch 198/300 done. Train accuracy: 98.74%, Test accuracy: 96.81%, Loss: 0.04381.\n",
      "Epoch 199/300 done. Train accuracy: 98.70%, Test accuracy: 97.11%, Loss: 0.04494.\n",
      "Epoch 200/300 done. Train accuracy: 98.65%, Test accuracy: 97.35%, Loss: 0.04515.\n",
      "Epoch 201/300 done. Train accuracy: 98.60%, Test accuracy: 97.05%, Loss: 0.04615.\n",
      "Epoch 202/300 done. Train accuracy: 98.72%, Test accuracy: 97.24%, Loss: 0.04620.\n",
      "Epoch 203/300 done. Train accuracy: 98.85%, Test accuracy: 97.05%, Loss: 0.04215.\n",
      "Epoch 204/300 done. Train accuracy: 98.69%, Test accuracy: 97.14%, Loss: 0.04583.\n",
      "Epoch 205/300 done. Train accuracy: 98.76%, Test accuracy: 96.84%, Loss: 0.04380.\n",
      "Epoch 206/300 done. Train accuracy: 98.61%, Test accuracy: 97.26%, Loss: 0.04688.\n",
      "Epoch 207/300 done. Train accuracy: 98.67%, Test accuracy: 97.41%, Loss: 0.04620.\n",
      "Epoch 208/300 done. Train accuracy: 98.76%, Test accuracy: 96.93%, Loss: 0.04328.\n",
      "Epoch 209/300 done. Train accuracy: 98.76%, Test accuracy: 97.26%, Loss: 0.04423.\n",
      "Epoch 210/300 done. Train accuracy: 98.59%, Test accuracy: 96.96%, Loss: 0.04666.\n",
      "Epoch 211/300 done. Train accuracy: 98.60%, Test accuracy: 96.93%, Loss: 0.04634.\n",
      "Epoch 212/300 done. Train accuracy: 98.61%, Test accuracy: 97.06%, Loss: 0.04569.\n",
      "Epoch 213/300 done. Train accuracy: 98.70%, Test accuracy: 96.81%, Loss: 0.04398.\n",
      "Epoch 214/300 done. Train accuracy: 98.77%, Test accuracy: 97.08%, Loss: 0.04379.\n",
      "Epoch 215/300 done. Train accuracy: 98.64%, Test accuracy: 97.05%, Loss: 0.04672.\n",
      "Epoch 216/300 done. Train accuracy: 98.67%, Test accuracy: 97.05%, Loss: 0.04640.\n",
      "Epoch 217/300 done. Train accuracy: 98.75%, Test accuracy: 97.65%, Loss: 0.04299.\n",
      "Epoch 218/300 done. Train accuracy: 98.73%, Test accuracy: 97.02%, Loss: 0.04319.\n",
      "Epoch 219/300 done. Train accuracy: 98.72%, Test accuracy: 97.20%, Loss: 0.04372.\n",
      "Epoch 220/300 done. Train accuracy: 98.71%, Test accuracy: 97.23%, Loss: 0.04538.\n",
      "Epoch 221/300 done. Train accuracy: 98.73%, Test accuracy: 97.23%, Loss: 0.04477.\n",
      "Epoch 222/300 done. Train accuracy: 98.70%, Test accuracy: 97.08%, Loss: 0.04519.\n",
      "Epoch 223/300 done. Train accuracy: 98.57%, Test accuracy: 97.18%, Loss: 0.04848.\n",
      "Epoch 224/300 done. Train accuracy: 98.71%, Test accuracy: 97.08%, Loss: 0.04404.\n",
      "Epoch 225/300 done. Train accuracy: 98.74%, Test accuracy: 97.02%, Loss: 0.04326.\n",
      "Epoch 226/300 done. Train accuracy: 98.76%, Test accuracy: 97.17%, Loss: 0.04256.\n",
      "Epoch 227/300 done. Train accuracy: 98.79%, Test accuracy: 97.23%, Loss: 0.04245.\n",
      "Epoch 228/300 done. Train accuracy: 98.73%, Test accuracy: 97.11%, Loss: 0.04318.\n",
      "Epoch 229/300 done. Train accuracy: 98.63%, Test accuracy: 97.11%, Loss: 0.04569.\n",
      "Epoch 230/300 done. Train accuracy: 98.76%, Test accuracy: 97.47%, Loss: 0.04310.\n",
      "Epoch 231/300 done. Train accuracy: 98.72%, Test accuracy: 96.90%, Loss: 0.04268.\n",
      "Epoch 232/300 done. Train accuracy: 98.78%, Test accuracy: 97.24%, Loss: 0.04304.\n",
      "Epoch 233/300 done. Train accuracy: 98.77%, Test accuracy: 96.90%, Loss: 0.04373.\n",
      "Epoch 234/300 done. Train accuracy: 98.61%, Test accuracy: 97.17%, Loss: 0.04539.\n",
      "Epoch 235/300 done. Train accuracy: 98.74%, Test accuracy: 97.38%, Loss: 0.04287.\n",
      "Epoch 236/300 done. Train accuracy: 98.74%, Test accuracy: 97.20%, Loss: 0.04480.\n",
      "Epoch 237/300 done. Train accuracy: 98.76%, Test accuracy: 96.78%, Loss: 0.04411.\n",
      "Epoch 238/300 done. Train accuracy: 98.79%, Test accuracy: 97.38%, Loss: 0.04291.\n",
      "Epoch 239/300 done. Train accuracy: 98.85%, Test accuracy: 97.17%, Loss: 0.04080.\n",
      "Epoch 240/300 done. Train accuracy: 98.68%, Test accuracy: 97.32%, Loss: 0.04417.\n",
      "Epoch 241/300 done. Train accuracy: 98.69%, Test accuracy: 97.32%, Loss: 0.04526.\n",
      "Epoch 242/300 done. Train accuracy: 98.68%, Test accuracy: 97.36%, Loss: 0.04513.\n",
      "Epoch 243/300 done. Train accuracy: 98.73%, Test accuracy: 97.29%, Loss: 0.04400.\n",
      "Epoch 244/300 done. Train accuracy: 98.80%, Test accuracy: 97.66%, Loss: 0.04202.\n",
      "Epoch 245/300 done. Train accuracy: 98.73%, Test accuracy: 97.32%, Loss: 0.04333.\n",
      "Epoch 246/300 done. Train accuracy: 98.68%, Test accuracy: 97.48%, Loss: 0.04609.\n",
      "Epoch 247/300 done. Train accuracy: 98.77%, Test accuracy: 97.47%, Loss: 0.04246.\n",
      "Epoch 248/300 done. Train accuracy: 98.73%, Test accuracy: 97.20%, Loss: 0.04441.\n",
      "Epoch 249/300 done. Train accuracy: 98.74%, Test accuracy: 97.17%, Loss: 0.04419.\n",
      "Epoch 250/300 done. Train accuracy: 98.62%, Test accuracy: 97.23%, Loss: 0.04582.\n",
      "Epoch 251/300 done. Train accuracy: 98.64%, Test accuracy: 96.75%, Loss: 0.04593.\n",
      "Epoch 252/300 done. Train accuracy: 98.74%, Test accuracy: 97.56%, Loss: 0.04336.\n",
      "Epoch 253/300 done. Train accuracy: 98.76%, Test accuracy: 97.29%, Loss: 0.04460.\n",
      "Epoch 254/300 done. Train accuracy: 98.69%, Test accuracy: 97.32%, Loss: 0.04539.\n",
      "Epoch 255/300 done. Train accuracy: 98.73%, Test accuracy: 97.35%, Loss: 0.04265.\n",
      "Epoch 256/300 done. Train accuracy: 98.76%, Test accuracy: 96.84%, Loss: 0.04301.\n",
      "Epoch 257/300 done. Train accuracy: 98.74%, Test accuracy: 97.20%, Loss: 0.04417.\n",
      "Epoch 258/300 done. Train accuracy: 98.74%, Test accuracy: 96.69%, Loss: 0.04529.\n",
      "Epoch 259/300 done. Train accuracy: 98.69%, Test accuracy: 96.78%, Loss: 0.04309.\n",
      "Epoch 260/300 done. Train accuracy: 98.82%, Test accuracy: 96.75%, Loss: 0.04147.\n",
      "Epoch 261/300 done. Train accuracy: 98.78%, Test accuracy: 97.14%, Loss: 0.04297.\n",
      "Epoch 262/300 done. Train accuracy: 98.76%, Test accuracy: 97.02%, Loss: 0.04228.\n",
      "Epoch 263/300 done. Train accuracy: 98.76%, Test accuracy: 97.38%, Loss: 0.04433.\n",
      "Epoch 264/300 done. Train accuracy: 98.75%, Test accuracy: 97.14%, Loss: 0.04309.\n",
      "Epoch 265/300 done. Train accuracy: 98.72%, Test accuracy: 97.14%, Loss: 0.04564.\n",
      "Epoch 266/300 done. Train accuracy: 98.75%, Test accuracy: 97.35%, Loss: 0.04370.\n",
      "Epoch 267/300 done. Train accuracy: 98.81%, Test accuracy: 97.14%, Loss: 0.04173.\n",
      "Epoch 268/300 done. Train accuracy: 98.77%, Test accuracy: 97.02%, Loss: 0.04253.\n",
      "Epoch 269/300 done. Train accuracy: 98.81%, Test accuracy: 96.94%, Loss: 0.04244.\n",
      "Epoch 270/300 done. Train accuracy: 98.72%, Test accuracy: 96.66%, Loss: 0.04355.\n",
      "Epoch 271/300 done. Train accuracy: 98.67%, Test accuracy: 96.78%, Loss: 0.04538.\n",
      "Epoch 272/300 done. Train accuracy: 98.57%, Test accuracy: 96.90%, Loss: 0.04879.\n",
      "Epoch 273/300 done. Train accuracy: 98.69%, Test accuracy: 96.57%, Loss: 0.04543.\n",
      "Epoch 274/300 done. Train accuracy: 98.77%, Test accuracy: 96.87%, Loss: 0.04177.\n",
      "Epoch 275/300 done. Train accuracy: 98.73%, Test accuracy: 97.08%, Loss: 0.04300.\n",
      "Epoch 276/300 done. Train accuracy: 98.76%, Test accuracy: 96.63%, Loss: 0.04413.\n",
      "Epoch 277/300 done. Train accuracy: 98.73%, Test accuracy: 96.84%, Loss: 0.04349.\n",
      "Epoch 278/300 done. Train accuracy: 98.66%, Test accuracy: 96.84%, Loss: 0.04521.\n",
      "Epoch 279/300 done. Train accuracy: 98.68%, Test accuracy: 97.05%, Loss: 0.04398.\n",
      "Epoch 280/300 done. Train accuracy: 98.62%, Test accuracy: 96.75%, Loss: 0.04606.\n",
      "Epoch 281/300 done. Train accuracy: 98.73%, Test accuracy: 96.87%, Loss: 0.04319.\n",
      "Epoch 282/300 done. Train accuracy: 98.75%, Test accuracy: 97.32%, Loss: 0.04237.\n",
      "Epoch 283/300 done. Train accuracy: 98.65%, Test accuracy: 97.02%, Loss: 0.04567.\n",
      "Epoch 284/300 done. Train accuracy: 98.79%, Test accuracy: 97.26%, Loss: 0.04247.\n",
      "Epoch 285/300 done. Train accuracy: 98.71%, Test accuracy: 97.11%, Loss: 0.04359.\n",
      "Epoch 286/300 done. Train accuracy: 98.73%, Test accuracy: 96.93%, Loss: 0.04296.\n",
      "Epoch 287/300 done. Train accuracy: 98.76%, Test accuracy: 97.26%, Loss: 0.04257.\n",
      "Epoch 288/300 done. Train accuracy: 98.74%, Test accuracy: 96.81%, Loss: 0.04311.\n",
      "Epoch 289/300 done. Train accuracy: 98.75%, Test accuracy: 97.05%, Loss: 0.04235.\n",
      "Epoch 290/300 done. Train accuracy: 98.77%, Test accuracy: 96.75%, Loss: 0.04165.\n",
      "Epoch 291/300 done. Train accuracy: 98.73%, Test accuracy: 97.05%, Loss: 0.04273.\n",
      "Epoch 292/300 done. Train accuracy: 98.70%, Test accuracy: 96.93%, Loss: 0.04568.\n",
      "Epoch 293/300 done. Train accuracy: 98.64%, Test accuracy: 97.05%, Loss: 0.04553.\n",
      "Epoch 294/300 done. Train accuracy: 98.69%, Test accuracy: 97.17%, Loss: 0.04436.\n",
      "Epoch 295/300 done. Train accuracy: 98.69%, Test accuracy: 96.93%, Loss: 0.04417.\n",
      "Epoch 296/300 done. Train accuracy: 98.71%, Test accuracy: 97.35%, Loss: 0.04366.\n",
      "Epoch 297/300 done. Train accuracy: 98.75%, Test accuracy: 97.38%, Loss: 0.04300.\n",
      "Epoch 298/300 done. Train accuracy: 98.66%, Test accuracy: 97.05%, Loss: 0.04726.\n",
      "Epoch 299/300 done. Train accuracy: 98.78%, Test accuracy: 97.17%, Loss: 0.04324.\n",
      "Epoch 300/300 done. Train accuracy: 98.75%, Test accuracy: 97.23%, Loss: 0.04532.\n",
      "Final results: \n",
      "Best training accuracy: 98.85% and according test accuracy: 97.05% at epoch: 203\n",
      "Best test accuracy: 97.93% and according train accuracy: 98.57% at epoch: 78\n",
      "------------------------------------------------------------------------------------\n",
      "\n",
      "Epoch 1/300 done. Train accuracy: 9.70%, Test accuracy: 15.58%, Loss: 23.98535.\n",
      "Epoch 2/300 done. Train accuracy: 20.20%, Test accuracy: 34.18%, Loss: 7.92060.\n",
      "Epoch 3/300 done. Train accuracy: 40.90%, Test accuracy: 58.34%, Loss: 3.39849.\n",
      "Epoch 4/300 done. Train accuracy: 57.10%, Test accuracy: 71.63%, Loss: 1.94045.\n",
      "Epoch 5/300 done. Train accuracy: 71.46%, Test accuracy: 81.74%, Loss: 1.09113.\n",
      "Epoch 6/300 done. Train accuracy: 78.05%, Test accuracy: 84.81%, Loss: 0.91652.\n",
      "Epoch 7/300 done. Train accuracy: 83.06%, Test accuracy: 89.11%, Loss: 0.62739.\n",
      "Epoch 8/300 done. Train accuracy: 87.05%, Test accuracy: 90.85%, Loss: 0.45611.\n",
      "Epoch 9/300 done. Train accuracy: 89.49%, Test accuracy: 93.98%, Loss: 0.41350.\n",
      "Epoch 10/300 done. Train accuracy: 90.75%, Test accuracy: 93.41%, Loss: 0.34598.\n",
      "Epoch 11/300 done. Train accuracy: 91.96%, Test accuracy: 95.19%, Loss: 0.32295.\n",
      "Epoch 12/300 done. Train accuracy: 94.07%, Test accuracy: 94.68%, Loss: 0.19923.\n",
      "Epoch 13/300 done. Train accuracy: 93.64%, Test accuracy: 95.64%, Loss: 0.21850.\n",
      "Epoch 14/300 done. Train accuracy: 94.49%, Test accuracy: 95.16%, Loss: 0.22861.\n",
      "Epoch 15/300 done. Train accuracy: 95.32%, Test accuracy: 95.49%, Loss: 0.18610.\n",
      "Epoch 16/300 done. Train accuracy: 95.88%, Test accuracy: 95.52%, Loss: 0.14672.\n",
      "Epoch 17/300 done. Train accuracy: 94.87%, Test accuracy: 96.39%, Loss: 0.18549.\n",
      "Epoch 18/300 done. Train accuracy: 95.87%, Test accuracy: 96.99%, Loss: 0.15643.\n",
      "Epoch 19/300 done. Train accuracy: 95.78%, Test accuracy: 96.57%, Loss: 0.15517.\n",
      "Epoch 20/300 done. Train accuracy: 96.26%, Test accuracy: 96.78%, Loss: 0.13505.\n",
      "Epoch 21/300 done. Train accuracy: 96.65%, Test accuracy: 96.21%, Loss: 0.11751.\n",
      "Epoch 22/300 done. Train accuracy: 96.87%, Test accuracy: 96.57%, Loss: 0.12578.\n",
      "Epoch 23/300 done. Train accuracy: 96.72%, Test accuracy: 97.11%, Loss: 0.11751.\n",
      "Epoch 24/300 done. Train accuracy: 97.44%, Test accuracy: 96.96%, Loss: 0.09778.\n",
      "Epoch 25/300 done. Train accuracy: 96.84%, Test accuracy: 96.96%, Loss: 0.12490.\n",
      "Epoch 26/300 done. Train accuracy: 97.03%, Test accuracy: 97.29%, Loss: 0.11411.\n",
      "Epoch 27/300 done. Train accuracy: 97.67%, Test accuracy: 96.54%, Loss: 0.08758.\n",
      "Epoch 28/300 done. Train accuracy: 97.55%, Test accuracy: 97.14%, Loss: 0.09838.\n",
      "Epoch 29/300 done. Train accuracy: 97.14%, Test accuracy: 97.44%, Loss: 0.11750.\n",
      "Epoch 30/300 done. Train accuracy: 97.59%, Test accuracy: 96.78%, Loss: 0.09298.\n",
      "Epoch 31/300 done. Train accuracy: 97.83%, Test accuracy: 97.14%, Loss: 0.09424.\n",
      "Epoch 32/300 done. Train accuracy: 97.68%, Test accuracy: 96.60%, Loss: 0.08880.\n",
      "Epoch 33/300 done. Train accuracy: 97.51%, Test accuracy: 97.32%, Loss: 0.09458.\n",
      "Epoch 34/300 done. Train accuracy: 97.73%, Test accuracy: 97.26%, Loss: 0.08946.\n",
      "Epoch 35/300 done. Train accuracy: 97.65%, Test accuracy: 97.20%, Loss: 0.09285.\n",
      "Epoch 36/300 done. Train accuracy: 97.59%, Test accuracy: 97.62%, Loss: 0.10383.\n",
      "Epoch 37/300 done. Train accuracy: 97.82%, Test accuracy: 97.65%, Loss: 0.09774.\n",
      "Epoch 38/300 done. Train accuracy: 97.95%, Test accuracy: 97.59%, Loss: 0.07531.\n",
      "Epoch 39/300 done. Train accuracy: 98.14%, Test accuracy: 97.60%, Loss: 0.07205.\n",
      "Epoch 40/300 done. Train accuracy: 97.97%, Test accuracy: 97.44%, Loss: 0.07440.\n",
      "Epoch 41/300 done. Train accuracy: 98.12%, Test accuracy: 97.32%, Loss: 0.06950.\n",
      "Epoch 42/300 done. Train accuracy: 97.99%, Test accuracy: 97.71%, Loss: 0.08473.\n",
      "Epoch 43/300 done. Train accuracy: 98.12%, Test accuracy: 97.59%, Loss: 0.07110.\n",
      "Epoch 44/300 done. Train accuracy: 97.92%, Test accuracy: 97.41%, Loss: 0.07714.\n",
      "Epoch 45/300 done. Train accuracy: 98.42%, Test accuracy: 97.74%, Loss: 0.06510.\n",
      "Epoch 46/300 done. Train accuracy: 98.17%, Test accuracy: 97.66%, Loss: 0.06646.\n",
      "Epoch 47/300 done. Train accuracy: 98.14%, Test accuracy: 97.59%, Loss: 0.06775.\n",
      "Epoch 48/300 done. Train accuracy: 98.26%, Test accuracy: 97.84%, Loss: 0.06727.\n",
      "Epoch 49/300 done. Train accuracy: 98.11%, Test accuracy: 97.26%, Loss: 0.07024.\n",
      "Epoch 50/300 done. Train accuracy: 98.30%, Test accuracy: 96.99%, Loss: 0.06440.\n",
      "Epoch 51/300 done. Train accuracy: 98.31%, Test accuracy: 97.48%, Loss: 0.06292.\n",
      "Epoch 52/300 done. Train accuracy: 98.20%, Test accuracy: 97.53%, Loss: 0.07029.\n",
      "Epoch 53/300 done. Train accuracy: 98.50%, Test accuracy: 97.11%, Loss: 0.05315.\n",
      "Epoch 54/300 done. Train accuracy: 98.39%, Test accuracy: 97.53%, Loss: 0.06226.\n",
      "Epoch 55/300 done. Train accuracy: 98.38%, Test accuracy: 97.48%, Loss: 0.05988.\n",
      "Epoch 56/300 done. Train accuracy: 98.21%, Test accuracy: 97.68%, Loss: 0.06586.\n",
      "Epoch 57/300 done. Train accuracy: 98.27%, Test accuracy: 97.71%, Loss: 0.05877.\n",
      "Epoch 58/300 done. Train accuracy: 98.29%, Test accuracy: 97.56%, Loss: 0.06020.\n",
      "Epoch 59/300 done. Train accuracy: 98.34%, Test accuracy: 97.84%, Loss: 0.05921.\n",
      "Epoch 60/300 done. Train accuracy: 98.39%, Test accuracy: 97.65%, Loss: 0.06577.\n",
      "Epoch 61/300 done. Train accuracy: 98.39%, Test accuracy: 97.59%, Loss: 0.05766.\n",
      "Epoch 62/300 done. Train accuracy: 98.47%, Test accuracy: 97.59%, Loss: 0.05550.\n",
      "Epoch 63/300 done. Train accuracy: 98.30%, Test accuracy: 97.44%, Loss: 0.05835.\n",
      "Epoch 64/300 done. Train accuracy: 98.09%, Test accuracy: 97.35%, Loss: 0.07457.\n",
      "Epoch 65/300 done. Train accuracy: 98.64%, Test accuracy: 97.71%, Loss: 0.04927.\n",
      "Epoch 66/300 done. Train accuracy: 98.47%, Test accuracy: 97.95%, Loss: 0.05429.\n",
      "Epoch 67/300 done. Train accuracy: 98.33%, Test accuracy: 97.71%, Loss: 0.05414.\n",
      "Epoch 68/300 done. Train accuracy: 98.33%, Test accuracy: 97.59%, Loss: 0.06072.\n",
      "Epoch 69/300 done. Train accuracy: 98.37%, Test accuracy: 97.41%, Loss: 0.05384.\n",
      "Epoch 70/300 done. Train accuracy: 98.52%, Test accuracy: 97.59%, Loss: 0.05247.\n",
      "Epoch 71/300 done. Train accuracy: 98.39%, Test accuracy: 97.59%, Loss: 0.05855.\n",
      "Epoch 72/300 done. Train accuracy: 98.44%, Test accuracy: 97.71%, Loss: 0.06380.\n",
      "Epoch 73/300 done. Train accuracy: 98.45%, Test accuracy: 98.02%, Loss: 0.05601.\n",
      "Epoch 74/300 done. Train accuracy: 98.41%, Test accuracy: 97.96%, Loss: 0.05540.\n",
      "Epoch 75/300 done. Train accuracy: 98.38%, Test accuracy: 97.11%, Loss: 0.05836.\n",
      "Epoch 76/300 done. Train accuracy: 98.47%, Test accuracy: 97.50%, Loss: 0.05218.\n",
      "Epoch 77/300 done. Train accuracy: 98.62%, Test accuracy: 97.56%, Loss: 0.05205.\n",
      "Epoch 78/300 done. Train accuracy: 98.53%, Test accuracy: 98.05%, Loss: 0.05224.\n",
      "Epoch 79/300 done. Train accuracy: 98.40%, Test accuracy: 97.95%, Loss: 0.05569.\n",
      "Epoch 80/300 done. Train accuracy: 98.50%, Test accuracy: 97.65%, Loss: 0.05582.\n",
      "Epoch 81/300 done. Train accuracy: 98.39%, Test accuracy: 97.84%, Loss: 0.06195.\n",
      "Epoch 82/300 done. Train accuracy: 98.65%, Test accuracy: 97.81%, Loss: 0.04962.\n",
      "Epoch 83/300 done. Train accuracy: 98.56%, Test accuracy: 97.60%, Loss: 0.05179.\n",
      "Epoch 84/300 done. Train accuracy: 98.52%, Test accuracy: 97.95%, Loss: 0.05539.\n",
      "Epoch 85/300 done. Train accuracy: 98.44%, Test accuracy: 97.59%, Loss: 0.05689.\n",
      "Epoch 86/300 done. Train accuracy: 98.57%, Test accuracy: 97.87%, Loss: 0.05050.\n",
      "Epoch 87/300 done. Train accuracy: 98.54%, Test accuracy: 97.74%, Loss: 0.05299.\n",
      "Epoch 88/300 done. Train accuracy: 98.54%, Test accuracy: 97.50%, Loss: 0.05186.\n",
      "Epoch 89/300 done. Train accuracy: 98.63%, Test accuracy: 97.74%, Loss: 0.05215.\n",
      "Epoch 90/300 done. Train accuracy: 98.47%, Test accuracy: 97.95%, Loss: 0.05290.\n",
      "Epoch 91/300 done. Train accuracy: 98.58%, Test accuracy: 98.07%, Loss: 0.05010.\n",
      "Epoch 92/300 done. Train accuracy: 98.62%, Test accuracy: 97.65%, Loss: 0.05197.\n",
      "Epoch 93/300 done. Train accuracy: 98.50%, Test accuracy: 97.83%, Loss: 0.05521.\n",
      "Epoch 94/300 done. Train accuracy: 98.62%, Test accuracy: 97.87%, Loss: 0.04912.\n",
      "Epoch 95/300 done. Train accuracy: 98.61%, Test accuracy: 97.68%, Loss: 0.04928.\n",
      "Epoch 96/300 done. Train accuracy: 98.76%, Test accuracy: 97.74%, Loss: 0.04491.\n",
      "Epoch 97/300 done. Train accuracy: 98.70%, Test accuracy: 97.81%, Loss: 0.04593.\n",
      "Epoch 98/300 done. Train accuracy: 98.54%, Test accuracy: 97.77%, Loss: 0.05225.\n",
      "Epoch 99/300 done. Train accuracy: 98.66%, Test accuracy: 97.87%, Loss: 0.04706.\n",
      "Epoch 100/300 done. Train accuracy: 98.62%, Test accuracy: 97.47%, Loss: 0.04914.\n",
      "Epoch 101/300 done. Train accuracy: 98.55%, Test accuracy: 97.80%, Loss: 0.05410.\n",
      "Epoch 102/300 done. Train accuracy: 98.67%, Test accuracy: 97.68%, Loss: 0.04837.\n",
      "Epoch 103/300 done. Train accuracy: 98.71%, Test accuracy: 97.68%, Loss: 0.04784.\n",
      "Epoch 104/300 done. Train accuracy: 98.65%, Test accuracy: 97.71%, Loss: 0.04668.\n",
      "Epoch 105/300 done. Train accuracy: 98.67%, Test accuracy: 97.54%, Loss: 0.04686.\n",
      "Epoch 106/300 done. Train accuracy: 98.58%, Test accuracy: 97.89%, Loss: 0.04837.\n",
      "Epoch 107/300 done. Train accuracy: 98.63%, Test accuracy: 97.53%, Loss: 0.04884.\n",
      "Epoch 108/300 done. Train accuracy: 98.58%, Test accuracy: 97.32%, Loss: 0.04845.\n",
      "Epoch 109/300 done. Train accuracy: 98.72%, Test accuracy: 97.65%, Loss: 0.04548.\n",
      "Epoch 110/300 done. Train accuracy: 98.72%, Test accuracy: 97.81%, Loss: 0.04468.\n",
      "Epoch 111/300 done. Train accuracy: 98.56%, Test accuracy: 97.48%, Loss: 0.05342.\n",
      "Epoch 112/300 done. Train accuracy: 98.51%, Test accuracy: 97.93%, Loss: 0.05046.\n",
      "Epoch 113/300 done. Train accuracy: 98.74%, Test accuracy: 97.77%, Loss: 0.04481.\n",
      "Epoch 114/300 done. Train accuracy: 98.68%, Test accuracy: 97.77%, Loss: 0.04625.\n",
      "Epoch 115/300 done. Train accuracy: 98.61%, Test accuracy: 97.41%, Loss: 0.05037.\n",
      "Epoch 116/300 done. Train accuracy: 98.69%, Test accuracy: 97.62%, Loss: 0.04545.\n",
      "Epoch 117/300 done. Train accuracy: 98.47%, Test accuracy: 97.89%, Loss: 0.05061.\n",
      "Epoch 118/300 done. Train accuracy: 98.59%, Test accuracy: 97.71%, Loss: 0.04909.\n",
      "Epoch 119/300 done. Train accuracy: 98.72%, Test accuracy: 97.68%, Loss: 0.04616.\n",
      "Epoch 120/300 done. Train accuracy: 98.74%, Test accuracy: 97.62%, Loss: 0.04439.\n",
      "Epoch 121/300 done. Train accuracy: 98.77%, Test accuracy: 97.96%, Loss: 0.04580.\n",
      "Epoch 122/300 done. Train accuracy: 98.73%, Test accuracy: 97.72%, Loss: 0.04554.\n",
      "Epoch 123/300 done. Train accuracy: 98.59%, Test accuracy: 97.35%, Loss: 0.04693.\n",
      "Epoch 124/300 done. Train accuracy: 98.63%, Test accuracy: 97.56%, Loss: 0.04908.\n",
      "Epoch 125/300 done. Train accuracy: 98.65%, Test accuracy: 97.47%, Loss: 0.04881.\n",
      "Epoch 126/300 done. Train accuracy: 98.69%, Test accuracy: 97.74%, Loss: 0.04726.\n",
      "Epoch 127/300 done. Train accuracy: 98.62%, Test accuracy: 97.71%, Loss: 0.04794.\n",
      "Epoch 128/300 done. Train accuracy: 98.70%, Test accuracy: 97.66%, Loss: 0.04495.\n",
      "Epoch 129/300 done. Train accuracy: 98.74%, Test accuracy: 97.62%, Loss: 0.04472.\n",
      "Epoch 130/300 done. Train accuracy: 98.73%, Test accuracy: 97.68%, Loss: 0.04580.\n",
      "Epoch 131/300 done. Train accuracy: 98.77%, Test accuracy: 97.78%, Loss: 0.04361.\n",
      "Epoch 132/300 done. Train accuracy: 98.66%, Test accuracy: 97.35%, Loss: 0.04570.\n",
      "Epoch 133/300 done. Train accuracy: 98.66%, Test accuracy: 97.74%, Loss: 0.04585.\n",
      "Epoch 134/300 done. Train accuracy: 98.41%, Test accuracy: 97.59%, Loss: 0.05587.\n",
      "Epoch 135/300 done. Train accuracy: 98.66%, Test accuracy: 97.92%, Loss: 0.04507.\n",
      "Epoch 136/300 done. Train accuracy: 98.56%, Test accuracy: 97.74%, Loss: 0.04821.\n",
      "Epoch 137/300 done. Train accuracy: 98.64%, Test accuracy: 97.53%, Loss: 0.04574.\n",
      "Epoch 138/300 done. Train accuracy: 98.73%, Test accuracy: 97.71%, Loss: 0.04407.\n",
      "Epoch 139/300 done. Train accuracy: 98.71%, Test accuracy: 97.47%, Loss: 0.04575.\n",
      "Epoch 140/300 done. Train accuracy: 98.67%, Test accuracy: 97.38%, Loss: 0.04701.\n",
      "Epoch 141/300 done. Train accuracy: 98.71%, Test accuracy: 97.65%, Loss: 0.04438.\n",
      "Epoch 142/300 done. Train accuracy: 98.69%, Test accuracy: 97.59%, Loss: 0.04593.\n",
      "Epoch 143/300 done. Train accuracy: 98.64%, Test accuracy: 97.68%, Loss: 0.04827.\n",
      "Epoch 144/300 done. Train accuracy: 98.57%, Test accuracy: 97.32%, Loss: 0.04802.\n",
      "Epoch 145/300 done. Train accuracy: 98.67%, Test accuracy: 97.77%, Loss: 0.04875.\n",
      "Epoch 146/300 done. Train accuracy: 98.52%, Test accuracy: 97.81%, Loss: 0.05210.\n",
      "Epoch 147/300 done. Train accuracy: 98.73%, Test accuracy: 97.66%, Loss: 0.04495.\n",
      "Epoch 148/300 done. Train accuracy: 98.68%, Test accuracy: 97.90%, Loss: 0.04559.\n",
      "Epoch 149/300 done. Train accuracy: 98.67%, Test accuracy: 97.44%, Loss: 0.04667.\n",
      "Epoch 150/300 done. Train accuracy: 98.75%, Test accuracy: 97.53%, Loss: 0.04441.\n",
      "Epoch 151/300 done. Train accuracy: 98.67%, Test accuracy: 97.71%, Loss: 0.04671.\n",
      "Epoch 152/300 done. Train accuracy: 98.61%, Test accuracy: 97.84%, Loss: 0.04684.\n",
      "Epoch 153/300 done. Train accuracy: 98.69%, Test accuracy: 97.47%, Loss: 0.04535.\n",
      "Epoch 154/300 done. Train accuracy: 98.61%, Test accuracy: 97.65%, Loss: 0.04504.\n",
      "Epoch 155/300 done. Train accuracy: 98.51%, Test accuracy: 97.38%, Loss: 0.05220.\n",
      "Epoch 156/300 done. Train accuracy: 98.66%, Test accuracy: 97.50%, Loss: 0.04605.\n",
      "Epoch 157/300 done. Train accuracy: 98.77%, Test accuracy: 97.66%, Loss: 0.04526.\n",
      "Epoch 158/300 done. Train accuracy: 98.75%, Test accuracy: 97.23%, Loss: 0.04512.\n",
      "Epoch 159/300 done. Train accuracy: 98.59%, Test accuracy: 97.23%, Loss: 0.04898.\n",
      "Epoch 160/300 done. Train accuracy: 98.63%, Test accuracy: 97.50%, Loss: 0.04724.\n",
      "Epoch 161/300 done. Train accuracy: 98.67%, Test accuracy: 97.38%, Loss: 0.04588.\n",
      "Epoch 162/300 done. Train accuracy: 98.71%, Test accuracy: 97.29%, Loss: 0.04401.\n",
      "Epoch 163/300 done. Train accuracy: 98.56%, Test accuracy: 97.08%, Loss: 0.05051.\n",
      "Epoch 164/300 done. Train accuracy: 98.73%, Test accuracy: 97.65%, Loss: 0.04524.\n",
      "Epoch 165/300 done. Train accuracy: 98.64%, Test accuracy: 97.50%, Loss: 0.04603.\n",
      "Epoch 166/300 done. Train accuracy: 98.69%, Test accuracy: 97.56%, Loss: 0.04635.\n",
      "Epoch 167/300 done. Train accuracy: 98.64%, Test accuracy: 97.65%, Loss: 0.04737.\n",
      "Epoch 168/300 done. Train accuracy: 98.63%, Test accuracy: 97.41%, Loss: 0.04633.\n",
      "Epoch 169/300 done. Train accuracy: 98.74%, Test accuracy: 97.71%, Loss: 0.04375.\n",
      "Epoch 170/300 done. Train accuracy: 98.64%, Test accuracy: 97.62%, Loss: 0.04534.\n",
      "Epoch 171/300 done. Train accuracy: 98.71%, Test accuracy: 97.35%, Loss: 0.04577.\n",
      "Epoch 172/300 done. Train accuracy: 98.72%, Test accuracy: 97.56%, Loss: 0.04638.\n",
      "Epoch 173/300 done. Train accuracy: 98.75%, Test accuracy: 97.44%, Loss: 0.04469.\n",
      "Epoch 174/300 done. Train accuracy: 98.67%, Test accuracy: 97.17%, Loss: 0.04750.\n",
      "Epoch 175/300 done. Train accuracy: 98.71%, Test accuracy: 97.59%, Loss: 0.04593.\n",
      "Epoch 176/300 done. Train accuracy: 98.69%, Test accuracy: 97.71%, Loss: 0.04644.\n",
      "Epoch 177/300 done. Train accuracy: 98.59%, Test accuracy: 97.20%, Loss: 0.04740.\n",
      "Epoch 178/300 done. Train accuracy: 98.79%, Test accuracy: 97.56%, Loss: 0.04285.\n",
      "Epoch 179/300 done. Train accuracy: 98.74%, Test accuracy: 97.53%, Loss: 0.04318.\n",
      "Epoch 180/300 done. Train accuracy: 98.59%, Test accuracy: 97.41%, Loss: 0.04790.\n",
      "Epoch 181/300 done. Train accuracy: 98.81%, Test accuracy: 97.84%, Loss: 0.04371.\n",
      "Epoch 182/300 done. Train accuracy: 98.68%, Test accuracy: 97.38%, Loss: 0.04478.\n",
      "Epoch 183/300 done. Train accuracy: 98.64%, Test accuracy: 97.38%, Loss: 0.04683.\n",
      "Epoch 184/300 done. Train accuracy: 98.79%, Test accuracy: 97.65%, Loss: 0.04209.\n",
      "Epoch 185/300 done. Train accuracy: 98.73%, Test accuracy: 97.53%, Loss: 0.04371.\n",
      "Epoch 186/300 done. Train accuracy: 98.73%, Test accuracy: 97.50%, Loss: 0.04377.\n",
      "Epoch 187/300 done. Train accuracy: 98.65%, Test accuracy: 97.96%, Loss: 0.04531.\n",
      "Epoch 188/300 done. Train accuracy: 98.73%, Test accuracy: 97.92%, Loss: 0.04472.\n",
      "Epoch 189/300 done. Train accuracy: 98.64%, Test accuracy: 97.68%, Loss: 0.04737.\n",
      "Epoch 190/300 done. Train accuracy: 98.79%, Test accuracy: 97.62%, Loss: 0.04291.\n",
      "Epoch 191/300 done. Train accuracy: 98.71%, Test accuracy: 97.66%, Loss: 0.04393.\n",
      "Epoch 192/300 done. Train accuracy: 98.66%, Test accuracy: 97.59%, Loss: 0.04558.\n",
      "Epoch 193/300 done. Train accuracy: 98.68%, Test accuracy: 97.77%, Loss: 0.04498.\n",
      "Epoch 194/300 done. Train accuracy: 98.82%, Test accuracy: 97.74%, Loss: 0.04179.\n",
      "Epoch 195/300 done. Train accuracy: 98.77%, Test accuracy: 97.90%, Loss: 0.04353.\n",
      "Epoch 196/300 done. Train accuracy: 98.76%, Test accuracy: 97.32%, Loss: 0.04356.\n",
      "Epoch 197/300 done. Train accuracy: 98.73%, Test accuracy: 97.50%, Loss: 0.04373.\n",
      "Epoch 198/300 done. Train accuracy: 98.76%, Test accuracy: 97.93%, Loss: 0.04368.\n",
      "Epoch 199/300 done. Train accuracy: 98.69%, Test accuracy: 97.59%, Loss: 0.04576.\n",
      "Epoch 200/300 done. Train accuracy: 98.76%, Test accuracy: 97.32%, Loss: 0.04359.\n",
      "Epoch 201/300 done. Train accuracy: 98.73%, Test accuracy: 97.80%, Loss: 0.04638.\n",
      "Epoch 202/300 done. Train accuracy: 98.69%, Test accuracy: 97.72%, Loss: 0.04596.\n",
      "Epoch 203/300 done. Train accuracy: 98.77%, Test accuracy: 97.60%, Loss: 0.04302.\n",
      "Epoch 204/300 done. Train accuracy: 98.78%, Test accuracy: 97.87%, Loss: 0.04265.\n",
      "Epoch 205/300 done. Train accuracy: 98.69%, Test accuracy: 97.62%, Loss: 0.04316.\n",
      "Epoch 206/300 done. Train accuracy: 98.78%, Test accuracy: 97.71%, Loss: 0.04307.\n",
      "Epoch 207/300 done. Train accuracy: 98.54%, Test accuracy: 97.68%, Loss: 0.04941.\n",
      "Epoch 208/300 done. Train accuracy: 98.69%, Test accuracy: 97.41%, Loss: 0.04560.\n",
      "Epoch 209/300 done. Train accuracy: 98.71%, Test accuracy: 97.38%, Loss: 0.04297.\n",
      "Epoch 210/300 done. Train accuracy: 98.69%, Test accuracy: 97.14%, Loss: 0.04591.\n",
      "Epoch 211/300 done. Train accuracy: 98.63%, Test accuracy: 97.47%, Loss: 0.04865.\n",
      "Epoch 212/300 done. Train accuracy: 98.69%, Test accuracy: 97.32%, Loss: 0.04475.\n",
      "Epoch 213/300 done. Train accuracy: 98.64%, Test accuracy: 97.29%, Loss: 0.04830.\n",
      "Epoch 214/300 done. Train accuracy: 98.60%, Test accuracy: 97.11%, Loss: 0.04680.\n",
      "Epoch 215/300 done. Train accuracy: 98.54%, Test accuracy: 97.48%, Loss: 0.05189.\n",
      "Epoch 216/300 done. Train accuracy: 98.71%, Test accuracy: 97.35%, Loss: 0.04338.\n",
      "Epoch 217/300 done. Train accuracy: 98.81%, Test accuracy: 97.48%, Loss: 0.04227.\n",
      "Epoch 218/300 done. Train accuracy: 98.67%, Test accuracy: 97.11%, Loss: 0.04525.\n",
      "Epoch 219/300 done. Train accuracy: 98.63%, Test accuracy: 97.47%, Loss: 0.04704.\n",
      "Epoch 220/300 done. Train accuracy: 98.73%, Test accuracy: 97.26%, Loss: 0.04341.\n",
      "Epoch 221/300 done. Train accuracy: 98.75%, Test accuracy: 97.38%, Loss: 0.04473.\n",
      "Epoch 222/300 done. Train accuracy: 98.71%, Test accuracy: 97.29%, Loss: 0.04364.\n",
      "Epoch 223/300 done. Train accuracy: 98.65%, Test accuracy: 97.56%, Loss: 0.04679.\n",
      "Epoch 224/300 done. Train accuracy: 98.70%, Test accuracy: 97.41%, Loss: 0.04461.\n",
      "Epoch 225/300 done. Train accuracy: 98.74%, Test accuracy: 97.44%, Loss: 0.04312.\n",
      "Epoch 226/300 done. Train accuracy: 98.69%, Test accuracy: 97.53%, Loss: 0.04444.\n",
      "Epoch 227/300 done. Train accuracy: 98.66%, Test accuracy: 97.62%, Loss: 0.04714.\n",
      "Epoch 228/300 done. Train accuracy: 98.63%, Test accuracy: 97.47%, Loss: 0.04491.\n",
      "Epoch 229/300 done. Train accuracy: 98.67%, Test accuracy: 97.38%, Loss: 0.04543.\n",
      "Epoch 230/300 done. Train accuracy: 98.76%, Test accuracy: 97.47%, Loss: 0.04463.\n",
      "Epoch 231/300 done. Train accuracy: 98.70%, Test accuracy: 96.96%, Loss: 0.04455.\n",
      "Epoch 232/300 done. Train accuracy: 98.72%, Test accuracy: 97.72%, Loss: 0.04459.\n",
      "Epoch 233/300 done. Train accuracy: 98.76%, Test accuracy: 97.38%, Loss: 0.04354.\n",
      "Epoch 234/300 done. Train accuracy: 98.74%, Test accuracy: 97.56%, Loss: 0.04441.\n",
      "Epoch 235/300 done. Train accuracy: 98.76%, Test accuracy: 97.60%, Loss: 0.04243.\n",
      "Epoch 236/300 done. Train accuracy: 98.66%, Test accuracy: 97.50%, Loss: 0.04515.\n",
      "Epoch 237/300 done. Train accuracy: 98.70%, Test accuracy: 97.26%, Loss: 0.04513.\n",
      "Epoch 238/300 done. Train accuracy: 98.61%, Test accuracy: 97.17%, Loss: 0.04812.\n",
      "Epoch 239/300 done. Train accuracy: 98.74%, Test accuracy: 97.44%, Loss: 0.04401.\n",
      "Epoch 240/300 done. Train accuracy: 98.73%, Test accuracy: 97.35%, Loss: 0.04464.\n",
      "Epoch 241/300 done. Train accuracy: 98.82%, Test accuracy: 97.29%, Loss: 0.04147.\n",
      "Epoch 242/300 done. Train accuracy: 98.63%, Test accuracy: 97.47%, Loss: 0.04592.\n",
      "Epoch 243/300 done. Train accuracy: 98.74%, Test accuracy: 96.93%, Loss: 0.04258.\n",
      "Epoch 244/300 done. Train accuracy: 98.73%, Test accuracy: 97.32%, Loss: 0.04408.\n",
      "Epoch 245/300 done. Train accuracy: 98.76%, Test accuracy: 97.14%, Loss: 0.04241.\n",
      "Epoch 246/300 done. Train accuracy: 98.72%, Test accuracy: 97.23%, Loss: 0.04605.\n",
      "Epoch 247/300 done. Train accuracy: 98.74%, Test accuracy: 97.14%, Loss: 0.04351.\n",
      "Epoch 248/300 done. Train accuracy: 98.77%, Test accuracy: 97.14%, Loss: 0.04397.\n",
      "Epoch 249/300 done. Train accuracy: 98.67%, Test accuracy: 97.08%, Loss: 0.04966.\n",
      "Epoch 250/300 done. Train accuracy: 98.79%, Test accuracy: 96.90%, Loss: 0.04200.\n",
      "Epoch 251/300 done. Train accuracy: 98.71%, Test accuracy: 97.11%, Loss: 0.04389.\n",
      "Epoch 252/300 done. Train accuracy: 98.65%, Test accuracy: 97.35%, Loss: 0.04502.\n",
      "Epoch 253/300 done. Train accuracy: 98.73%, Test accuracy: 97.23%, Loss: 0.04537.\n",
      "Epoch 254/300 done. Train accuracy: 98.71%, Test accuracy: 97.20%, Loss: 0.04333.\n",
      "Epoch 255/300 done. Train accuracy: 98.68%, Test accuracy: 97.26%, Loss: 0.04691.\n",
      "Epoch 256/300 done. Train accuracy: 98.77%, Test accuracy: 97.35%, Loss: 0.04363.\n",
      "Epoch 257/300 done. Train accuracy: 98.75%, Test accuracy: 97.41%, Loss: 0.04271.\n",
      "Epoch 258/300 done. Train accuracy: 98.73%, Test accuracy: 97.14%, Loss: 0.04383.\n",
      "Epoch 259/300 done. Train accuracy: 98.74%, Test accuracy: 97.20%, Loss: 0.04351.\n",
      "Epoch 260/300 done. Train accuracy: 98.80%, Test accuracy: 97.17%, Loss: 0.04302.\n",
      "Epoch 261/300 done. Train accuracy: 98.66%, Test accuracy: 96.84%, Loss: 0.04673.\n",
      "Epoch 262/300 done. Train accuracy: 98.68%, Test accuracy: 97.23%, Loss: 0.04615.\n",
      "Epoch 263/300 done. Train accuracy: 98.61%, Test accuracy: 96.99%, Loss: 0.04834.\n",
      "Epoch 264/300 done. Train accuracy: 98.75%, Test accuracy: 97.02%, Loss: 0.04444.\n",
      "Epoch 265/300 done. Train accuracy: 98.80%, Test accuracy: 96.87%, Loss: 0.04245.\n",
      "Epoch 266/300 done. Train accuracy: 98.58%, Test accuracy: 96.96%, Loss: 0.04499.\n",
      "Epoch 267/300 done. Train accuracy: 98.73%, Test accuracy: 97.32%, Loss: 0.04560.\n",
      "Epoch 268/300 done. Train accuracy: 98.73%, Test accuracy: 97.41%, Loss: 0.04476.\n",
      "Epoch 269/300 done. Train accuracy: 98.72%, Test accuracy: 97.35%, Loss: 0.04429.\n",
      "Epoch 270/300 done. Train accuracy: 98.77%, Test accuracy: 97.14%, Loss: 0.04262.\n",
      "Epoch 271/300 done. Train accuracy: 98.55%, Test accuracy: 97.17%, Loss: 0.04726.\n",
      "Epoch 272/300 done. Train accuracy: 98.73%, Test accuracy: 97.14%, Loss: 0.04402.\n",
      "Epoch 273/300 done. Train accuracy: 98.68%, Test accuracy: 97.18%, Loss: 0.04565.\n",
      "Epoch 274/300 done. Train accuracy: 98.78%, Test accuracy: 97.14%, Loss: 0.04202.\n",
      "Epoch 275/300 done. Train accuracy: 98.75%, Test accuracy: 97.48%, Loss: 0.04315.\n",
      "Epoch 276/300 done. Train accuracy: 98.69%, Test accuracy: 97.14%, Loss: 0.04423.\n",
      "Epoch 277/300 done. Train accuracy: 98.60%, Test accuracy: 97.05%, Loss: 0.04770.\n",
      "Epoch 278/300 done. Train accuracy: 98.67%, Test accuracy: 97.08%, Loss: 0.04438.\n",
      "Epoch 279/300 done. Train accuracy: 98.77%, Test accuracy: 97.32%, Loss: 0.04293.\n",
      "Epoch 280/300 done. Train accuracy: 98.80%, Test accuracy: 97.08%, Loss: 0.04373.\n",
      "Epoch 281/300 done. Train accuracy: 98.67%, Test accuracy: 97.50%, Loss: 0.04518.\n",
      "Epoch 282/300 done. Train accuracy: 98.73%, Test accuracy: 96.93%, Loss: 0.04320.\n",
      "Epoch 283/300 done. Train accuracy: 98.70%, Test accuracy: 97.14%, Loss: 0.04378.\n",
      "Epoch 284/300 done. Train accuracy: 98.74%, Test accuracy: 97.20%, Loss: 0.04320.\n",
      "Epoch 285/300 done. Train accuracy: 98.85%, Test accuracy: 97.29%, Loss: 0.04063.\n",
      "Epoch 286/300 done. Train accuracy: 98.77%, Test accuracy: 97.26%, Loss: 0.04174.\n",
      "Epoch 287/300 done. Train accuracy: 98.78%, Test accuracy: 96.84%, Loss: 0.04218.\n",
      "Epoch 288/300 done. Train accuracy: 98.69%, Test accuracy: 97.41%, Loss: 0.04322.\n",
      "Epoch 289/300 done. Train accuracy: 98.79%, Test accuracy: 97.36%, Loss: 0.04249.\n",
      "Epoch 290/300 done. Train accuracy: 98.73%, Test accuracy: 97.53%, Loss: 0.04260.\n",
      "Epoch 291/300 done. Train accuracy: 98.71%, Test accuracy: 97.48%, Loss: 0.04354.\n",
      "Epoch 292/300 done. Train accuracy: 98.77%, Test accuracy: 97.26%, Loss: 0.04379.\n",
      "Epoch 293/300 done. Train accuracy: 98.67%, Test accuracy: 97.41%, Loss: 0.04636.\n",
      "Epoch 294/300 done. Train accuracy: 98.80%, Test accuracy: 97.32%, Loss: 0.04215.\n",
      "Epoch 295/300 done. Train accuracy: 98.69%, Test accuracy: 97.47%, Loss: 0.04426.\n",
      "Epoch 296/300 done. Train accuracy: 98.73%, Test accuracy: 97.35%, Loss: 0.04279.\n",
      "Epoch 297/300 done. Train accuracy: 98.73%, Test accuracy: 97.41%, Loss: 0.04564.\n",
      "Epoch 298/300 done. Train accuracy: 98.76%, Test accuracy: 97.53%, Loss: 0.04236.\n",
      "Epoch 299/300 done. Train accuracy: 98.69%, Test accuracy: 97.32%, Loss: 0.04512.\n",
      "Epoch 300/300 done. Train accuracy: 98.72%, Test accuracy: 97.47%, Loss: 0.04446.\n",
      "Final results: \n",
      "Best training accuracy: 98.85% and according test accuracy: 97.29% at epoch: 285\n",
      "Best test accuracy: 98.07% and according train accuracy: 98.58% at epoch: 91\n",
      "------------------------------------------------------------------------------------\n",
      "\n",
      "Epoch 1/300 done. Train accuracy: 9.40%, Test accuracy: 17.51%, Loss: 14.75729.\n",
      "Epoch 2/300 done. Train accuracy: 13.96%, Test accuracy: 20.91%, Loss: 4.23772.\n",
      "Epoch 3/300 done. Train accuracy: 23.83%, Test accuracy: 33.70%, Loss: 3.16067.\n",
      "Epoch 4/300 done. Train accuracy: 28.89%, Test accuracy: 37.16%, Loss: 2.98784.\n",
      "Epoch 5/300 done. Train accuracy: 31.06%, Test accuracy: 40.21%, Loss: 3.00413.\n",
      "Epoch 6/300 done. Train accuracy: 40.46%, Test accuracy: 53.31%, Loss: 2.42681.\n",
      "Epoch 7/300 done. Train accuracy: 48.20%, Test accuracy: 60.07%, Loss: 2.12182.\n",
      "Epoch 8/300 done. Train accuracy: 58.09%, Test accuracy: 68.51%, Loss: 1.73470.\n",
      "Epoch 9/300 done. Train accuracy: 61.73%, Test accuracy: 74.12%, Loss: 1.96512.\n",
      "Epoch 10/300 done. Train accuracy: 62.61%, Test accuracy: 74.67%, Loss: 1.82164.\n",
      "Epoch 11/300 done. Train accuracy: 70.71%, Test accuracy: 78.97%, Loss: 1.30072.\n",
      "Epoch 12/300 done. Train accuracy: 75.36%, Test accuracy: 85.89%, Loss: 0.94523.\n",
      "Epoch 13/300 done. Train accuracy: 80.74%, Test accuracy: 85.91%, Loss: 0.91447.\n",
      "Epoch 14/300 done. Train accuracy: 83.72%, Test accuracy: 86.76%, Loss: 0.68959.\n",
      "Epoch 15/300 done. Train accuracy: 87.89%, Test accuracy: 91.69%, Loss: 0.44386.\n",
      "Epoch 16/300 done. Train accuracy: 88.18%, Test accuracy: 91.94%, Loss: 0.47486.\n",
      "Epoch 17/300 done. Train accuracy: 91.77%, Test accuracy: 93.78%, Loss: 0.30317.\n",
      "Epoch 18/300 done. Train accuracy: 90.49%, Test accuracy: 93.80%, Loss: 0.45997.\n",
      "Epoch 19/300 done. Train accuracy: 92.03%, Test accuracy: 94.38%, Loss: 0.36266.\n",
      "Epoch 20/300 done. Train accuracy: 94.62%, Test accuracy: 94.70%, Loss: 0.19748.\n",
      "Epoch 21/300 done. Train accuracy: 94.58%, Test accuracy: 95.03%, Loss: 0.18817.\n",
      "Epoch 22/300 done. Train accuracy: 94.95%, Test accuracy: 96.06%, Loss: 0.19933.\n",
      "Epoch 23/300 done. Train accuracy: 95.25%, Test accuracy: 96.72%, Loss: 0.16464.\n",
      "Epoch 24/300 done. Train accuracy: 96.27%, Test accuracy: 96.21%, Loss: 0.13435.\n",
      "Epoch 25/300 done. Train accuracy: 95.60%, Test accuracy: 96.06%, Loss: 0.15617.\n",
      "Epoch 26/300 done. Train accuracy: 96.73%, Test accuracy: 96.36%, Loss: 0.11566.\n",
      "Epoch 27/300 done. Train accuracy: 96.74%, Test accuracy: 96.72%, Loss: 0.12337.\n",
      "Epoch 28/300 done. Train accuracy: 96.98%, Test accuracy: 96.60%, Loss: 0.10623.\n",
      "Epoch 29/300 done. Train accuracy: 96.91%, Test accuracy: 97.50%, Loss: 0.11445.\n",
      "Epoch 30/300 done. Train accuracy: 97.31%, Test accuracy: 96.63%, Loss: 0.10432.\n",
      "Epoch 31/300 done. Train accuracy: 96.91%, Test accuracy: 97.17%, Loss: 0.10720.\n",
      "Epoch 32/300 done. Train accuracy: 97.21%, Test accuracy: 97.17%, Loss: 0.09385.\n",
      "Epoch 33/300 done. Train accuracy: 97.34%, Test accuracy: 97.11%, Loss: 0.10532.\n",
      "Epoch 34/300 done. Train accuracy: 97.50%, Test accuracy: 97.05%, Loss: 0.08566.\n",
      "Epoch 35/300 done. Train accuracy: 97.55%, Test accuracy: 96.63%, Loss: 0.09427.\n",
      "Epoch 36/300 done. Train accuracy: 97.65%, Test accuracy: 96.69%, Loss: 0.09351.\n",
      "Epoch 37/300 done. Train accuracy: 97.75%, Test accuracy: 96.75%, Loss: 0.07899.\n",
      "Epoch 38/300 done. Train accuracy: 97.45%, Test accuracy: 97.05%, Loss: 0.09788.\n",
      "Epoch 39/300 done. Train accuracy: 97.56%, Test accuracy: 97.20%, Loss: 0.09532.\n",
      "Epoch 40/300 done. Train accuracy: 97.61%, Test accuracy: 96.81%, Loss: 0.08736.\n",
      "Epoch 41/300 done. Train accuracy: 97.10%, Test accuracy: 97.02%, Loss: 0.11441.\n",
      "Epoch 42/300 done. Train accuracy: 97.76%, Test accuracy: 97.26%, Loss: 0.08731.\n",
      "Epoch 43/300 done. Train accuracy: 97.99%, Test accuracy: 97.29%, Loss: 0.07069.\n",
      "Epoch 44/300 done. Train accuracy: 97.92%, Test accuracy: 96.99%, Loss: 0.07762.\n",
      "Epoch 45/300 done. Train accuracy: 98.10%, Test accuracy: 97.20%, Loss: 0.06706.\n",
      "Epoch 46/300 done. Train accuracy: 98.15%, Test accuracy: 97.23%, Loss: 0.06708.\n",
      "Epoch 47/300 done. Train accuracy: 97.90%, Test accuracy: 97.08%, Loss: 0.07998.\n",
      "Epoch 48/300 done. Train accuracy: 98.15%, Test accuracy: 97.59%, Loss: 0.07433.\n",
      "Epoch 49/300 done. Train accuracy: 98.08%, Test accuracy: 97.30%, Loss: 0.06955.\n",
      "Epoch 50/300 done. Train accuracy: 97.89%, Test accuracy: 97.14%, Loss: 0.07680.\n",
      "Epoch 51/300 done. Train accuracy: 98.30%, Test accuracy: 97.66%, Loss: 0.06159.\n",
      "Epoch 52/300 done. Train accuracy: 98.21%, Test accuracy: 97.44%, Loss: 0.06251.\n",
      "Epoch 53/300 done. Train accuracy: 98.22%, Test accuracy: 97.47%, Loss: 0.06322.\n",
      "Epoch 54/300 done. Train accuracy: 98.07%, Test accuracy: 97.54%, Loss: 0.06613.\n",
      "Epoch 55/300 done. Train accuracy: 98.20%, Test accuracy: 97.47%, Loss: 0.06419.\n",
      "Epoch 56/300 done. Train accuracy: 98.28%, Test accuracy: 97.47%, Loss: 0.06323.\n",
      "Epoch 57/300 done. Train accuracy: 98.30%, Test accuracy: 97.26%, Loss: 0.05942.\n",
      "Epoch 58/300 done. Train accuracy: 98.14%, Test accuracy: 97.20%, Loss: 0.06609.\n",
      "Epoch 59/300 done. Train accuracy: 98.28%, Test accuracy: 97.38%, Loss: 0.06173.\n",
      "Epoch 60/300 done. Train accuracy: 98.35%, Test accuracy: 97.20%, Loss: 0.07028.\n",
      "Epoch 61/300 done. Train accuracy: 98.27%, Test accuracy: 97.59%, Loss: 0.06583.\n",
      "Epoch 62/300 done. Train accuracy: 98.41%, Test accuracy: 97.38%, Loss: 0.05741.\n",
      "Epoch 63/300 done. Train accuracy: 98.32%, Test accuracy: 97.50%, Loss: 0.05813.\n",
      "Epoch 64/300 done. Train accuracy: 98.45%, Test accuracy: 97.54%, Loss: 0.05613.\n",
      "Epoch 65/300 done. Train accuracy: 98.54%, Test accuracy: 97.62%, Loss: 0.05801.\n",
      "Epoch 66/300 done. Train accuracy: 98.50%, Test accuracy: 97.32%, Loss: 0.05653.\n",
      "Epoch 67/300 done. Train accuracy: 98.47%, Test accuracy: 97.65%, Loss: 0.05673.\n",
      "Epoch 68/300 done. Train accuracy: 98.27%, Test accuracy: 97.53%, Loss: 0.06487.\n",
      "Epoch 69/300 done. Train accuracy: 98.54%, Test accuracy: 97.41%, Loss: 0.05264.\n",
      "Epoch 70/300 done. Train accuracy: 98.36%, Test accuracy: 97.08%, Loss: 0.05893.\n",
      "Epoch 71/300 done. Train accuracy: 98.54%, Test accuracy: 97.54%, Loss: 0.05472.\n",
      "Epoch 72/300 done. Train accuracy: 98.41%, Test accuracy: 97.36%, Loss: 0.06168.\n",
      "Epoch 73/300 done. Train accuracy: 98.63%, Test accuracy: 97.56%, Loss: 0.05398.\n",
      "Epoch 74/300 done. Train accuracy: 98.40%, Test accuracy: 97.56%, Loss: 0.05855.\n",
      "Epoch 75/300 done. Train accuracy: 98.50%, Test accuracy: 97.35%, Loss: 0.05128.\n",
      "Epoch 76/300 done. Train accuracy: 98.40%, Test accuracy: 97.44%, Loss: 0.05990.\n",
      "Epoch 77/300 done. Train accuracy: 98.45%, Test accuracy: 97.50%, Loss: 0.05621.\n",
      "Epoch 78/300 done. Train accuracy: 98.40%, Test accuracy: 97.35%, Loss: 0.05760.\n",
      "Epoch 79/300 done. Train accuracy: 98.54%, Test accuracy: 97.47%, Loss: 0.05291.\n",
      "Epoch 80/300 done. Train accuracy: 98.50%, Test accuracy: 97.38%, Loss: 0.05415.\n",
      "Epoch 81/300 done. Train accuracy: 98.42%, Test accuracy: 97.72%, Loss: 0.05578.\n",
      "Epoch 82/300 done. Train accuracy: 98.53%, Test accuracy: 97.41%, Loss: 0.05201.\n",
      "Epoch 83/300 done. Train accuracy: 98.64%, Test accuracy: 97.47%, Loss: 0.05078.\n",
      "Epoch 84/300 done. Train accuracy: 98.55%, Test accuracy: 97.65%, Loss: 0.04987.\n",
      "Epoch 85/300 done. Train accuracy: 98.54%, Test accuracy: 97.35%, Loss: 0.05501.\n",
      "Epoch 86/300 done. Train accuracy: 98.58%, Test accuracy: 97.35%, Loss: 0.05022.\n",
      "Epoch 87/300 done. Train accuracy: 98.66%, Test accuracy: 97.26%, Loss: 0.04859.\n",
      "Epoch 88/300 done. Train accuracy: 98.46%, Test accuracy: 97.38%, Loss: 0.05810.\n",
      "Epoch 89/300 done. Train accuracy: 98.70%, Test accuracy: 97.35%, Loss: 0.04686.\n",
      "Epoch 90/300 done. Train accuracy: 98.46%, Test accuracy: 97.59%, Loss: 0.05470.\n",
      "Epoch 91/300 done. Train accuracy: 98.71%, Test accuracy: 97.41%, Loss: 0.04712.\n",
      "Epoch 92/300 done. Train accuracy: 98.52%, Test accuracy: 97.44%, Loss: 0.05164.\n",
      "Epoch 93/300 done. Train accuracy: 98.62%, Test accuracy: 97.26%, Loss: 0.04873.\n",
      "Epoch 94/300 done. Train accuracy: 98.60%, Test accuracy: 97.48%, Loss: 0.04813.\n",
      "Epoch 95/300 done. Train accuracy: 98.56%, Test accuracy: 97.59%, Loss: 0.05140.\n",
      "Epoch 96/300 done. Train accuracy: 98.60%, Test accuracy: 97.35%, Loss: 0.04970.\n",
      "Epoch 97/300 done. Train accuracy: 98.77%, Test accuracy: 97.20%, Loss: 0.04461.\n",
      "Epoch 98/300 done. Train accuracy: 98.41%, Test accuracy: 97.56%, Loss: 0.05315.\n",
      "Epoch 99/300 done. Train accuracy: 98.70%, Test accuracy: 97.56%, Loss: 0.04619.\n",
      "Epoch 100/300 done. Train accuracy: 98.47%, Test accuracy: 97.20%, Loss: 0.05177.\n",
      "Epoch 101/300 done. Train accuracy: 98.46%, Test accuracy: 97.77%, Loss: 0.05698.\n",
      "Epoch 102/300 done. Train accuracy: 98.48%, Test accuracy: 97.72%, Loss: 0.05171.\n",
      "Epoch 103/300 done. Train accuracy: 98.52%, Test accuracy: 97.35%, Loss: 0.04996.\n",
      "Epoch 104/300 done. Train accuracy: 98.57%, Test accuracy: 97.50%, Loss: 0.04992.\n",
      "Epoch 105/300 done. Train accuracy: 98.61%, Test accuracy: 97.44%, Loss: 0.04870.\n",
      "Epoch 106/300 done. Train accuracy: 98.53%, Test accuracy: 97.38%, Loss: 0.05041.\n",
      "Epoch 107/300 done. Train accuracy: 98.67%, Test accuracy: 97.38%, Loss: 0.04679.\n",
      "Epoch 108/300 done. Train accuracy: 98.77%, Test accuracy: 97.50%, Loss: 0.04420.\n",
      "Epoch 109/300 done. Train accuracy: 98.67%, Test accuracy: 97.62%, Loss: 0.04638.\n",
      "Epoch 110/300 done. Train accuracy: 98.57%, Test accuracy: 97.71%, Loss: 0.05107.\n",
      "Epoch 111/300 done. Train accuracy: 98.64%, Test accuracy: 97.38%, Loss: 0.04810.\n",
      "Epoch 112/300 done. Train accuracy: 98.62%, Test accuracy: 97.56%, Loss: 0.04904.\n",
      "Epoch 113/300 done. Train accuracy: 98.70%, Test accuracy: 97.74%, Loss: 0.04552.\n",
      "Epoch 114/300 done. Train accuracy: 98.71%, Test accuracy: 97.35%, Loss: 0.04701.\n",
      "Epoch 115/300 done. Train accuracy: 98.61%, Test accuracy: 97.44%, Loss: 0.04805.\n",
      "Epoch 116/300 done. Train accuracy: 98.67%, Test accuracy: 97.20%, Loss: 0.04838.\n",
      "Epoch 117/300 done. Train accuracy: 98.66%, Test accuracy: 97.32%, Loss: 0.04829.\n",
      "Epoch 118/300 done. Train accuracy: 98.54%, Test accuracy: 97.41%, Loss: 0.05249.\n",
      "Epoch 119/300 done. Train accuracy: 98.48%, Test accuracy: 97.17%, Loss: 0.05047.\n",
      "Epoch 120/300 done. Train accuracy: 98.62%, Test accuracy: 97.53%, Loss: 0.04719.\n",
      "Epoch 121/300 done. Train accuracy: 98.64%, Test accuracy: 97.41%, Loss: 0.04930.\n",
      "Epoch 122/300 done. Train accuracy: 98.53%, Test accuracy: 97.29%, Loss: 0.04928.\n",
      "Epoch 123/300 done. Train accuracy: 98.63%, Test accuracy: 97.32%, Loss: 0.04690.\n",
      "Epoch 124/300 done. Train accuracy: 98.61%, Test accuracy: 97.41%, Loss: 0.05068.\n",
      "Epoch 125/300 done. Train accuracy: 98.68%, Test accuracy: 97.60%, Loss: 0.04533.\n",
      "Epoch 126/300 done. Train accuracy: 98.63%, Test accuracy: 96.93%, Loss: 0.04883.\n",
      "Epoch 127/300 done. Train accuracy: 98.65%, Test accuracy: 97.32%, Loss: 0.04633.\n",
      "Epoch 128/300 done. Train accuracy: 98.69%, Test accuracy: 97.41%, Loss: 0.04814.\n",
      "Epoch 129/300 done. Train accuracy: 98.57%, Test accuracy: 97.26%, Loss: 0.04931.\n",
      "Epoch 130/300 done. Train accuracy: 98.70%, Test accuracy: 97.20%, Loss: 0.04647.\n",
      "Epoch 131/300 done. Train accuracy: 98.72%, Test accuracy: 97.53%, Loss: 0.04639.\n",
      "Epoch 132/300 done. Train accuracy: 98.72%, Test accuracy: 97.38%, Loss: 0.04655.\n",
      "Epoch 133/300 done. Train accuracy: 98.67%, Test accuracy: 97.71%, Loss: 0.04542.\n",
      "Epoch 134/300 done. Train accuracy: 98.70%, Test accuracy: 97.71%, Loss: 0.04506.\n",
      "Epoch 135/300 done. Train accuracy: 98.56%, Test accuracy: 97.68%, Loss: 0.04799.\n",
      "Epoch 136/300 done. Train accuracy: 98.66%, Test accuracy: 97.50%, Loss: 0.04861.\n",
      "Epoch 137/300 done. Train accuracy: 98.62%, Test accuracy: 97.72%, Loss: 0.04930.\n",
      "Epoch 138/300 done. Train accuracy: 98.66%, Test accuracy: 97.68%, Loss: 0.05058.\n",
      "Epoch 139/300 done. Train accuracy: 98.67%, Test accuracy: 97.38%, Loss: 0.04620.\n",
      "Epoch 140/300 done. Train accuracy: 98.54%, Test accuracy: 97.47%, Loss: 0.04909.\n",
      "Epoch 141/300 done. Train accuracy: 98.72%, Test accuracy: 97.74%, Loss: 0.04613.\n",
      "Epoch 142/300 done. Train accuracy: 98.79%, Test accuracy: 97.77%, Loss: 0.04314.\n",
      "Epoch 143/300 done. Train accuracy: 98.60%, Test accuracy: 97.26%, Loss: 0.04684.\n",
      "Epoch 144/300 done. Train accuracy: 98.65%, Test accuracy: 97.50%, Loss: 0.04449.\n",
      "Epoch 145/300 done. Train accuracy: 98.77%, Test accuracy: 97.41%, Loss: 0.04449.\n",
      "Epoch 146/300 done. Train accuracy: 98.79%, Test accuracy: 97.38%, Loss: 0.04387.\n",
      "Epoch 147/300 done. Train accuracy: 98.58%, Test accuracy: 97.47%, Loss: 0.04951.\n",
      "Epoch 148/300 done. Train accuracy: 98.79%, Test accuracy: 97.41%, Loss: 0.04422.\n",
      "Epoch 149/300 done. Train accuracy: 98.62%, Test accuracy: 97.47%, Loss: 0.04617.\n",
      "Epoch 150/300 done. Train accuracy: 98.61%, Test accuracy: 97.50%, Loss: 0.04592.\n",
      "Epoch 151/300 done. Train accuracy: 98.75%, Test accuracy: 97.08%, Loss: 0.04313.\n",
      "Epoch 152/300 done. Train accuracy: 98.74%, Test accuracy: 97.48%, Loss: 0.04486.\n",
      "Epoch 153/300 done. Train accuracy: 98.55%, Test accuracy: 97.74%, Loss: 0.04915.\n",
      "Epoch 154/300 done. Train accuracy: 98.65%, Test accuracy: 97.68%, Loss: 0.04937.\n",
      "Epoch 155/300 done. Train accuracy: 98.73%, Test accuracy: 97.53%, Loss: 0.04468.\n",
      "Epoch 156/300 done. Train accuracy: 98.73%, Test accuracy: 97.32%, Loss: 0.04426.\n",
      "Epoch 157/300 done. Train accuracy: 98.72%, Test accuracy: 97.44%, Loss: 0.04838.\n",
      "Epoch 158/300 done. Train accuracy: 98.77%, Test accuracy: 97.26%, Loss: 0.04307.\n",
      "Epoch 159/300 done. Train accuracy: 98.63%, Test accuracy: 97.60%, Loss: 0.04789.\n",
      "Epoch 160/300 done. Train accuracy: 98.65%, Test accuracy: 97.32%, Loss: 0.04589.\n",
      "Epoch 161/300 done. Train accuracy: 98.64%, Test accuracy: 97.68%, Loss: 0.04628.\n",
      "Epoch 162/300 done. Train accuracy: 98.71%, Test accuracy: 97.47%, Loss: 0.04448.\n",
      "Epoch 163/300 done. Train accuracy: 98.70%, Test accuracy: 97.47%, Loss: 0.04403.\n",
      "Epoch 164/300 done. Train accuracy: 98.65%, Test accuracy: 97.50%, Loss: 0.04509.\n",
      "Epoch 165/300 done. Train accuracy: 98.69%, Test accuracy: 97.54%, Loss: 0.04601.\n",
      "Epoch 166/300 done. Train accuracy: 98.64%, Test accuracy: 97.59%, Loss: 0.04932.\n",
      "Epoch 167/300 done. Train accuracy: 98.68%, Test accuracy: 97.56%, Loss: 0.04527.\n",
      "Epoch 168/300 done. Train accuracy: 98.76%, Test accuracy: 97.65%, Loss: 0.04301.\n",
      "Epoch 169/300 done. Train accuracy: 98.72%, Test accuracy: 97.83%, Loss: 0.04551.\n",
      "Epoch 170/300 done. Train accuracy: 98.75%, Test accuracy: 97.38%, Loss: 0.04456.\n",
      "Epoch 171/300 done. Train accuracy: 98.66%, Test accuracy: 97.68%, Loss: 0.04615.\n",
      "Epoch 172/300 done. Train accuracy: 98.85%, Test accuracy: 97.56%, Loss: 0.04198.\n",
      "Epoch 173/300 done. Train accuracy: 98.61%, Test accuracy: 97.35%, Loss: 0.04660.\n",
      "Epoch 174/300 done. Train accuracy: 98.65%, Test accuracy: 97.59%, Loss: 0.04564.\n",
      "Epoch 175/300 done. Train accuracy: 98.72%, Test accuracy: 97.53%, Loss: 0.04393.\n",
      "Epoch 176/300 done. Train accuracy: 98.79%, Test accuracy: 97.54%, Loss: 0.04360.\n",
      "Epoch 177/300 done. Train accuracy: 98.73%, Test accuracy: 97.74%, Loss: 0.04517.\n",
      "Epoch 178/300 done. Train accuracy: 98.63%, Test accuracy: 97.26%, Loss: 0.04713.\n",
      "Epoch 179/300 done. Train accuracy: 98.67%, Test accuracy: 97.68%, Loss: 0.04607.\n",
      "Epoch 180/300 done. Train accuracy: 98.73%, Test accuracy: 97.68%, Loss: 0.04380.\n",
      "Epoch 181/300 done. Train accuracy: 98.74%, Test accuracy: 97.65%, Loss: 0.04365.\n",
      "Epoch 182/300 done. Train accuracy: 98.77%, Test accuracy: 97.59%, Loss: 0.04404.\n",
      "Epoch 183/300 done. Train accuracy: 98.73%, Test accuracy: 97.44%, Loss: 0.04269.\n",
      "Epoch 184/300 done. Train accuracy: 98.61%, Test accuracy: 97.17%, Loss: 0.04692.\n",
      "Epoch 185/300 done. Train accuracy: 98.66%, Test accuracy: 96.99%, Loss: 0.04524.\n",
      "Epoch 186/300 done. Train accuracy: 98.75%, Test accuracy: 97.56%, Loss: 0.04351.\n",
      "Epoch 187/300 done. Train accuracy: 98.80%, Test accuracy: 97.29%, Loss: 0.04268.\n",
      "Epoch 188/300 done. Train accuracy: 98.72%, Test accuracy: 97.60%, Loss: 0.04365.\n",
      "Epoch 189/300 done. Train accuracy: 98.73%, Test accuracy: 97.35%, Loss: 0.04520.\n",
      "Epoch 190/300 done. Train accuracy: 98.73%, Test accuracy: 97.66%, Loss: 0.04288.\n",
      "Epoch 191/300 done. Train accuracy: 98.77%, Test accuracy: 97.41%, Loss: 0.04255.\n",
      "Epoch 192/300 done. Train accuracy: 98.71%, Test accuracy: 97.81%, Loss: 0.04321.\n",
      "Epoch 193/300 done. Train accuracy: 98.77%, Test accuracy: 97.32%, Loss: 0.04380.\n",
      "Epoch 194/300 done. Train accuracy: 98.78%, Test accuracy: 97.50%, Loss: 0.04226.\n",
      "Epoch 195/300 done. Train accuracy: 98.71%, Test accuracy: 97.59%, Loss: 0.04444.\n",
      "Epoch 196/300 done. Train accuracy: 98.67%, Test accuracy: 97.81%, Loss: 0.04440.\n",
      "Epoch 197/300 done. Train accuracy: 98.71%, Test accuracy: 97.93%, Loss: 0.04353.\n",
      "Epoch 198/300 done. Train accuracy: 98.62%, Test accuracy: 97.56%, Loss: 0.04645.\n",
      "Epoch 199/300 done. Train accuracy: 98.71%, Test accuracy: 97.38%, Loss: 0.04424.\n",
      "Epoch 200/300 done. Train accuracy: 98.77%, Test accuracy: 97.50%, Loss: 0.04193.\n",
      "Epoch 201/300 done. Train accuracy: 98.67%, Test accuracy: 97.38%, Loss: 0.04487.\n",
      "Epoch 202/300 done. Train accuracy: 98.70%, Test accuracy: 97.50%, Loss: 0.04407.\n",
      "Epoch 203/300 done. Train accuracy: 98.73%, Test accuracy: 97.56%, Loss: 0.04256.\n",
      "Epoch 204/300 done. Train accuracy: 98.73%, Test accuracy: 97.74%, Loss: 0.04376.\n",
      "Epoch 205/300 done. Train accuracy: 98.71%, Test accuracy: 97.26%, Loss: 0.04450.\n",
      "Epoch 206/300 done. Train accuracy: 98.68%, Test accuracy: 97.50%, Loss: 0.04446.\n",
      "Epoch 207/300 done. Train accuracy: 98.73%, Test accuracy: 97.42%, Loss: 0.04388.\n",
      "Epoch 208/300 done. Train accuracy: 98.73%, Test accuracy: 97.38%, Loss: 0.04479.\n",
      "Epoch 209/300 done. Train accuracy: 98.70%, Test accuracy: 97.26%, Loss: 0.04455.\n",
      "Epoch 210/300 done. Train accuracy: 98.73%, Test accuracy: 97.56%, Loss: 0.04346.\n",
      "Epoch 211/300 done. Train accuracy: 98.76%, Test accuracy: 97.68%, Loss: 0.04361.\n",
      "Epoch 212/300 done. Train accuracy: 98.67%, Test accuracy: 97.50%, Loss: 0.04686.\n",
      "Epoch 213/300 done. Train accuracy: 98.71%, Test accuracy: 97.77%, Loss: 0.04435.\n",
      "Epoch 214/300 done. Train accuracy: 98.70%, Test accuracy: 97.68%, Loss: 0.04469.\n",
      "Epoch 215/300 done. Train accuracy: 98.64%, Test accuracy: 97.26%, Loss: 0.04609.\n",
      "Epoch 216/300 done. Train accuracy: 98.67%, Test accuracy: 97.68%, Loss: 0.04454.\n",
      "Epoch 217/300 done. Train accuracy: 98.77%, Test accuracy: 97.59%, Loss: 0.04324.\n",
      "Epoch 218/300 done. Train accuracy: 98.70%, Test accuracy: 97.50%, Loss: 0.04589.\n",
      "Epoch 219/300 done. Train accuracy: 98.70%, Test accuracy: 97.54%, Loss: 0.04437.\n",
      "Epoch 220/300 done. Train accuracy: 98.69%, Test accuracy: 97.48%, Loss: 0.04480.\n",
      "Epoch 221/300 done. Train accuracy: 98.79%, Test accuracy: 97.48%, Loss: 0.04238.\n",
      "Epoch 222/300 done. Train accuracy: 98.74%, Test accuracy: 97.74%, Loss: 0.04318.\n",
      "Epoch 223/300 done. Train accuracy: 98.73%, Test accuracy: 97.26%, Loss: 0.04447.\n",
      "Epoch 224/300 done. Train accuracy: 98.85%, Test accuracy: 97.23%, Loss: 0.04194.\n",
      "Epoch 225/300 done. Train accuracy: 98.69%, Test accuracy: 97.08%, Loss: 0.04512.\n",
      "Epoch 226/300 done. Train accuracy: 98.77%, Test accuracy: 97.05%, Loss: 0.04327.\n",
      "Epoch 227/300 done. Train accuracy: 98.67%, Test accuracy: 97.47%, Loss: 0.04510.\n",
      "Epoch 228/300 done. Train accuracy: 98.78%, Test accuracy: 97.35%, Loss: 0.04282.\n",
      "Epoch 229/300 done. Train accuracy: 98.76%, Test accuracy: 97.54%, Loss: 0.04318.\n",
      "Epoch 230/300 done. Train accuracy: 98.75%, Test accuracy: 97.29%, Loss: 0.04422.\n",
      "Epoch 231/300 done. Train accuracy: 98.74%, Test accuracy: 97.47%, Loss: 0.04292.\n",
      "Epoch 232/300 done. Train accuracy: 98.74%, Test accuracy: 97.60%, Loss: 0.04309.\n",
      "Epoch 233/300 done. Train accuracy: 98.78%, Test accuracy: 97.20%, Loss: 0.04201.\n",
      "Epoch 234/300 done. Train accuracy: 98.81%, Test accuracy: 97.29%, Loss: 0.04178.\n",
      "Epoch 235/300 done. Train accuracy: 98.67%, Test accuracy: 97.38%, Loss: 0.04499.\n",
      "Epoch 236/300 done. Train accuracy: 98.64%, Test accuracy: 96.87%, Loss: 0.04409.\n",
      "Epoch 237/300 done. Train accuracy: 98.69%, Test accuracy: 97.14%, Loss: 0.04507.\n",
      "Epoch 238/300 done. Train accuracy: 98.78%, Test accuracy: 97.35%, Loss: 0.04255.\n",
      "Epoch 239/300 done. Train accuracy: 98.81%, Test accuracy: 97.23%, Loss: 0.04166.\n",
      "Epoch 240/300 done. Train accuracy: 98.79%, Test accuracy: 97.41%, Loss: 0.04297.\n",
      "Epoch 241/300 done. Train accuracy: 98.73%, Test accuracy: 97.38%, Loss: 0.04666.\n",
      "Epoch 242/300 done. Train accuracy: 98.77%, Test accuracy: 97.47%, Loss: 0.04280.\n",
      "Epoch 243/300 done. Train accuracy: 98.76%, Test accuracy: 97.44%, Loss: 0.04389.\n",
      "Epoch 244/300 done. Train accuracy: 98.81%, Test accuracy: 97.41%, Loss: 0.04163.\n",
      "Epoch 245/300 done. Train accuracy: 98.67%, Test accuracy: 97.47%, Loss: 0.04428.\n",
      "Epoch 246/300 done. Train accuracy: 98.76%, Test accuracy: 97.53%, Loss: 0.04372.\n",
      "Epoch 247/300 done. Train accuracy: 98.78%, Test accuracy: 97.20%, Loss: 0.04233.\n",
      "Epoch 248/300 done. Train accuracy: 98.73%, Test accuracy: 97.47%, Loss: 0.04340.\n",
      "Epoch 249/300 done. Train accuracy: 98.76%, Test accuracy: 97.56%, Loss: 0.04384.\n",
      "Epoch 250/300 done. Train accuracy: 98.77%, Test accuracy: 97.50%, Loss: 0.04309.\n",
      "Epoch 251/300 done. Train accuracy: 98.77%, Test accuracy: 97.38%, Loss: 0.04257.\n",
      "Epoch 252/300 done. Train accuracy: 98.75%, Test accuracy: 97.23%, Loss: 0.04346.\n",
      "Epoch 253/300 done. Train accuracy: 98.70%, Test accuracy: 97.41%, Loss: 0.04342.\n",
      "Epoch 254/300 done. Train accuracy: 98.76%, Test accuracy: 97.74%, Loss: 0.04362.\n",
      "Epoch 255/300 done. Train accuracy: 98.74%, Test accuracy: 97.26%, Loss: 0.04325.\n",
      "Epoch 256/300 done. Train accuracy: 98.65%, Test accuracy: 97.68%, Loss: 0.04488.\n",
      "Epoch 257/300 done. Train accuracy: 98.75%, Test accuracy: 97.02%, Loss: 0.04293.\n",
      "Epoch 258/300 done. Train accuracy: 98.75%, Test accuracy: 97.48%, Loss: 0.04538.\n",
      "Epoch 259/300 done. Train accuracy: 98.75%, Test accuracy: 97.62%, Loss: 0.04370.\n",
      "Epoch 260/300 done. Train accuracy: 98.80%, Test accuracy: 97.17%, Loss: 0.04160.\n",
      "Epoch 261/300 done. Train accuracy: 98.80%, Test accuracy: 97.35%, Loss: 0.04282.\n",
      "Epoch 262/300 done. Train accuracy: 98.73%, Test accuracy: 97.30%, Loss: 0.04412.\n",
      "Epoch 263/300 done. Train accuracy: 98.69%, Test accuracy: 97.36%, Loss: 0.04402.\n",
      "Epoch 264/300 done. Train accuracy: 98.77%, Test accuracy: 97.20%, Loss: 0.04306.\n",
      "Epoch 265/300 done. Train accuracy: 98.77%, Test accuracy: 97.38%, Loss: 0.04243.\n",
      "Epoch 266/300 done. Train accuracy: 98.74%, Test accuracy: 97.35%, Loss: 0.04246.\n",
      "Epoch 267/300 done. Train accuracy: 98.66%, Test accuracy: 97.35%, Loss: 0.04514.\n",
      "Epoch 268/300 done. Train accuracy: 98.72%, Test accuracy: 96.99%, Loss: 0.04494.\n",
      "Epoch 269/300 done. Train accuracy: 98.67%, Test accuracy: 97.32%, Loss: 0.04530.\n",
      "Epoch 270/300 done. Train accuracy: 98.78%, Test accuracy: 97.48%, Loss: 0.04280.\n",
      "Epoch 271/300 done. Train accuracy: 98.73%, Test accuracy: 97.48%, Loss: 0.04412.\n",
      "Epoch 272/300 done. Train accuracy: 98.58%, Test accuracy: 97.14%, Loss: 0.04721.\n",
      "Epoch 273/300 done. Train accuracy: 98.78%, Test accuracy: 97.44%, Loss: 0.04329.\n",
      "Epoch 274/300 done. Train accuracy: 98.79%, Test accuracy: 97.20%, Loss: 0.04197.\n",
      "Epoch 275/300 done. Train accuracy: 98.81%, Test accuracy: 97.32%, Loss: 0.04231.\n",
      "Epoch 276/300 done. Train accuracy: 98.76%, Test accuracy: 97.08%, Loss: 0.04308.\n",
      "Epoch 277/300 done. Train accuracy: 98.77%, Test accuracy: 97.29%, Loss: 0.04226.\n",
      "Epoch 278/300 done. Train accuracy: 98.71%, Test accuracy: 96.99%, Loss: 0.04397.\n",
      "Epoch 279/300 done. Train accuracy: 98.68%, Test accuracy: 97.23%, Loss: 0.04452.\n",
      "Epoch 280/300 done. Train accuracy: 98.75%, Test accuracy: 97.23%, Loss: 0.04298.\n",
      "Epoch 281/300 done. Train accuracy: 98.72%, Test accuracy: 97.17%, Loss: 0.04472.\n",
      "Epoch 282/300 done. Train accuracy: 98.67%, Test accuracy: 97.20%, Loss: 0.04551.\n",
      "Epoch 283/300 done. Train accuracy: 98.80%, Test accuracy: 97.11%, Loss: 0.04141.\n",
      "Epoch 284/300 done. Train accuracy: 98.73%, Test accuracy: 97.53%, Loss: 0.04344.\n",
      "Epoch 285/300 done. Train accuracy: 98.80%, Test accuracy: 96.72%, Loss: 0.04243.\n",
      "Epoch 286/300 done. Train accuracy: 98.73%, Test accuracy: 97.32%, Loss: 0.04372.\n",
      "Epoch 287/300 done. Train accuracy: 98.73%, Test accuracy: 97.42%, Loss: 0.04373.\n",
      "Epoch 288/300 done. Train accuracy: 98.72%, Test accuracy: 97.26%, Loss: 0.04435.\n",
      "Epoch 289/300 done. Train accuracy: 98.67%, Test accuracy: 97.50%, Loss: 0.04409.\n",
      "Epoch 290/300 done. Train accuracy: 98.71%, Test accuracy: 97.11%, Loss: 0.04382.\n",
      "Epoch 291/300 done. Train accuracy: 98.74%, Test accuracy: 97.23%, Loss: 0.04226.\n",
      "Epoch 292/300 done. Train accuracy: 98.76%, Test accuracy: 97.47%, Loss: 0.04431.\n",
      "Epoch 293/300 done. Train accuracy: 98.81%, Test accuracy: 97.29%, Loss: 0.04199.\n",
      "Epoch 294/300 done. Train accuracy: 98.73%, Test accuracy: 97.23%, Loss: 0.04254.\n",
      "Epoch 295/300 done. Train accuracy: 98.67%, Test accuracy: 97.11%, Loss: 0.04414.\n",
      "Epoch 296/300 done. Train accuracy: 98.75%, Test accuracy: 97.23%, Loss: 0.04191.\n",
      "Epoch 297/300 done. Train accuracy: 98.68%, Test accuracy: 97.41%, Loss: 0.04495.\n",
      "Epoch 298/300 done. Train accuracy: 98.78%, Test accuracy: 97.56%, Loss: 0.04223.\n",
      "Epoch 299/300 done. Train accuracy: 98.71%, Test accuracy: 97.48%, Loss: 0.04368.\n",
      "Epoch 300/300 done. Train accuracy: 98.67%, Test accuracy: 97.32%, Loss: 0.04370.\n",
      "Final results: \n",
      "Best training accuracy: 98.85% and according test accuracy: 97.56% at epoch: 172\n",
      "Best test accuracy: 97.93% and according train accuracy: 98.71% at epoch: 197\n",
      "------------------------------------------------------------------------------------\n",
      "\n",
      "Epoch 1/300 done. Train accuracy: 10.53%, Test accuracy: 20.25%, Loss: 18.12985.\n",
      "Epoch 2/300 done. Train accuracy: 20.61%, Test accuracy: 31.35%, Loss: 6.93469.\n",
      "Epoch 3/300 done. Train accuracy: 32.23%, Test accuracy: 47.50%, Loss: 3.03999.\n",
      "Epoch 4/300 done. Train accuracy: 45.93%, Test accuracy: 57.85%, Loss: 2.64504.\n",
      "Epoch 5/300 done. Train accuracy: 53.75%, Test accuracy: 66.40%, Loss: 2.04156.\n",
      "Epoch 6/300 done. Train accuracy: 64.64%, Test accuracy: 74.01%, Loss: 1.41975.\n",
      "Epoch 7/300 done. Train accuracy: 69.50%, Test accuracy: 77.65%, Loss: 1.39719.\n",
      "Epoch 8/300 done. Train accuracy: 74.04%, Test accuracy: 83.27%, Loss: 1.10953.\n",
      "Epoch 9/300 done. Train accuracy: 81.77%, Test accuracy: 86.70%, Loss: 0.63592.\n",
      "Epoch 10/300 done. Train accuracy: 85.02%, Test accuracy: 88.90%, Loss: 0.54089.\n",
      "Epoch 11/300 done. Train accuracy: 86.25%, Test accuracy: 91.76%, Loss: 0.58299.\n",
      "Epoch 12/300 done. Train accuracy: 89.23%, Test accuracy: 93.56%, Loss: 0.38068.\n",
      "Epoch 13/300 done. Train accuracy: 89.45%, Test accuracy: 93.35%, Loss: 0.44441.\n",
      "Epoch 14/300 done. Train accuracy: 91.40%, Test accuracy: 93.50%, Loss: 0.33132.\n",
      "Epoch 15/300 done. Train accuracy: 91.43%, Test accuracy: 94.53%, Loss: 0.32941.\n",
      "Epoch 16/300 done. Train accuracy: 92.58%, Test accuracy: 95.64%, Loss: 0.29772.\n",
      "Epoch 17/300 done. Train accuracy: 94.25%, Test accuracy: 96.21%, Loss: 0.20264.\n",
      "Epoch 18/300 done. Train accuracy: 94.23%, Test accuracy: 95.16%, Loss: 0.21781.\n",
      "Epoch 19/300 done. Train accuracy: 95.78%, Test accuracy: 96.21%, Loss: 0.14740.\n",
      "Epoch 20/300 done. Train accuracy: 96.06%, Test accuracy: 96.63%, Loss: 0.13885.\n",
      "Epoch 21/300 done. Train accuracy: 96.27%, Test accuracy: 96.30%, Loss: 0.14765.\n",
      "Epoch 22/300 done. Train accuracy: 96.57%, Test accuracy: 96.60%, Loss: 0.12442.\n",
      "Epoch 23/300 done. Train accuracy: 96.33%, Test accuracy: 95.34%, Loss: 0.14132.\n",
      "Epoch 24/300 done. Train accuracy: 97.20%, Test accuracy: 96.48%, Loss: 0.10044.\n",
      "Epoch 25/300 done. Train accuracy: 97.20%, Test accuracy: 97.20%, Loss: 0.10568.\n",
      "Epoch 26/300 done. Train accuracy: 96.42%, Test accuracy: 96.75%, Loss: 0.14398.\n",
      "Epoch 27/300 done. Train accuracy: 96.74%, Test accuracy: 97.50%, Loss: 0.15734.\n",
      "Epoch 28/300 done. Train accuracy: 97.33%, Test accuracy: 96.93%, Loss: 0.09730.\n",
      "Epoch 29/300 done. Train accuracy: 96.82%, Test accuracy: 97.08%, Loss: 0.13403.\n",
      "Epoch 30/300 done. Train accuracy: 97.56%, Test accuracy: 96.99%, Loss: 0.08856.\n",
      "Epoch 31/300 done. Train accuracy: 97.40%, Test accuracy: 97.17%, Loss: 0.09669.\n",
      "Epoch 32/300 done. Train accuracy: 97.04%, Test accuracy: 97.24%, Loss: 0.14108.\n",
      "Epoch 33/300 done. Train accuracy: 97.28%, Test accuracy: 97.08%, Loss: 0.10761.\n",
      "Epoch 34/300 done. Train accuracy: 97.86%, Test accuracy: 96.99%, Loss: 0.07901.\n",
      "Epoch 35/300 done. Train accuracy: 97.35%, Test accuracy: 97.47%, Loss: 0.10566.\n",
      "Epoch 36/300 done. Train accuracy: 97.69%, Test accuracy: 96.69%, Loss: 0.08858.\n",
      "Epoch 37/300 done. Train accuracy: 97.49%, Test accuracy: 97.62%, Loss: 0.09600.\n",
      "Epoch 38/300 done. Train accuracy: 97.75%, Test accuracy: 97.02%, Loss: 0.08220.\n",
      "Epoch 39/300 done. Train accuracy: 98.05%, Test accuracy: 97.23%, Loss: 0.07331.\n",
      "Epoch 40/300 done. Train accuracy: 97.46%, Test accuracy: 97.68%, Loss: 0.12225.\n",
      "Epoch 41/300 done. Train accuracy: 98.19%, Test accuracy: 97.23%, Loss: 0.06529.\n",
      "Epoch 42/300 done. Train accuracy: 98.04%, Test accuracy: 97.26%, Loss: 0.08450.\n",
      "Epoch 43/300 done. Train accuracy: 98.15%, Test accuracy: 97.44%, Loss: 0.06742.\n",
      "Epoch 44/300 done. Train accuracy: 98.19%, Test accuracy: 96.33%, Loss: 0.06532.\n",
      "Epoch 45/300 done. Train accuracy: 98.17%, Test accuracy: 97.17%, Loss: 0.06663.\n",
      "Epoch 46/300 done. Train accuracy: 97.85%, Test accuracy: 97.56%, Loss: 0.08452.\n",
      "Epoch 47/300 done. Train accuracy: 98.26%, Test accuracy: 97.29%, Loss: 0.05985.\n",
      "Epoch 48/300 done. Train accuracy: 98.38%, Test accuracy: 97.35%, Loss: 0.05867.\n",
      "Epoch 49/300 done. Train accuracy: 97.99%, Test accuracy: 97.08%, Loss: 0.06919.\n",
      "Epoch 50/300 done. Train accuracy: 97.99%, Test accuracy: 97.44%, Loss: 0.07300.\n",
      "Epoch 51/300 done. Train accuracy: 98.34%, Test accuracy: 97.65%, Loss: 0.06460.\n",
      "Epoch 52/300 done. Train accuracy: 98.34%, Test accuracy: 97.35%, Loss: 0.06367.\n",
      "Epoch 53/300 done. Train accuracy: 98.42%, Test accuracy: 97.41%, Loss: 0.05713.\n",
      "Epoch 54/300 done. Train accuracy: 98.35%, Test accuracy: 97.74%, Loss: 0.06212.\n",
      "Epoch 55/300 done. Train accuracy: 98.43%, Test accuracy: 97.56%, Loss: 0.06154.\n",
      "Epoch 56/300 done. Train accuracy: 98.42%, Test accuracy: 97.87%, Loss: 0.05887.\n",
      "Epoch 57/300 done. Train accuracy: 98.41%, Test accuracy: 97.50%, Loss: 0.05442.\n",
      "Epoch 58/300 done. Train accuracy: 98.08%, Test accuracy: 97.08%, Loss: 0.06794.\n",
      "Epoch 59/300 done. Train accuracy: 98.18%, Test accuracy: 97.60%, Loss: 0.06880.\n",
      "Epoch 60/300 done. Train accuracy: 98.31%, Test accuracy: 97.56%, Loss: 0.06150.\n",
      "Epoch 61/300 done. Train accuracy: 98.18%, Test accuracy: 97.14%, Loss: 0.06750.\n",
      "Epoch 62/300 done. Train accuracy: 98.13%, Test accuracy: 97.38%, Loss: 0.06634.\n",
      "Epoch 63/300 done. Train accuracy: 98.31%, Test accuracy: 97.02%, Loss: 0.05947.\n",
      "Epoch 64/300 done. Train accuracy: 98.29%, Test accuracy: 97.50%, Loss: 0.06342.\n",
      "Epoch 65/300 done. Train accuracy: 98.40%, Test accuracy: 97.74%, Loss: 0.06584.\n",
      "Epoch 66/300 done. Train accuracy: 98.51%, Test accuracy: 97.59%, Loss: 0.05333.\n",
      "Epoch 67/300 done. Train accuracy: 98.62%, Test accuracy: 97.53%, Loss: 0.05053.\n",
      "Epoch 68/300 done. Train accuracy: 98.56%, Test accuracy: 97.29%, Loss: 0.05538.\n",
      "Epoch 69/300 done. Train accuracy: 98.27%, Test accuracy: 97.41%, Loss: 0.06617.\n",
      "Epoch 70/300 done. Train accuracy: 98.60%, Test accuracy: 97.90%, Loss: 0.05195.\n",
      "Epoch 71/300 done. Train accuracy: 98.45%, Test accuracy: 97.44%, Loss: 0.05362.\n",
      "Epoch 72/300 done. Train accuracy: 98.42%, Test accuracy: 97.72%, Loss: 0.05692.\n",
      "Epoch 73/300 done. Train accuracy: 98.69%, Test accuracy: 97.60%, Loss: 0.05219.\n",
      "Epoch 74/300 done. Train accuracy: 98.48%, Test accuracy: 97.38%, Loss: 0.05336.\n",
      "Epoch 75/300 done. Train accuracy: 98.35%, Test accuracy: 98.05%, Loss: 0.05762.\n",
      "Epoch 76/300 done. Train accuracy: 98.47%, Test accuracy: 97.59%, Loss: 0.05269.\n",
      "Epoch 77/300 done. Train accuracy: 98.52%, Test accuracy: 97.17%, Loss: 0.05315.\n",
      "Epoch 78/300 done. Train accuracy: 98.49%, Test accuracy: 97.32%, Loss: 0.05515.\n",
      "Epoch 79/300 done. Train accuracy: 98.54%, Test accuracy: 97.59%, Loss: 0.05210.\n",
      "Epoch 80/300 done. Train accuracy: 98.37%, Test accuracy: 97.44%, Loss: 0.05590.\n",
      "Epoch 81/300 done. Train accuracy: 98.62%, Test accuracy: 97.17%, Loss: 0.04976.\n",
      "Epoch 82/300 done. Train accuracy: 98.55%, Test accuracy: 97.50%, Loss: 0.05067.\n",
      "Epoch 83/300 done. Train accuracy: 98.37%, Test accuracy: 97.23%, Loss: 0.05654.\n",
      "Epoch 84/300 done. Train accuracy: 98.56%, Test accuracy: 97.62%, Loss: 0.05104.\n",
      "Epoch 85/300 done. Train accuracy: 98.67%, Test accuracy: 97.35%, Loss: 0.04981.\n",
      "Epoch 86/300 done. Train accuracy: 98.70%, Test accuracy: 97.29%, Loss: 0.04589.\n",
      "Epoch 87/300 done. Train accuracy: 98.52%, Test accuracy: 97.44%, Loss: 0.05597.\n",
      "Epoch 88/300 done. Train accuracy: 98.44%, Test accuracy: 97.23%, Loss: 0.05191.\n",
      "Epoch 89/300 done. Train accuracy: 98.41%, Test accuracy: 97.41%, Loss: 0.05419.\n",
      "Epoch 90/300 done. Train accuracy: 98.66%, Test accuracy: 97.35%, Loss: 0.04972.\n",
      "Epoch 91/300 done. Train accuracy: 98.62%, Test accuracy: 97.44%, Loss: 0.04852.\n",
      "Epoch 92/300 done. Train accuracy: 98.64%, Test accuracy: 97.23%, Loss: 0.04843.\n",
      "Epoch 93/300 done. Train accuracy: 98.63%, Test accuracy: 97.59%, Loss: 0.04900.\n",
      "Epoch 94/300 done. Train accuracy: 98.54%, Test accuracy: 97.83%, Loss: 0.05268.\n",
      "Epoch 95/300 done. Train accuracy: 98.61%, Test accuracy: 97.26%, Loss: 0.04784.\n",
      "Epoch 96/300 done. Train accuracy: 98.56%, Test accuracy: 97.99%, Loss: 0.05032.\n",
      "Epoch 97/300 done. Train accuracy: 98.66%, Test accuracy: 97.38%, Loss: 0.04645.\n",
      "Epoch 98/300 done. Train accuracy: 98.65%, Test accuracy: 97.41%, Loss: 0.04867.\n",
      "Epoch 99/300 done. Train accuracy: 98.67%, Test accuracy: 97.65%, Loss: 0.04730.\n",
      "Epoch 100/300 done. Train accuracy: 98.69%, Test accuracy: 97.71%, Loss: 0.04676.\n",
      "Epoch 101/300 done. Train accuracy: 98.64%, Test accuracy: 97.62%, Loss: 0.04766.\n",
      "Epoch 102/300 done. Train accuracy: 98.58%, Test accuracy: 97.53%, Loss: 0.05156.\n",
      "Epoch 103/300 done. Train accuracy: 98.61%, Test accuracy: 97.50%, Loss: 0.04719.\n",
      "Epoch 104/300 done. Train accuracy: 98.70%, Test accuracy: 97.26%, Loss: 0.04590.\n",
      "Epoch 105/300 done. Train accuracy: 98.59%, Test accuracy: 97.53%, Loss: 0.04828.\n",
      "Epoch 106/300 done. Train accuracy: 98.60%, Test accuracy: 97.53%, Loss: 0.04945.\n",
      "Epoch 107/300 done. Train accuracy: 98.69%, Test accuracy: 97.17%, Loss: 0.04754.\n",
      "Epoch 108/300 done. Train accuracy: 98.54%, Test accuracy: 97.62%, Loss: 0.05056.\n",
      "Epoch 109/300 done. Train accuracy: 98.48%, Test accuracy: 97.56%, Loss: 0.05116.\n",
      "Epoch 110/300 done. Train accuracy: 98.65%, Test accuracy: 97.32%, Loss: 0.04750.\n",
      "Epoch 111/300 done. Train accuracy: 98.77%, Test accuracy: 97.41%, Loss: 0.04393.\n",
      "Epoch 112/300 done. Train accuracy: 98.58%, Test accuracy: 97.60%, Loss: 0.04802.\n",
      "Epoch 113/300 done. Train accuracy: 98.67%, Test accuracy: 97.56%, Loss: 0.04826.\n",
      "Epoch 114/300 done. Train accuracy: 98.64%, Test accuracy: 97.56%, Loss: 0.04853.\n",
      "Epoch 115/300 done. Train accuracy: 98.74%, Test accuracy: 97.53%, Loss: 0.04708.\n",
      "Epoch 116/300 done. Train accuracy: 98.66%, Test accuracy: 97.44%, Loss: 0.04760.\n",
      "Epoch 117/300 done. Train accuracy: 98.71%, Test accuracy: 97.41%, Loss: 0.04480.\n",
      "Epoch 118/300 done. Train accuracy: 98.57%, Test accuracy: 97.41%, Loss: 0.04971.\n",
      "Epoch 119/300 done. Train accuracy: 98.68%, Test accuracy: 97.59%, Loss: 0.04930.\n",
      "Epoch 120/300 done. Train accuracy: 98.64%, Test accuracy: 97.60%, Loss: 0.04983.\n",
      "Epoch 121/300 done. Train accuracy: 98.43%, Test accuracy: 97.38%, Loss: 0.05084.\n",
      "Epoch 122/300 done. Train accuracy: 98.60%, Test accuracy: 97.35%, Loss: 0.04791.\n",
      "Epoch 123/300 done. Train accuracy: 98.73%, Test accuracy: 97.47%, Loss: 0.04638.\n",
      "Epoch 124/300 done. Train accuracy: 98.65%, Test accuracy: 97.72%, Loss: 0.04819.\n",
      "Epoch 125/300 done. Train accuracy: 98.66%, Test accuracy: 97.83%, Loss: 0.04827.\n",
      "Epoch 126/300 done. Train accuracy: 98.57%, Test accuracy: 97.81%, Loss: 0.04986.\n",
      "Epoch 127/300 done. Train accuracy: 98.66%, Test accuracy: 97.11%, Loss: 0.04693.\n",
      "Epoch 128/300 done. Train accuracy: 98.72%, Test accuracy: 97.41%, Loss: 0.04664.\n",
      "Epoch 129/300 done. Train accuracy: 98.70%, Test accuracy: 97.50%, Loss: 0.04527.\n",
      "Epoch 130/300 done. Train accuracy: 98.65%, Test accuracy: 97.50%, Loss: 0.04726.\n",
      "Epoch 131/300 done. Train accuracy: 98.66%, Test accuracy: 97.65%, Loss: 0.04643.\n",
      "Epoch 132/300 done. Train accuracy: 98.70%, Test accuracy: 97.74%, Loss: 0.04584.\n",
      "Epoch 133/300 done. Train accuracy: 98.80%, Test accuracy: 97.41%, Loss: 0.04306.\n",
      "Epoch 134/300 done. Train accuracy: 98.77%, Test accuracy: 97.81%, Loss: 0.04392.\n",
      "Epoch 135/300 done. Train accuracy: 98.63%, Test accuracy: 97.89%, Loss: 0.04762.\n",
      "Epoch 136/300 done. Train accuracy: 98.60%, Test accuracy: 97.50%, Loss: 0.04758.\n",
      "Epoch 137/300 done. Train accuracy: 98.59%, Test accuracy: 97.59%, Loss: 0.04964.\n",
      "Epoch 138/300 done. Train accuracy: 98.77%, Test accuracy: 97.86%, Loss: 0.04331.\n",
      "Epoch 139/300 done. Train accuracy: 98.59%, Test accuracy: 97.84%, Loss: 0.05166.\n",
      "Epoch 140/300 done. Train accuracy: 98.70%, Test accuracy: 97.56%, Loss: 0.04474.\n",
      "Epoch 141/300 done. Train accuracy: 98.50%, Test accuracy: 97.41%, Loss: 0.05318.\n",
      "Epoch 142/300 done. Train accuracy: 98.71%, Test accuracy: 97.35%, Loss: 0.04482.\n",
      "Epoch 143/300 done. Train accuracy: 98.76%, Test accuracy: 97.38%, Loss: 0.04485.\n",
      "Epoch 144/300 done. Train accuracy: 98.63%, Test accuracy: 97.44%, Loss: 0.04606.\n",
      "Epoch 145/300 done. Train accuracy: 98.64%, Test accuracy: 97.89%, Loss: 0.04637.\n",
      "Epoch 146/300 done. Train accuracy: 98.68%, Test accuracy: 97.59%, Loss: 0.04505.\n",
      "Epoch 147/300 done. Train accuracy: 98.67%, Test accuracy: 97.32%, Loss: 0.04611.\n",
      "Epoch 148/300 done. Train accuracy: 98.66%, Test accuracy: 97.81%, Loss: 0.04691.\n",
      "Epoch 149/300 done. Train accuracy: 98.85%, Test accuracy: 97.47%, Loss: 0.04176.\n",
      "Epoch 150/300 done. Train accuracy: 98.77%, Test accuracy: 97.74%, Loss: 0.04392.\n",
      "Epoch 151/300 done. Train accuracy: 98.77%, Test accuracy: 97.26%, Loss: 0.04392.\n",
      "Epoch 152/300 done. Train accuracy: 98.72%, Test accuracy: 97.23%, Loss: 0.04570.\n",
      "Epoch 153/300 done. Train accuracy: 98.72%, Test accuracy: 97.47%, Loss: 0.04537.\n",
      "Epoch 154/300 done. Train accuracy: 98.72%, Test accuracy: 97.71%, Loss: 0.04373.\n",
      "Epoch 155/300 done. Train accuracy: 98.66%, Test accuracy: 97.35%, Loss: 0.04559.\n",
      "Epoch 156/300 done. Train accuracy: 98.73%, Test accuracy: 97.35%, Loss: 0.04353.\n",
      "Epoch 157/300 done. Train accuracy: 98.72%, Test accuracy: 97.83%, Loss: 0.04529.\n",
      "Epoch 158/300 done. Train accuracy: 98.67%, Test accuracy: 97.56%, Loss: 0.04525.\n",
      "Epoch 159/300 done. Train accuracy: 98.71%, Test accuracy: 97.41%, Loss: 0.04717.\n",
      "Epoch 160/300 done. Train accuracy: 98.77%, Test accuracy: 97.35%, Loss: 0.04368.\n",
      "Epoch 161/300 done. Train accuracy: 98.68%, Test accuracy: 97.65%, Loss: 0.04509.\n",
      "Epoch 162/300 done. Train accuracy: 98.74%, Test accuracy: 97.68%, Loss: 0.04493.\n",
      "Epoch 163/300 done. Train accuracy: 98.72%, Test accuracy: 97.68%, Loss: 0.04631.\n",
      "Epoch 164/300 done. Train accuracy: 98.77%, Test accuracy: 97.74%, Loss: 0.04338.\n",
      "Epoch 165/300 done. Train accuracy: 98.74%, Test accuracy: 97.53%, Loss: 0.04453.\n",
      "Epoch 166/300 done. Train accuracy: 98.77%, Test accuracy: 97.68%, Loss: 0.04303.\n",
      "Epoch 167/300 done. Train accuracy: 98.73%, Test accuracy: 97.38%, Loss: 0.04387.\n",
      "Epoch 168/300 done. Train accuracy: 98.74%, Test accuracy: 97.35%, Loss: 0.04454.\n",
      "Epoch 169/300 done. Train accuracy: 98.73%, Test accuracy: 97.68%, Loss: 0.04539.\n",
      "Epoch 170/300 done. Train accuracy: 98.71%, Test accuracy: 97.62%, Loss: 0.04516.\n",
      "Epoch 171/300 done. Train accuracy: 98.73%, Test accuracy: 97.44%, Loss: 0.04636.\n",
      "Epoch 172/300 done. Train accuracy: 98.76%, Test accuracy: 97.32%, Loss: 0.04385.\n",
      "Epoch 173/300 done. Train accuracy: 98.80%, Test accuracy: 97.41%, Loss: 0.04346.\n",
      "Epoch 174/300 done. Train accuracy: 98.79%, Test accuracy: 97.38%, Loss: 0.04194.\n",
      "Epoch 175/300 done. Train accuracy: 98.78%, Test accuracy: 97.32%, Loss: 0.04390.\n",
      "Epoch 176/300 done. Train accuracy: 98.71%, Test accuracy: 97.56%, Loss: 0.04375.\n",
      "Epoch 177/300 done. Train accuracy: 98.67%, Test accuracy: 97.47%, Loss: 0.04740.\n",
      "Epoch 178/300 done. Train accuracy: 98.64%, Test accuracy: 97.05%, Loss: 0.04533.\n",
      "Epoch 179/300 done. Train accuracy: 98.73%, Test accuracy: 97.41%, Loss: 0.04463.\n",
      "Epoch 180/300 done. Train accuracy: 98.70%, Test accuracy: 97.30%, Loss: 0.04483.\n",
      "Epoch 181/300 done. Train accuracy: 98.71%, Test accuracy: 97.11%, Loss: 0.04527.\n",
      "Epoch 182/300 done. Train accuracy: 98.76%, Test accuracy: 97.68%, Loss: 0.04330.\n",
      "Epoch 183/300 done. Train accuracy: 98.81%, Test accuracy: 97.44%, Loss: 0.04300.\n",
      "Epoch 184/300 done. Train accuracy: 98.72%, Test accuracy: 97.14%, Loss: 0.04468.\n",
      "Epoch 185/300 done. Train accuracy: 98.72%, Test accuracy: 97.66%, Loss: 0.04394.\n",
      "Epoch 186/300 done. Train accuracy: 98.65%, Test accuracy: 97.54%, Loss: 0.04883.\n",
      "Epoch 187/300 done. Train accuracy: 98.76%, Test accuracy: 97.53%, Loss: 0.04322.\n",
      "Epoch 188/300 done. Train accuracy: 98.67%, Test accuracy: 97.32%, Loss: 0.04488.\n",
      "Epoch 189/300 done. Train accuracy: 98.73%, Test accuracy: 97.62%, Loss: 0.04420.\n",
      "Epoch 190/300 done. Train accuracy: 98.73%, Test accuracy: 97.41%, Loss: 0.04326.\n",
      "Epoch 191/300 done. Train accuracy: 98.73%, Test accuracy: 97.71%, Loss: 0.04377.\n",
      "Epoch 192/300 done. Train accuracy: 98.68%, Test accuracy: 97.32%, Loss: 0.04598.\n",
      "Epoch 193/300 done. Train accuracy: 98.68%, Test accuracy: 97.56%, Loss: 0.04523.\n",
      "Epoch 194/300 done. Train accuracy: 98.72%, Test accuracy: 97.29%, Loss: 0.04456.\n",
      "Epoch 195/300 done. Train accuracy: 98.69%, Test accuracy: 97.62%, Loss: 0.04601.\n",
      "Epoch 196/300 done. Train accuracy: 98.72%, Test accuracy: 97.65%, Loss: 0.04484.\n",
      "Epoch 197/300 done. Train accuracy: 98.79%, Test accuracy: 97.68%, Loss: 0.04315.\n",
      "Epoch 198/300 done. Train accuracy: 98.78%, Test accuracy: 97.50%, Loss: 0.04233.\n",
      "Epoch 199/300 done. Train accuracy: 98.67%, Test accuracy: 97.35%, Loss: 0.04502.\n",
      "Epoch 200/300 done. Train accuracy: 98.69%, Test accuracy: 97.44%, Loss: 0.04537.\n",
      "Epoch 201/300 done. Train accuracy: 98.64%, Test accuracy: 97.54%, Loss: 0.04544.\n",
      "Epoch 202/300 done. Train accuracy: 98.60%, Test accuracy: 97.30%, Loss: 0.04803.\n",
      "Epoch 203/300 done. Train accuracy: 98.70%, Test accuracy: 97.23%, Loss: 0.04498.\n",
      "Epoch 204/300 done. Train accuracy: 98.65%, Test accuracy: 97.60%, Loss: 0.04487.\n",
      "Epoch 205/300 done. Train accuracy: 98.81%, Test accuracy: 97.50%, Loss: 0.04212.\n",
      "Epoch 206/300 done. Train accuracy: 98.72%, Test accuracy: 97.23%, Loss: 0.04542.\n",
      "Epoch 207/300 done. Train accuracy: 98.74%, Test accuracy: 97.26%, Loss: 0.04526.\n",
      "Epoch 208/300 done. Train accuracy: 98.80%, Test accuracy: 97.59%, Loss: 0.04337.\n",
      "Epoch 209/300 done. Train accuracy: 98.69%, Test accuracy: 97.26%, Loss: 0.04466.\n",
      "Epoch 210/300 done. Train accuracy: 98.72%, Test accuracy: 97.14%, Loss: 0.04359.\n",
      "Epoch 211/300 done. Train accuracy: 98.77%, Test accuracy: 97.41%, Loss: 0.04279.\n",
      "Epoch 212/300 done. Train accuracy: 98.72%, Test accuracy: 97.29%, Loss: 0.04499.\n",
      "Epoch 213/300 done. Train accuracy: 98.69%, Test accuracy: 97.14%, Loss: 0.04549.\n",
      "Epoch 214/300 done. Train accuracy: 98.59%, Test accuracy: 97.24%, Loss: 0.04749.\n",
      "Epoch 215/300 done. Train accuracy: 98.73%, Test accuracy: 97.38%, Loss: 0.04447.\n",
      "Epoch 216/300 done. Train accuracy: 98.80%, Test accuracy: 97.42%, Loss: 0.04289.\n",
      "Epoch 217/300 done. Train accuracy: 98.81%, Test accuracy: 97.59%, Loss: 0.04200.\n",
      "Epoch 218/300 done. Train accuracy: 98.81%, Test accuracy: 97.23%, Loss: 0.04211.\n",
      "Epoch 219/300 done. Train accuracy: 98.79%, Test accuracy: 97.41%, Loss: 0.04163.\n",
      "Epoch 220/300 done. Train accuracy: 98.72%, Test accuracy: 97.38%, Loss: 0.04320.\n",
      "Epoch 221/300 done. Train accuracy: 98.74%, Test accuracy: 97.38%, Loss: 0.04564.\n",
      "Epoch 222/300 done. Train accuracy: 98.54%, Test accuracy: 97.32%, Loss: 0.04846.\n",
      "Epoch 223/300 done. Train accuracy: 98.68%, Test accuracy: 97.08%, Loss: 0.04590.\n",
      "Epoch 224/300 done. Train accuracy: 98.81%, Test accuracy: 97.08%, Loss: 0.04248.\n",
      "Epoch 225/300 done. Train accuracy: 98.77%, Test accuracy: 97.05%, Loss: 0.04269.\n",
      "Epoch 226/300 done. Train accuracy: 98.77%, Test accuracy: 97.26%, Loss: 0.04280.\n",
      "Epoch 227/300 done. Train accuracy: 98.66%, Test accuracy: 97.44%, Loss: 0.04349.\n",
      "Epoch 228/300 done. Train accuracy: 98.70%, Test accuracy: 97.11%, Loss: 0.04390.\n",
      "Epoch 229/300 done. Train accuracy: 98.76%, Test accuracy: 97.50%, Loss: 0.04364.\n",
      "Epoch 230/300 done. Train accuracy: 98.76%, Test accuracy: 97.17%, Loss: 0.04335.\n",
      "Epoch 231/300 done. Train accuracy: 98.80%, Test accuracy: 97.32%, Loss: 0.04359.\n",
      "Epoch 232/300 done. Train accuracy: 98.73%, Test accuracy: 97.08%, Loss: 0.04605.\n",
      "Epoch 233/300 done. Train accuracy: 98.62%, Test accuracy: 97.32%, Loss: 0.04566.\n",
      "Epoch 234/300 done. Train accuracy: 98.72%, Test accuracy: 97.50%, Loss: 0.04541.\n",
      "Epoch 235/300 done. Train accuracy: 98.70%, Test accuracy: 97.35%, Loss: 0.04408.\n",
      "Epoch 236/300 done. Train accuracy: 98.70%, Test accuracy: 97.41%, Loss: 0.04507.\n",
      "Epoch 237/300 done. Train accuracy: 98.64%, Test accuracy: 97.05%, Loss: 0.04609.\n",
      "Epoch 238/300 done. Train accuracy: 98.62%, Test accuracy: 97.35%, Loss: 0.04840.\n",
      "Epoch 239/300 done. Train accuracy: 98.74%, Test accuracy: 97.42%, Loss: 0.04316.\n",
      "Epoch 240/300 done. Train accuracy: 98.72%, Test accuracy: 97.11%, Loss: 0.04391.\n",
      "Epoch 241/300 done. Train accuracy: 98.73%, Test accuracy: 97.26%, Loss: 0.04393.\n",
      "Epoch 242/300 done. Train accuracy: 98.59%, Test accuracy: 97.41%, Loss: 0.04655.\n",
      "Epoch 243/300 done. Train accuracy: 98.72%, Test accuracy: 97.38%, Loss: 0.04419.\n",
      "Epoch 244/300 done. Train accuracy: 98.72%, Test accuracy: 97.26%, Loss: 0.04336.\n",
      "Epoch 245/300 done. Train accuracy: 98.72%, Test accuracy: 97.38%, Loss: 0.04344.\n",
      "Epoch 246/300 done. Train accuracy: 98.73%, Test accuracy: 97.32%, Loss: 0.04395.\n",
      "Epoch 247/300 done. Train accuracy: 98.77%, Test accuracy: 96.99%, Loss: 0.04430.\n",
      "Epoch 248/300 done. Train accuracy: 98.65%, Test accuracy: 97.05%, Loss: 0.04793.\n",
      "Epoch 249/300 done. Train accuracy: 98.73%, Test accuracy: 97.23%, Loss: 0.04523.\n",
      "Epoch 250/300 done. Train accuracy: 98.76%, Test accuracy: 97.14%, Loss: 0.04306.\n",
      "Epoch 251/300 done. Train accuracy: 98.70%, Test accuracy: 97.23%, Loss: 0.04384.\n",
      "Epoch 252/300 done. Train accuracy: 98.74%, Test accuracy: 97.11%, Loss: 0.04350.\n",
      "Epoch 253/300 done. Train accuracy: 98.72%, Test accuracy: 97.35%, Loss: 0.04358.\n",
      "Epoch 254/300 done. Train accuracy: 98.66%, Test accuracy: 97.23%, Loss: 0.04744.\n",
      "Epoch 255/300 done. Train accuracy: 98.78%, Test accuracy: 97.23%, Loss: 0.04219.\n",
      "Epoch 256/300 done. Train accuracy: 98.77%, Test accuracy: 97.20%, Loss: 0.04342.\n",
      "Epoch 257/300 done. Train accuracy: 98.75%, Test accuracy: 97.29%, Loss: 0.04330.\n",
      "Epoch 258/300 done. Train accuracy: 98.66%, Test accuracy: 97.20%, Loss: 0.04537.\n",
      "Epoch 259/300 done. Train accuracy: 98.78%, Test accuracy: 97.44%, Loss: 0.04160.\n",
      "Epoch 260/300 done. Train accuracy: 98.69%, Test accuracy: 97.26%, Loss: 0.04419.\n",
      "Epoch 261/300 done. Train accuracy: 98.67%, Test accuracy: 97.38%, Loss: 0.04415.\n",
      "Epoch 262/300 done. Train accuracy: 98.61%, Test accuracy: 97.38%, Loss: 0.04599.\n",
      "Epoch 263/300 done. Train accuracy: 98.75%, Test accuracy: 97.41%, Loss: 0.04533.\n",
      "Epoch 264/300 done. Train accuracy: 98.73%, Test accuracy: 97.17%, Loss: 0.04438.\n",
      "Epoch 265/300 done. Train accuracy: 98.71%, Test accuracy: 97.17%, Loss: 0.04425.\n",
      "Epoch 266/300 done. Train accuracy: 98.69%, Test accuracy: 97.38%, Loss: 0.04491.\n",
      "Epoch 267/300 done. Train accuracy: 98.67%, Test accuracy: 97.74%, Loss: 0.04523.\n",
      "Epoch 268/300 done. Train accuracy: 98.80%, Test accuracy: 97.05%, Loss: 0.04184.\n",
      "Epoch 269/300 done. Train accuracy: 98.77%, Test accuracy: 97.20%, Loss: 0.04259.\n",
      "Epoch 270/300 done. Train accuracy: 98.81%, Test accuracy: 97.05%, Loss: 0.04164.\n",
      "Epoch 271/300 done. Train accuracy: 98.75%, Test accuracy: 97.17%, Loss: 0.04419.\n",
      "Epoch 272/300 done. Train accuracy: 98.78%, Test accuracy: 97.60%, Loss: 0.04528.\n",
      "Epoch 273/300 done. Train accuracy: 98.61%, Test accuracy: 96.90%, Loss: 0.04812.\n",
      "Epoch 274/300 done. Train accuracy: 98.66%, Test accuracy: 97.08%, Loss: 0.04588.\n",
      "Epoch 275/300 done. Train accuracy: 98.76%, Test accuracy: 97.44%, Loss: 0.04392.\n",
      "Epoch 276/300 done. Train accuracy: 98.65%, Test accuracy: 97.38%, Loss: 0.04511.\n",
      "Epoch 277/300 done. Train accuracy: 98.73%, Test accuracy: 96.96%, Loss: 0.04444.\n",
      "Epoch 278/300 done. Train accuracy: 98.66%, Test accuracy: 96.72%, Loss: 0.04448.\n",
      "Epoch 279/300 done. Train accuracy: 98.67%, Test accuracy: 97.35%, Loss: 0.04608.\n",
      "Epoch 280/300 done. Train accuracy: 98.75%, Test accuracy: 97.20%, Loss: 0.04331.\n",
      "Epoch 281/300 done. Train accuracy: 98.74%, Test accuracy: 97.02%, Loss: 0.04235.\n",
      "Epoch 282/300 done. Train accuracy: 98.69%, Test accuracy: 96.84%, Loss: 0.04516.\n",
      "Epoch 283/300 done. Train accuracy: 98.69%, Test accuracy: 97.30%, Loss: 0.04377.\n",
      "Epoch 284/300 done. Train accuracy: 98.73%, Test accuracy: 97.42%, Loss: 0.04323.\n",
      "Epoch 285/300 done. Train accuracy: 98.72%, Test accuracy: 97.02%, Loss: 0.04222.\n",
      "Epoch 286/300 done. Train accuracy: 98.73%, Test accuracy: 97.47%, Loss: 0.04349.\n",
      "Epoch 287/300 done. Train accuracy: 98.75%, Test accuracy: 97.05%, Loss: 0.04258.\n",
      "Epoch 288/300 done. Train accuracy: 98.73%, Test accuracy: 97.06%, Loss: 0.04379.\n",
      "Epoch 289/300 done. Train accuracy: 98.77%, Test accuracy: 97.02%, Loss: 0.04291.\n",
      "Epoch 290/300 done. Train accuracy: 98.76%, Test accuracy: 96.75%, Loss: 0.04279.\n",
      "Epoch 291/300 done. Train accuracy: 98.61%, Test accuracy: 96.90%, Loss: 0.04839.\n",
      "Epoch 292/300 done. Train accuracy: 98.67%, Test accuracy: 97.26%, Loss: 0.04511.\n",
      "Epoch 293/300 done. Train accuracy: 98.71%, Test accuracy: 97.05%, Loss: 0.04354.\n",
      "Epoch 294/300 done. Train accuracy: 98.77%, Test accuracy: 97.35%, Loss: 0.04241.\n",
      "Epoch 295/300 done. Train accuracy: 98.73%, Test accuracy: 97.35%, Loss: 0.04373.\n",
      "Epoch 296/300 done. Train accuracy: 98.71%, Test accuracy: 97.50%, Loss: 0.04312.\n",
      "Epoch 297/300 done. Train accuracy: 98.71%, Test accuracy: 97.44%, Loss: 0.04326.\n",
      "Epoch 298/300 done. Train accuracy: 98.71%, Test accuracy: 97.20%, Loss: 0.04285.\n",
      "Epoch 299/300 done. Train accuracy: 98.74%, Test accuracy: 97.11%, Loss: 0.04314.\n",
      "Epoch 300/300 done. Train accuracy: 98.73%, Test accuracy: 97.59%, Loss: 0.04352.\n",
      "Final results: \n",
      "Best training accuracy: 98.85% and according test accuracy: 97.47% at epoch: 149\n",
      "Best test accuracy: 98.05% and according train accuracy: 98.35% at epoch: 75\n",
      "------------------------------------------------------------------------------------\n",
      "\n",
      "*************************\n",
      "* Best:  98.07406135531136\n",
      "*************************\n"
     ]
    }
   ],
   "source": [
    "acc_train_list = []\n",
    "acc_test_list = []\n",
    "max_epochs = 5\n",
    "for epoch in range(max_epochs):\n",
    "    # reload and shuffle data each epoch\n",
    "    ds_train, _, ds_test, labels, nb_channels, data_steps = load_and_extract_events(\n",
    "        params, file_name, letter_written=letters)\n",
    "\n",
    "    if epoch == 0:\n",
    "        print(\"Number of training data %i\" % len(ds_train))\n",
    "        print(\"Number of testing data %i\" % len(ds_test))\n",
    "        print(\"Number of outputs %i\" % len(np.unique(labels)))\n",
    "        print(\"Number of timesteps %i\" % data_steps)\n",
    "        print(\"Input duration %fs\" % (data_steps*time_step))\n",
    "        print(\"---------------------------\\n\")\n",
    "\n",
    "    # initialize and train network\n",
    "    loss_hist, acc_hist, best_layers = build_and_train(\n",
    "        params, ds_train, ds_test, epochs=epochs)\n",
    "\n",
    "    # safe overall best layer\n",
    "    if epoch == 0:\n",
    "        very_best_layer = best_layers\n",
    "        best_acc = max(acc_hist[1])\n",
    "    else:\n",
    "        if max(acc_hist[1]) > best_acc:\n",
    "            very_best_layer = best_layers\n",
    "            best_acc = max(acc_hist[1])\n",
    "\n",
    "    acc_train_list.append(acc_hist[0])\n",
    "    acc_test_list.append(acc_hist[1])\n",
    "\n",
    "print(\"*************************\")\n",
    "print(\"* Best: \", best_acc*100)\n",
    "print(\"*************************\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1e2701b",
   "metadata": {},
   "source": [
    "### Let's plot the training curve and the confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d4aa7b76",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# calc mean and std\n",
    "acc_mean_train = np.mean(acc_train_list, axis=0)\n",
    "acc_std_train = np.std(acc_train_list, axis=0)\n",
    "acc_mean_test = np.mean(acc_test_list, axis=0)\n",
    "acc_std_test = np.std(acc_test_list, axis=0)\n",
    "best_trial, best_val_idx = np.where(np.max(acc_test_list) == acc_test_list)\n",
    "best_trial, best_val_idx = best_trial[0], best_val_idx[0]\n",
    "plt.figure()\n",
    "# plot best trial\n",
    "plt.plot(range(1, len(acc_train_list[best_trial])+1), 100*np.array(\n",
    "    acc_train_list[best_trial]), color='blue', linestyle='dashed')\n",
    "plt.plot(range(1, len(acc_test_list[best_trial])+1), 100*np.array(\n",
    "    acc_test_list[best_trial]), color='orangered', linestyle='dashed')\n",
    "# plot mean and std\n",
    "plt.plot(range(1, len(acc_mean_train)+1),\n",
    "         100*np.array(acc_mean_train), color='blue')\n",
    "plt.plot(range(1, len(acc_mean_test)+1), 100 *\n",
    "         np.array(acc_mean_test), color='orangered')\n",
    "plt.fill_between(range(1, len(acc_mean_train)+1), 100*(acc_mean_train+acc_std_train), 100*(\n",
    "    acc_mean_train-acc_std_train), color='cornflowerblue')\n",
    "plt.fill_between(range(1, len(acc_mean_test)+1), 100*(\n",
    "    acc_mean_test+acc_std_test), 100*(acc_mean_test-acc_std_test), color='sandybrown')\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Accuracy (%)\")\n",
    "plt.ylim((0, 105))\n",
    "plt.legend([\"Training\", \"Test\"], loc='lower right')\n",
    "if save_fig:\n",
    "    plt.savefig(\"../plots/rsnn_1layers_train_tc_thr_\" +\n",
    "                str(threshold)+\"_acc.png\", dpi=300)\n",
    "else:\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2ad5ddfa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x900 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plotting the confusion matrix\n",
    "ConfusionMatrix(ds_test, layers=very_best_layer, save=save_fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7f07656",
   "metadata": {},
   "source": [
    "### Lets create some raster plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9c4a533b",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "not enough values to unpack (expected 5, got 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [22], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# plotting the network activity\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[43mNetworkActivity\u001b[49m\u001b[43m(\u001b[49m\u001b[43mds_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlayers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvery_best_layer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msave\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msave_fig\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn [15], line 25\u001b[0m, in \u001b[0;36mNetworkActivity\u001b[0;34m(dataset, save, layers, labels)\u001b[0m\n\u001b[1;32m     22\u001b[0m         spks_out, recs, _ \u001b[38;5;241m=\u001b[39m run_snn(x_local, layers)\n\u001b[1;32m     24\u001b[0m     \u001b[38;5;66;03m# [mem_rec, spk_rec, mem_rec2, spk_rec2, out_rec]\u001b[39;00m\n\u001b[0;32m---> 25\u001b[0m     _, spk_rec, _, spk_rec3, _ \u001b[38;5;241m=\u001b[39m recs\n\u001b[1;32m     27\u001b[0m nb_plt \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m4\u001b[39m\n\u001b[1;32m     28\u001b[0m gs \u001b[38;5;241m=\u001b[39m GridSpec(\u001b[38;5;241m1\u001b[39m, nb_plt)\n",
      "\u001b[0;31mValueError\u001b[0m: not enough values to unpack (expected 5, got 3)"
     ]
    }
   ],
   "source": [
    "# plotting the network activity\n",
    "NetworkActivity(ds_test, layers=very_best_layer, save=save_fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4262235",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.0 ('env_nteEnc': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "77798a54e7665e7cdc06a08ee54c1994981fcf46c4af6330a97b3c21e089a8c7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
