{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualizer\n",
    "### Use this script to visualize the neuron traces according to the paper \"A Generalized Linear Integrate-and-Fire Neural Model Produces Diverse Spiking Behaviors\" by Stefan Mihalas and Ernst Niebur. Further, data was created with a fix length of 1sec (1ms time steps), with noise on the input current, and/or temporal jitter on the time point of the step for dynamic inputs. \n",
    "\n",
    "### The script will also calculate the inter-spike intervalls (ISIs) for a single trial and for all repeating trials, whenever possible. For repeating trials, all ISIs are grouped and further statics represent the outcome of all repetitions per class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\smuel\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import torch\n",
    "import os\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import numpy.polynomial.polynomial as poly\n",
    "\n",
    "from tactile_encoding.utils.utils import value2key, create_directory\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "braille_letters = ['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L',\n",
    "                   'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z', 'Space']\n",
    "\n",
    "max_trials = 100\n",
    "\n",
    "classes_list = {\n",
    "    'A': \"Tonic spiking\",\n",
    "    'B': \"Class 1\",\n",
    "    'C': \"Spike frequency adaptation\",\n",
    "    'D': \"Phasic spiking\",\n",
    "    'E': \"Accommodation\",\n",
    "    'F': \"Threshold variability\",\n",
    "    'G': \"Rebound spike\",\n",
    "    'H': \"Class 2\",\n",
    "    'I': \"Integrator\",\n",
    "    'J': \"Input bistability\",\n",
    "    'K': \"Hyperpolarizing spiking\",\n",
    "    'L': \"Hyperpolarizing bursting\",\n",
    "    'M': \"Tonic bursting\",\n",
    "    'N': \"Phasic bursting\",\n",
    "    'O': \"Rebound burst\",\n",
    "    'P': \"Mixed mode\",\n",
    "    'Q': \"Afterpotentials\",\n",
    "    'R': \"Basal bistability\",\n",
    "    'S': \"Preferred frequency\",\n",
    "    'T': \"Spike latency\",\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_isi_fix_len(data, max_trials, norm_count=False, norm_time=False):\n",
    "    \"\"\"\n",
    "    Calculates and returns the ISI for all repetitions of fix length data.\n",
    "    \"\"\"\n",
    "    isi_list = []\n",
    "    for num, el in enumerate(list(classes_list.values())):\n",
    "        # print(el)\n",
    "        # concatenate all ISIs\n",
    "        isi_fix_len = []\n",
    "        for trial in range(max_trials):\n",
    "            # calc spikes per trial\n",
    "            spikes = np.reshape(np.array(data[trial + num*max_trials][0]), (np.array(\n",
    "                data[trial + num*max_trials][0]).shape[0]))\n",
    "            # calc ISI\n",
    "            isi_fix_len.extend(np.diff(np.where(spikes == 1)[0]))\n",
    "\n",
    "        if len(isi_fix_len) > 0:\n",
    "            tmp_fix_len = np.unique(isi_fix_len, return_counts=True)\n",
    "            isi_fix_len = tmp_fix_len[0]\n",
    "            if norm_time:\n",
    "                isi_fix_len = isi_fix_len/max(isi_fix_len)\n",
    "            isi_fix_len_count = tmp_fix_len[1]\n",
    "            if norm_count:\n",
    "                isi_fix_len_count = isi_fix_len_count/max(isi_fix_len_count)\n",
    "            # create 2d array\n",
    "            isi = np.vstack([isi_fix_len, isi_fix_len_count])\n",
    "        isi_list.append(isi)\n",
    "\n",
    "    return isi_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nneuron parameters:\\na: 2.743\\nA1: 0.03712\\nA2: -0.5089\\nb: 11.4\\nG: 47.02\\nk1: 200\\nk2: 20\\nR1: 0\\nR2: 1\\n'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_path_braille = './data/braille_mn_output'  # path to output from Braille data\n",
    "data_path_original = './data/original_mn_output'  # path to output from MN paper\n",
    "plot_out = './plots'  # path to save plots\n",
    "create_directory(plot_out)\n",
    "\n",
    "'''\n",
    "neuron parameters:\n",
    "a: 2.743\n",
    "A1: 0.03712\n",
    "A2: -0.5089\n",
    "b: 11.4\n",
    "G: 47.02\n",
    "k1: 200\n",
    "k2: 20\n",
    "R1: 0\n",
    "R2: 1\n",
    "'''\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-processing\n",
    "### extract and concatenate all ISIs for each label and sensor over all data after training and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_names = os.listdir(data_path_braille)\n",
    "file_names = np.sort(file_names)\n",
    "isi_list = []\n",
    "isi_dict = {}\n",
    "for entry in range(27):\n",
    "    isi_dict[entry] = []\n",
    "for _, file_name in enumerate(file_names):\n",
    "    [mn_spk, input_current, trial_label] = torch.load(\n",
    "        data_path_braille + '/' + file_name, map_location=torch.device('cpu'))\n",
    "    # convert to numpy\n",
    "    mn_spk = mn_spk.numpy()\n",
    "    input_current = input_current.numpy()\n",
    "    trial_label = trial_label.numpy()\n",
    "\n",
    "    # extract traces from single batch\n",
    "    for batch in range(mn_spk.shape[0]):\n",
    "        isi_list = []\n",
    "\n",
    "        # loop over all channels\n",
    "        for channel in range(mn_spk[batch].shape[-1]):\n",
    "            # calc ISI per channel and append to list\n",
    "            isi_list.append(np.diff(np.where(mn_spk[batch][:, channel] == 1.0))*1E-2)\n",
    "\n",
    "        # init dict per label\n",
    "        if len(isi_dict[trial_label[batch]]) < 1:\n",
    "            isi_dict[trial_label[batch]] = isi_list\n",
    "        # extend dict if contains already values\n",
    "        else:\n",
    "            # extend the dict for each channel\n",
    "            for entry in range(len(isi_dict[trial_label[batch]])):\n",
    "                if len(isi_list[entry]) > 0:\n",
    "                    isi_dict[trial_label[batch]][entry] = np.append(isi_dict[trial_label[batch]][entry], isi_list[entry], axis=1)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compare to paper output"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Per class and channel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\smuel\\AppData\\Local\\Temp\\ipykernel_8668\\3861821810.py:24: RuntimeWarning: invalid value encountered in divide\n",
      "  count = count/max(count)\n"
     ]
    }
   ],
   "source": [
    "# load ISIs from paper\n",
    "norm_count = True\n",
    "norm_time = True\n",
    "# data_types = ['', '_noisy', '_temp_jitter', '_noisy_temp_jitter_offset']\n",
    "filename = 'data_encoding_fix_len_noisy_temp_jitter_offset'\n",
    "infile = open(f\"{data_path_original}/{filename}.pkl\", 'rb')\n",
    "data_original = pickle.load(infile)\n",
    "infile.close()\n",
    "isi_original = return_isi_fix_len(\n",
    "    data_original, max_trials, norm_count=norm_count, norm_time=norm_time)\n",
    "\n",
    "for _, entry in enumerate(isi_dict):\n",
    "    # iterate over channel\n",
    "    for channel in range(len(isi_dict[entry])):\n",
    "        # print('\\nWorking on channel: ', channel)\n",
    "        # extract single ISIs and their count\n",
    "        isi, count = np.unique(isi_dict[entry][channel][0], return_index=True)\n",
    "\n",
    "        # only plot if ISIs found in channel\n",
    "        if len(isi) > 0:\n",
    "            if norm_time:\n",
    "                isi = isi/max(isi)\n",
    "            if norm_count:\n",
    "                count = count/max(count)\n",
    "\n",
    "            # create box plots with all classes from paper and single sensor and class for Braille data\n",
    "            figname = f'comparison ISI\\nLetter: {braille_letters[entry]} Sensor: {channel}'\n",
    "            plt.figure(figsize=(12, 12))\n",
    "            plt.suptitle(figname)\n",
    "\n",
    "            # compare to original traces\n",
    "            for num, isi_original_sel in enumerate(isi_original):             \n",
    "                # create scatter plot for Braille and original ISIs\n",
    "                plt.subplot(5, 4, num+1)\n",
    "                plt.title(f'{classes_list[braille_letters[num]]}')\n",
    "                plt.scatter(isi_original_sel[0], isi_original_sel[1])\n",
    "                plt.scatter(isi, count)\n",
    "                plt.xlim((0, 1.1))\n",
    "\n",
    "            plt.tight_layout()\n",
    "            plt.savefig(\n",
    "                f'{plot_out}/comparison_class_{braille_letters[entry]}_channel_{channel}_scatter.png', dpi=300)\n",
    "            plt.close()\n",
    "            # plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\smuel\\AppData\\Local\\Temp\\ipykernel_8668\\1133819330.py:24: RuntimeWarning: invalid value encountered in divide\n",
      "  count = count/max(count)\n"
     ]
    }
   ],
   "source": [
    "# load ISIs from paper\n",
    "norm_count = True\n",
    "norm_time = True\n",
    "# data_types = ['', '_noisy', '_temp_jitter', '_noisy_temp_jitter_offset']\n",
    "filename = 'data_encoding_fix_len_noisy_temp_jitter_offset'\n",
    "infile = open(f\"{data_path_original}/{filename}.pkl\", 'rb')\n",
    "data_original = pickle.load(infile)\n",
    "infile.close()\n",
    "isi_original = return_isi_fix_len(\n",
    "    data_original, max_trials, norm_count=norm_count, norm_time=norm_time)\n",
    "\n",
    "for _, entry in enumerate(isi_dict):\n",
    "    # iterate over channel\n",
    "    for channel in range(len(isi_dict[entry])):\n",
    "        # print('\\nWorking on channel: ', channel)\n",
    "        # extract single ISIs and their count\n",
    "        isi, count = np.unique(isi_dict[entry][channel][0], return_index=True)\n",
    "\n",
    "        # only plot if ISIs found in channel\n",
    "        if len(isi) > 0:\n",
    "            if norm_time:\n",
    "                isi = isi/max(isi)\n",
    "            if norm_count:\n",
    "                count = count/max(count)\n",
    "\n",
    "            # create box plots with all classes from paper and single sensor and class for Braille data\n",
    "            figname = f'comparison ISI\\nLetter: {braille_letters[entry]} Sensor: {channel}'\n",
    "            plt.figure(figsize=(12, 12))\n",
    "            plt.suptitle(figname)\n",
    "\n",
    "            # mean and std for channel\n",
    "            mean_isi_braille = [np.mean(isi), np.std(isi)]\n",
    "            mean_count_braille = [np.mean(count), np.std(count)]\n",
    "            # print('Mean Braille: ', [mean_isi_braille[0], mean_count_braille[0]])\n",
    "            \n",
    "            # median for channel\n",
    "            median_isi_braille, median_count_braille = np.median(isi), np.median(count)\n",
    "            # print('Median Braille: ', [median_isi_braille, median_count_braille])\n",
    "            \n",
    "        \n",
    "            # compare to original traces\n",
    "            for num, isi_original_sel in enumerate(isi_original):\n",
    "                # # problem: differnet length of input\n",
    "\n",
    "                # # https://stats.stackexchange.com/questions/194023/how-to-measure-similarity-of-two-lists-of-continuous-data-with-different-length\n",
    "                # # I: try a curve fit on both distributions and from fitted curve the distance can be calculated\n",
    "\n",
    "                # II: calc some statistics and use corralation\n",
    "                import math\n",
    "                # calc mean and std\n",
    "                mean_isi_original_sel = [np.mean(isi_original_sel[0]), np.std(isi_original_sel[0])]\n",
    "                mean_count_original_sel = [np.mean(isi_original_sel[1]), np.std(isi_original_sel[1])]\n",
    "                \n",
    "                # print('Mean original: ', [mean_isi_original_sel[0], mean_count_original_sel[0]])\n",
    "                distance_mean = math.dist([mean_isi_original_sel[0], mean_count_original_sel[0]], [mean_isi_braille[0], mean_count_braille[0]])\n",
    "                # print('Mean dist.: ', distance_mean)\n",
    "\n",
    "                # calc meadian\n",
    "                median_isi_original_sel, median_count_original_sel = np.median(isi_original_sel[0]), np.median(isi_original_sel[1])\n",
    "                # print('Median original: ', [median_isi_original_sel, median_count_original_sel])\n",
    "                \n",
    "                distance_median = math.dist([median_isi_original_sel, median_count_original_sel], [median_isi_braille, median_count_braille])\n",
    "                # print('Median dist.: ', distance_median)\n",
    "                # calc Eukledean distance\n",
    "                # print('Input: ', [isi_original[0], count_original[0]], [isi_braille[0], count_braille[0]])\n",
    "                \n",
    "                # print('Distance: ', distance)\n",
    "\n",
    "                # # calc covariance between mean isi and count\n",
    "                # covariance = np.cov([isi_original[0], count_original[0]], [isi_braille[0], count_braille[0]])\n",
    "                # print('covariance: ', covariance)\n",
    "\n",
    "                # calculate Pearson's correlation\n",
    "                # https://machinelearningmastery.com/how-to-use-correlation-to-understand-the-relationship-between-variables/\n",
    "                # from scipy.stats import pearsonr\n",
    "                # print('Input for Pearson\\'s correlation:')\n",
    "                # print([isi_original[0], count_original[0]], [isi_braille[0], count_braille[0]])\n",
    "                # # calc Pearson's correlation isi_braille[0]\n",
    "                # corr, _ = pearsonr([isi_original[0], count_original[0]], [isi_braille[0], count_braille[0]])\n",
    "                # print('Pearson\\'s correlation: ', corr)\n",
    "                \n",
    "\n",
    "                # create bar plot for Braille and original ISIs\n",
    "                plt.subplot(5, 4, num+1)\n",
    "                # plt.title(f'{isi_original_sel} spikes in {classes_list[braille_letters[num]]}')\n",
    "                plt.title('mean, median: {:.2f}, {:.2f}' .format(distance_mean, distance_median))\n",
    "                if norm_time:\n",
    "                    plt.bar(isi_original_sel[0],\n",
    "                            isi_original_sel[1], width=0.01)\n",
    "                    plt.bar(isi, count, width=0.01)\n",
    "                else:\n",
    "                    plt.bar(isi_original_sel[0], isi_original_sel[1])\n",
    "                    plt.bar(isi, count)\n",
    "                plt.xlim((0, 1.1))\n",
    "\n",
    "            plt.tight_layout()\n",
    "            plt.savefig(\n",
    "                f'{plot_out}/comparison_class_{braille_letters[entry]}_channel_{channel}_bar.png', dpi=300)\n",
    "            plt.close()\n",
    "            # plt.show()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Per channel over all classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_names = os.listdir(data_path_braille)\n",
    "file_names = np.sort(file_names)\n",
    "init = True\n",
    "\n",
    "for _, file_name in enumerate(file_names):\n",
    "    [mn_spk, input_current, trial_label] = torch.load(\n",
    "        data_path_braille + '/' + file_name, map_location=torch.device('cpu'))\n",
    "    # convert to numpy\n",
    "    mn_spk = mn_spk.numpy()\n",
    "    input_current = input_current.numpy()\n",
    "    trial_label = trial_label.numpy()\n",
    "\n",
    "    # extract traces from single batch\n",
    "    for batch in range(mn_spk.shape[0]):\n",
    "        isi_list_channel = []\n",
    "\n",
    "        # loop over all channels\n",
    "        for channel in range(mn_spk[batch].shape[-1]):\n",
    "            # calc ISI per channel and append to list\n",
    "            isi_list_channel.append(\n",
    "                np.diff(np.where(mn_spk[batch][:, channel] == 1.0))*1E-2)\n",
    "\n",
    "        if init:\n",
    "            # init at first run\n",
    "            isi_list = isi_list_channel\n",
    "            init = False\n",
    "        else:\n",
    "            # extend with ISIs found in channel per batch\n",
    "            for num, _ in enumerate(isi_list_channel):\n",
    "                # print(len(isi_list[num][0]), len(isi_list_channel[num][0]))\n",
    "                isi_list[num] = np.append(\n",
    "                    isi_list[num], isi_list_channel[num], axis=1)\n",
    "                # print(len(isi_list[num][0]))\n",
    "\n",
    "# check data\n",
    "# print('Channels: ', len(isi_list))\n",
    "# for num, isi in enumerate(isi_list):\n",
    "#     print('ISIs for channel ', num, ': ', len(isi[0]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load ISIs from paper\n",
    "norm_count = True\n",
    "norm_time = True\n",
    "# data_types = ['', '_noisy', '_temp_jitter', '_noisy_temp_jitter_offset']\n",
    "filename = 'data_encoding_fix_len_noisy_temp_jitter_offset'\n",
    "infile = open(f\"{data_path_original}/{filename}.pkl\", 'rb')\n",
    "data_original = pickle.load(infile)\n",
    "infile.close()\n",
    "isi_original = return_isi_fix_len(\n",
    "    data_original, max_trials, norm_count=norm_count, norm_time=norm_time)\n",
    "\n",
    "# iterate channel (sensors)\n",
    "for channel, entry in enumerate(isi_list):\n",
    "    # extract single ISIs and their count\n",
    "    isi, count = np.unique(entry[0], return_index=True)\n",
    "    \n",
    "    # only plot if ISIs found in channel\n",
    "    if len(isi) > 0:\n",
    "        if norm_time:\n",
    "            isi = isi/max(isi)\n",
    "        if norm_count:\n",
    "            count = count/max(count)\n",
    "\n",
    "        # create box plots with all classes from paper and single sensor and class for Braille data\n",
    "        figname = f'comparison ISI sensor: {channel}'\n",
    "        plt.figure(figsize=(12, 12))\n",
    "        plt.suptitle(figname)\n",
    "\n",
    "        # compare to original traces\n",
    "        for num, isi_original_sel in enumerate(isi_original):             \n",
    "            # create scatter plot for Braille and original ISIs\n",
    "            plt.subplot(5, 4, num+1)\n",
    "            plt.title(f'{classes_list[braille_letters[num]]}')\n",
    "            plt.scatter(isi_original_sel[0], isi_original_sel[1])\n",
    "            plt.scatter(isi, count)\n",
    "            plt.xlim((0, 1.1))\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(\n",
    "            f'{plot_out}/comparison_all_classes_channel_{channel}_scatter.png', dpi=300)\n",
    "        plt.close()\n",
    "        # plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11\n",
      "3\n",
      "108\n",
      "106\n",
      "67\n",
      "0\n",
      "114\n",
      "5\n",
      "4\n",
      "4\n",
      "111\n",
      "0\n",
      "120\n",
      "37\n",
      "105\n",
      "2\n",
      "11\n",
      "21\n",
      "0\n",
      "6\n",
      "117\n",
      "0\n",
      "14\n",
      "17\n"
     ]
    }
   ],
   "source": [
    "# load ISIs from paper\n",
    "norm_count = True\n",
    "norm_time = True\n",
    "# data_types = ['', '_noisy', '_temp_jitter', '_noisy_temp_jitter_offset']\n",
    "filename = 'data_encoding_fix_len_noisy_temp_jitter_offset'\n",
    "infile = open(f\"{data_path_original}/{filename}.pkl\", 'rb')\n",
    "data_original = pickle.load(infile)\n",
    "infile.close()\n",
    "isi_original = return_isi_fix_len(\n",
    "    data_original, max_trials, norm_count=norm_count, norm_time=norm_time)\n",
    "\n",
    "# iterate channel (sensors)\n",
    "for channel, entry in enumerate(isi_list):\n",
    "    # extract single ISIs and their count\n",
    "    isi, count = np.unique(entry[0], return_index=True)\n",
    "    print(len(isi))\n",
    "    # only plot if ISIs found in channel\n",
    "    if len(isi) > 0:\n",
    "        if norm_time:\n",
    "            isi = isi/max(isi)\n",
    "        if norm_count:\n",
    "            count = count/max(count)\n",
    "\n",
    "        # create box plots with all classes from paper and single sensor and class for Braille data\n",
    "        figname = f'comparison ISI sensor: {channel}'\n",
    "        plt.figure(figsize=(12, 12))\n",
    "        plt.suptitle(figname)\n",
    "\n",
    "        # compare to original traces\n",
    "        for num, isi_original_sel in enumerate(isi_original):             \n",
    "            # create scatter plot for Braille and original ISIs\n",
    "            plt.subplot(5, 4, num+1)\n",
    "            plt.title(f'{classes_list[braille_letters[num]]}')\n",
    "            if norm_time:\n",
    "                plt.bar(isi_original_sel[0], isi_original_sel[1], width=0.01)\n",
    "                plt.bar(isi, count, width=0.01)\n",
    "            else:\n",
    "                plt.bar(isi_original_sel[0], isi_original_sel[1])\n",
    "                plt.bar(isi, count)\n",
    "            plt.xlim((0, 1.1))\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(\n",
    "            f'{plot_out}/comparison_all_classes_channel_{channel}_bar.png', dpi=300)\n",
    "        plt.close()\n",
    "        # plt.show()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a rel=\"license\" href=\"http://creativecommons.org/licenses/by/4.0/\"><img alt=\"Creative Commons License\" style=\"border-width:0\" src=\"https://i.creativecommons.org/l/by/4.0/88x31.png\" /></a><br />This work is licensed under a <a rel=\"license\" href=\"http://creativecommons.org/licenses/by/4.0/\">Creative Commons Attribution 4.0 International License</a>."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
