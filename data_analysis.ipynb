{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualizer\n",
    "### Use this script to visualize the neuron traces according to the paper \"A Generalized Linear Integrate-and-Fire Neural Model Produces Diverse Spiking Behaviors\" by Stefan Mihalas and Ernst Niebur. Further, data was created with a fix length of 1sec (1ms time steps), with noise on the input current, and/or temporal jitter on the time point of the step for dynamic inputs. \n",
    "\n",
    "### The script will also calculate the inter-spike intervalls (ISIs) for a single trial and for all repeating trials, whenever possible. For repeating trials, all ISIs are grouped and further statics represent the outcome of all repetitions per class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import torch\n",
    "import os\n",
    "import progressbar\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from tactile_encoding.utils.utils import create_directory\n",
    "from utils.functions import return_isi_fix_len\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nneuron parameters:\\na: 2.743\\nA1: 0.03712\\nA2: -0.5089\\nb: 11.4\\nG: 47.02\\nk1: 200\\nk2: 20\\nR1: 0\\nR2: 1\\n'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "data_path_braille = './data/braille_mn_output'  # path to output from Braille data\n",
    "data_path_original = './data/original_mn_output'  # path to output from MN paper\n",
    "plot_out = './plots/braille'  # path to save plots\n",
    "create_directory(plot_out)\n",
    "data_types = ['', '_noisy', '_temp_jitter', '_offset', '_noisy_temp_jitter',\n",
    "              '_noisy_offset', '_temp_jitter_offset', '_noisy_temp_jitter_offset']\n",
    "\n",
    "braille_letters = ['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L',\n",
    "                   'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z', 'Space']\n",
    "\n",
    "max_trials = 100\n",
    "\n",
    "classes_list = {\n",
    "    'A': \"Tonic spiking\",\n",
    "    'B': \"Class 1\",\n",
    "    'C': \"Spike frequency adaptation\",\n",
    "    'D': \"Phasic spiking\",\n",
    "    'E': \"Accommodation\",\n",
    "    'F': \"Threshold variability\",\n",
    "    'G': \"Rebound spike\",\n",
    "    'H': \"Class 2\",\n",
    "    'I': \"Integrator\",\n",
    "    'J': \"Input bistability\",\n",
    "    'K': \"Hyperpolarizing spiking\",\n",
    "    'L': \"Hyperpolarizing bursting\",\n",
    "    'M': \"Tonic bursting\",\n",
    "    'N': \"Phasic bursting\",\n",
    "    'O': \"Rebound burst\",\n",
    "    'P': \"Mixed mode\",\n",
    "    'Q': \"Afterpotentials\",\n",
    "    'R': \"Basal bistability\",\n",
    "    'S': \"Preferred frequency\",\n",
    "    'T': \"Spike latency\",\n",
    "}\n",
    "\n",
    "'''\n",
    "neuron parameters:\n",
    "a: 2.743\n",
    "A1: 0.03712\n",
    "A2: -0.5089\n",
    "b: 11.4\n",
    "G: 47.02\n",
    "k1: 200\n",
    "k2: 20\n",
    "R1: 0\n",
    "R2: 1\n",
    "'''\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-processing\n",
    "### extract and concatenate all ISIs for each sensor over all data after training and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load ISIs from paper\n",
    "norm_count = True\n",
    "norm_time = True\n",
    "# for possible datatypes look at the top\n",
    "filename = 'data_encoding_fix_len_noisy_temp_jitter_offset'\n",
    "infile = open(f\"{data_path_original}/{filename}.pkl\", 'rb')\n",
    "data_original = pickle.load(infile)\n",
    "infile.close()\n",
    "isi_original = return_isi_fix_len(\n",
    "    data_original, max_trials, norm_count=norm_count, norm_time=norm_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_names = os.listdir(data_path_braille)\n",
    "file_names = np.sort(file_names)\n",
    "init = True\n",
    "\n",
    "for _, file_name in enumerate(file_names):\n",
    "    [mn_spk, input_current, trial_label] = torch.load(\n",
    "        data_path_braille + '/' + file_name, map_location=torch.device('cpu'))\n",
    "    # convert to numpy\n",
    "    mn_spk = mn_spk.numpy()\n",
    "    input_current = input_current.numpy()\n",
    "    trial_label = trial_label.numpy()\n",
    "\n",
    "    # extract traces from single batch\n",
    "    for batch in range(mn_spk.shape[0]):\n",
    "        isi_list_channel = []\n",
    "\n",
    "        # loop over all channels\n",
    "        for channel in range(mn_spk[batch].shape[-1]):\n",
    "            # calc ISI per channel and append to list\n",
    "            isi_list_channel.append(\n",
    "                np.diff(np.where(mn_spk[batch][:, channel] == 1.0))*1E-2)\n",
    "\n",
    "        if init:\n",
    "            # init at first run\n",
    "            isi_list = isi_list_channel\n",
    "            init = False\n",
    "        else:\n",
    "            # extend with ISIs found in channel per batch\n",
    "            for num, _ in enumerate(isi_list_channel):\n",
    "                # print(len(isi_list[num][0]), len(isi_list_channel[num][0]))\n",
    "                isi_list[num] = np.append(\n",
    "                    isi_list[num], isi_list_channel[num], axis=1)\n",
    "                # print(len(isi_list[num][0]))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compare to paper output"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Per channel over all classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "uncertainty (x, y): [4.72455591 4.17475406]\n",
      "uncertainty (x, y): [0.58361602 0.13815952]\n",
      "uncertainty (x, y): [1.62697843 1.24558042]\n",
      "uncertainty (x, y): [0.77674075 0.47061617]\n",
      "uncertainty (x, y): [0.30205903 0.21230182]\n",
      "uncertainty (x, y): [1.08463873 0.98699511]\n",
      "Only got  0  ISIs.\n",
      "uncertainty (x, y): [1.62697843 1.24558042]\n",
      "uncertainty (x, y): [2.14662172 1.60380898]\n",
      "uncertainty (x, y): [0.44806227 0.20821254]\n",
      "Only got  0  ISIs.\n",
      "Only got  0  ISIs.\n",
      "uncertainty (x, y): [0.42753135 0.31420317]\n",
      "uncertainty (x, y): [1.91236577 1.37667647]\n",
      "Only got  0  ISIs.\n",
      "uncertainty (x, y): [0.44567503 0.25964504]\n",
      "uncertainty (x, y): [0.77089091 0.43685787]\n",
      "uncertainty (x, y): [0.51849612 0.40057013]\n",
      "uncertainty (x, y): [0.31224206 0.21069833]\n",
      "uncertainty (x, y): [0.53528914 0.25689683]\n"
     ]
    }
   ],
   "source": [
    "# linear fit on original data\n",
    "lin_fit_original = []\n",
    "cov_matr_original = []\n",
    "for num, isi_original_sel in enumerate(isi_original):\n",
    "    if len(isi_original_sel[0]) > 0:\n",
    "        # linear fit on original ISIs\n",
    "        [slope, offset], cov_matr = np.polyfit(isi_original_sel[0], isi_original_sel[1], 1, cov='unscaled')\n",
    "        print('uncertainty (x, y):', np.sqrt(np.diag(cov_matr)))\n",
    "        lin_fit_original.append([slope, offset])\n",
    "        cov_matr_original.append(cov_matr)\n",
    "    else:\n",
    "        print('Only got ', len(isi_original_sel[0]), ' ISIs.')\n",
    "        lin_fit_original.append([[], []])\n",
    "        cov_matr_original.append([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[                                                                        ]   0%\n",
      "[=                                                                       ]   1%\n",
      "[=                                                                       ]   2%\n",
      "[==                                                                      ]   3%\n",
      "[===                                                                     ]   5%\n",
      "[====                                                                    ]   6%\n",
      "[=====                                                                   ]   7%\n",
      "[======                                                                  ]   8%\n",
      "[=======                                                                 ]  10%\n",
      "[========                                                                ]  11%\n",
      "[=========                                                               ]  12%\n",
      "[==========                                                              ]  13%\n",
      "[==========                                                              ]  15%\n",
      "[===========                                                             ]  16%\n",
      "[============                                                            ]  17%\n",
      "[=============                                                           ]  19%\n",
      "[==============                                                          ]  20%\n",
      "[==================                                                      ]  25%\n",
      "[===================                                                     ]  26%\n",
      "[====================                                                    ]  27%\n",
      "[=====================                                                   ]  29%\n",
      "[=====================                                                   ]  30%\n",
      "[======================                                                  ]  31%\n",
      "[=======================                                                 ]  32%\n",
      "[========================                                                ]  34%\n",
      "[=========================                                               ]  35%\n",
      "[==========================                                              ]  36%\n",
      "[===========================                                             ]  38%\n",
      "[============================                                            ]  39%\n",
      "[=============================                                           ]  40%\n",
      "[==============================                                          ]  41%\n",
      "[===============================                                         ]  43%\n",
      "[===============================                                         ]  44%\n",
      "[================================                                        ]  45%\n",
      "[====================================                                    ]  50%\n",
      "[====================================                                    ]  50%\n",
      "[=====================================                                   ]  52%\n",
      "[======================================                                  ]  53%\n",
      "[=======================================                                 ]  54%\n",
      "[========================================                                ]  55%\n",
      "[=========================================                               ]  57%\n",
      "[==========================================                              ]  58%\n",
      "[==========================================                              ]  59%\n",
      "[===========================================                             ]  60%\n",
      "[============================================                            ]  62%\n",
      "[=============================================                           ]  63%\n",
      "[==============================================                          ]  64%\n",
      "[===============================================                         ]  65%\n",
      "[================================================                        ]  67%\n",
      "[=================================================                       ]  68%\n",
      "[==================================================                      ]  69%\n",
      "[===================================================                     ]  71%\n",
      "[====================================================                    ]  72%\n",
      "[====================================================                    ]  73%\n",
      "[=====================================================                   ]  74%\n",
      "[=========================================================               ]  79%\n",
      "[=========================================================               ]  79%\n",
      "[==========================================================              ]  81%\n",
      "[===========================================================             ]  82%\n",
      "[============================================================            ]  83%\n",
      "[=============================================================           ]  85%\n",
      "[==============================================================          ]  86%\n",
      "[==================================================================      ]  91%\n",
      "[==================================================================      ]  92%\n",
      "[===================================================================     ]  93%\n",
      "[====================================================================    ]  95%\n",
      "[=====================================================================   ]  96%\n",
      "[======================================================================  ]  97%\n",
      "[======================================================================= ]  98%\n",
      "[========================================================================] 100%\n"
     ]
    }
   ],
   "source": [
    "# load ISIs from paper\n",
    "norm_count = True\n",
    "norm_time = True\n",
    "# data_types = ['', '_noisy', '_temp_jitter', '_noisy_temp_jitter_offset']\n",
    "filename = 'data_encoding_fix_len_noisy_temp_jitter_offset'\n",
    "infile = open(f\"{data_path_original}/{filename}.pkl\", 'rb')\n",
    "data_original = pickle.load(infile)\n",
    "infile.close()\n",
    "isi_original = return_isi_fix_len(\n",
    "    data_original, max_trials, norm_count=norm_count, norm_time=norm_time)\n",
    "error_list = []\n",
    "\n",
    "bar = progressbar.ProgressBar(maxval=len(isi_list)*len(isi_original), \\\n",
    "    widgets=[progressbar.Bar('=', '[', ']'), ' ', progressbar.Percentage()])\n",
    "bar.start()\n",
    "\n",
    "# TODO save error values!\n",
    "# iterate channel (sensors)\n",
    "for channel, entry in enumerate(isi_list):\n",
    "    # extract single ISIs and their count\n",
    "    isi, count = np.unique(entry[0], return_counts=True)\n",
    "\n",
    "    # only plot if ISIs found in channel\n",
    "    if len(isi) > 0:\n",
    "        if norm_time:\n",
    "            isi = isi/max(isi)\n",
    "        if norm_count:\n",
    "            count = count/max(count)\n",
    "\n",
    "        # linear fit on ISIs from channel (sensor)\n",
    "        slope_braille, offset_braille = np.polyfit(isi, count, 1)\n",
    "        # https://numpy.org/doc/stable/reference/generated/numpy.polyfit.html\n",
    "        [slope_braille, offset_braille], cov_matr_braille = np.polyfit(isi, count, 1, cov='unscaled')\n",
    "        # print('uncertainty (x, y): ', np.sqrt(np.diag(cov_matr_braille)))\n",
    "        # create box plots with all classes from paper and single sensor and class for Braille data\n",
    "        figname = f'comparison ISI sensor: {channel}'\n",
    "        plt.figure(figname, figsize=(12, 12))\n",
    "        plt.suptitle(figname)\n",
    "\n",
    "        error = []\n",
    "        # compare to original traces\n",
    "        for num, isi_original_sel in enumerate(isi_original):\n",
    "            # create scatter plot for Braille and original ISIs\n",
    "            plt.subplot(5, 4, num+1)\n",
    "            plt.title(f'{classes_list[braille_letters[num]]}')\n",
    "            if len(isi_original_sel[0]) > 0:\n",
    "                # load linear fit for original\n",
    "                slope_original, offset_original = lin_fit_original[num]\n",
    "                # TODO inlcude check of uncertainty. \n",
    "                # High uncertainty -> bad fit -> bad data representation -> not reliable\n",
    "                # find threshold\n",
    "\n",
    "                # slope is a good first indicator some similarity\n",
    "                if np.sign(slope_original) == np.sign(slope_braille):\n",
    "                    # TODO error = max(error). No sqrt needed\n",
    "                    # calc error between line fits\n",
    "                    line_braille = slope_braille*np.linspace(0.0, 1.0, 10)+offset_braille\n",
    "                    line_original = slope_original*np.linspace(0.0, 1.0, 10)+offset_original\n",
    "                    error_of_fits = np.sqrt(np.mean((line_braille-line_original)**2))\n",
    "                    error.append(error_of_fits)\n",
    "                    # print('error: ', error_of_fits)\n",
    "                else:\n",
    "                    error.append([])\n",
    "                    # print('Skipped error computation.')\n",
    "            \n",
    "                plt.scatter(isi_original_sel[0], isi_original_sel[1], color='tab:blue')\n",
    "                plt.plot(np.linspace(0.0, 1.0, 10), slope_original*np.linspace(0.0, 1.0, 10)+offset_original, color='tab:blue') \n",
    "            else:\n",
    "                error.append([])\n",
    "                plt.text(0.3, 0.5, f'nbr. ISIs = {len(isi_original_sel[0])}')\n",
    "            # https://matplotlib.org/stable/gallery/color/named_colors.html\n",
    "            plt.scatter(isi, count, color='tab:orange')\n",
    "            plt.plot(np.linspace(0.0, 1.0, 10), slope_braille*np.linspace(0.0, 1.0, 10)+offset_braille, color='tab:orange') \n",
    "            plt.xlim((0, 1.1))\n",
    "            plt.ylim((0, 1.1))\n",
    "            if num == 0 or num == 4 or num == 8 or num == 12 or num == 16:\n",
    "                plt.ylabel('Count')\n",
    "            if num > 15:\n",
    "                plt.xlabel('ISI')\n",
    "            bar.update(channel*len(isi_original)+num)\n",
    "\n",
    "        error_list.append(error)\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(\n",
    "            f'{plot_out}/comparison_all_classes_channel_{channel}_scatter.png', dpi=300)\n",
    "        plt.close()\n",
    "    else:\n",
    "        bar.update(channel*len(isi_original)+len(isi_original))\n",
    "bar.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[                                                                        ]   0%\n",
      "[=                                                                       ]   1%\n",
      "[=                                                                       ]   2%\n",
      "[==                                                                      ]   3%\n",
      "[===                                                                     ]   5%\n",
      "[====                                                                    ]   6%\n",
      "[=====                                                                   ]   7%\n",
      "[======                                                                  ]   8%\n",
      "[=======                                                                 ]  10%\n",
      "[========                                                                ]  11%\n",
      "[=========                                                               ]  12%\n",
      "[==========                                                              ]  13%\n",
      "[==========                                                              ]  15%\n",
      "[===========                                                             ]  16%\n",
      "[============                                                            ]  17%\n",
      "[=============                                                           ]  19%\n",
      "[==============                                                          ]  20%\n",
      "[==================                                                      ]  25%\n",
      "[==================                                                      ]  25%\n",
      "[===================                                                     ]  26%\n",
      "[====================                                                    ]  27%\n",
      "[=====================                                                   ]  29%\n",
      "[=====================                                                   ]  30%\n",
      "[======================                                                  ]  31%\n",
      "[=======================                                                 ]  32%\n",
      "[========================                                                ]  34%\n",
      "[=========================                                               ]  35%\n",
      "[==========================                                              ]  36%\n",
      "[===========================                                             ]  38%\n",
      "[============================                                            ]  39%\n",
      "[=============================                                           ]  40%\n",
      "[==============================                                          ]  41%\n",
      "[===============================                                         ]  43%\n",
      "[===============================                                         ]  44%\n",
      "[================================                                        ]  45%\n",
      "[====================================                                    ]  50%\n",
      "[====================================                                    ]  50%\n",
      "[=====================================                                   ]  52%\n",
      "[======================================                                  ]  53%\n",
      "[=======================================                                 ]  54%\n",
      "[========================================                                ]  55%\n",
      "[=========================================                               ]  57%\n",
      "[==========================================                              ]  58%\n",
      "[==========================================                              ]  59%\n",
      "[===========================================                             ]  60%\n",
      "[============================================                            ]  62%\n",
      "[=============================================                           ]  63%\n",
      "[==============================================                          ]  64%\n",
      "[===============================================                         ]  65%\n",
      "[================================================                        ]  67%\n",
      "[=================================================                       ]  68%\n",
      "[==================================================                      ]  69%\n",
      "[===================================================                     ]  71%\n",
      "[====================================================                    ]  72%\n",
      "[====================================================                    ]  73%\n",
      "[=====================================================                   ]  74%\n",
      "[=========================================================               ]  79%\n",
      "[=========================================================               ]  79%\n",
      "[==========================================================              ]  81%\n",
      "[===========================================================             ]  82%\n",
      "[============================================================            ]  83%\n",
      "[=============================================================           ]  85%\n",
      "[==============================================================          ]  86%\n",
      "[==================================================================      ]  91%\n",
      "[==================================================================      ]  92%\n",
      "[===================================================================     ]  93%\n",
      "[====================================================================    ]  95%\n",
      "[=====================================================================   ]  96%\n",
      "[======================================================================  ]  97%\n",
      "[======================================================================= ]  98%\n",
      "[========================================================================] 100%\n"
     ]
    }
   ],
   "source": [
    "# TODO use numpy hist function to select the number of bins!\n",
    "# TODO check how to calculate a probability out of hist -> same dimensions despite the input dimensions\n",
    "# load ISIs from paper\n",
    "norm_count = True\n",
    "norm_time = True\n",
    "# data_types = ['', '_noisy', '_temp_jitter', '_noisy_temp_jitter_offset']\n",
    "filename = 'data_encoding_fix_len_noisy_temp_jitter_offset'\n",
    "infile = open(f\"{data_path_original}/{filename}.pkl\", 'rb')\n",
    "data_original = pickle.load(infile)\n",
    "infile.close()\n",
    "isi_original = return_isi_fix_len(\n",
    "    data_original, max_trials, norm_count=norm_count, norm_time=norm_time)\n",
    "\n",
    "bar = progressbar.ProgressBar(maxval=len(isi_list)*len(isi_original), \\\n",
    "    widgets=[progressbar.Bar('=', '[', ']'), ' ', progressbar.Percentage()])\n",
    "bar.start()\n",
    "\n",
    "# iterate channel (sensors)\n",
    "for channel, entry in enumerate(isi_list):\n",
    "    # TODO try numpy hist\n",
    "    # hist doku: https://numpy.org/doc/stable/reference/generated/numpy.histogram.html\n",
    "    # setting bin size: https://numpy.org/doc/stable/reference/generated/numpy.histogram_bin_edges.html#numpy.histogram_bin_edges\n",
    "    # count_hist, isi_hist = np.histogram(entry[0])\n",
    "    # print(isi_hist, count_hist)\n",
    "    # extract single ISIs and their count\n",
    "    isi, count = np.unique(entry[0], return_counts=True)\n",
    "    # print(isi, count)\n",
    "    # only plot if ISIs found in channel\n",
    "    if len(isi) > 0:\n",
    "        if norm_time:\n",
    "            isi = isi/max(isi)\n",
    "        if norm_count:\n",
    "            count = count/max(count)\n",
    "\n",
    "        # create box plots with all classes from paper and single sensor and class for Braille data\n",
    "        figname = f'comparison ISI sensor: {channel}'\n",
    "        plt.figure(figname, figsize=(12, 12))\n",
    "        plt.suptitle(figname)\n",
    "\n",
    "        # compare to original traces\n",
    "        for num, isi_original_sel in enumerate(isi_original):\n",
    "            # create scatter plot for Braille and original ISIs\n",
    "            plt.subplot(5, 4, num+1)\n",
    "            plt.title(f'{classes_list[braille_letters[num]]}')\n",
    "            if len(isi_original_sel[0]) > 0:\n",
    "                if norm_time:\n",
    "                    plt.bar(isi_original_sel[0], isi_original_sel[1], width=0.01, color='tab:blue')\n",
    "                else:\n",
    "                    plt.bar(isi_original_sel[0], isi_original_sel[1], color='tab:blue')\n",
    "            else:\n",
    "                plt.text(0.3, 0.5, f'nbr. ISIs = {len(isi_original_sel[0])}')\n",
    "            if norm_time:\n",
    "                plt.bar(isi, count, width=0.01, color='tab:orange')\n",
    "            else:\n",
    "                plt.bar(isi, count, color='tab:orange')\n",
    "            plt.xlim((0, 1.1))\n",
    "            if num == 0 or num == 4 or num == 8 or num == 12 or num == 16:\n",
    "                plt.ylabel('Count')\n",
    "            if num > 15:\n",
    "                plt.xlabel('ISI')\n",
    "            bar.update(channel*len(isi_original)+num)\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(\n",
    "            f'{plot_out}/comparison_all_classes_channel_{channel}_bar.png', dpi=300)\n",
    "        plt.close()\n",
    "    else:\n",
    "        bar.update(channel*len(isi_original)+len(isi_original))\n",
    "bar.finish()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Find temporal evolution of predicted classes\n",
    "### Given we have the output spike trains from the trained classifier for MN original classes, we can use a sliding window to determine the evolution of the networks prediction over time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_path_original_classifier = './data/original_classifier'\n",
    "# file_names = os.listdir(data_path_original_classifier)\n",
    "# file_names = np.sort(file_names)\n",
    "# init = True\n",
    "# window_size = 50  # ms\n",
    "\n",
    "# for _, file_name in enumerate(file_names):\n",
    "#     original_classifier_spk = torch.load(\n",
    "#         data_path_braille + '/' + file_name, map_location=torch.device('cpu'))\n",
    "#     # convert to numpy\n",
    "#     original_classifier_spk = original_classifier_spk.numpy()\n",
    "\n",
    "#     # extract traces from single batch\n",
    "#     for batch in range(mn_spk.shape[0]):\n",
    "#         prediction_list_channel = []\n",
    "\n",
    "#         # loop over all channels\n",
    "#         for channel in range(original_classifier_spk[batch].shape[-1]):\n",
    "#             # loop over temporal increments\n",
    "#             for window in range(len(original_classifier_spk[batch][:, channel]), window_size):\n",
    "#                 # calc winning class in time window\n",
    "#                 prediction_list_channel.append(np.sum(original_classifier_spk[batch][window_size*window:window_size*(window+1), channel], axis=0))\n",
    "\n",
    "#         if init:\n",
    "#             # init at first run\n",
    "#             prediction_list = prediction_list_channel\n",
    "#             init = False\n",
    "#         else:\n",
    "#             # extend with ISIs found in channel per batch\n",
    "#             for num, _ in enumerate(prediction_list_channel):\n",
    "#                 # print(len(isi_list[num][0]), len(isi_list_channel[num][0]))\n",
    "#                 prediction_list[num] = np.append(\n",
    "#                     prediction_list[num], prediction_list_channel[num], axis=1)\n",
    "#                 # print(len(isi_list[num][0]))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a rel=\"license\" href=\"http://creativecommons.org/licenses/by/4.0/\"><img alt=\"Creative Commons License\" style=\"border-width:0\" src=\"https://i.creativecommons.org/l/by/4.0/88x31.png\" /></a><br />This work is licensed under a <a rel=\"license\" href=\"http://creativecommons.org/licenses/by/4.0/\">Creative Commons Attribution 4.0 International License</a>."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
