{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualizer\n",
    "### Use this script to visualize the neuron traces according to the paper \"A Generalized Linear Integrate-and-Fire Neural Model Produces Diverse Spiking Behaviors\" by Stefan Mihalas and Ernst Niebur. Further, data was created with a fix length of 1sec (1ms time steps), with noise on the input current, and/or temporal jitter on the time point of the step for dynamic inputs. \n",
    "\n",
    "### The script will also calculate the inter-spike intervalls (ISIs) for a single trial and for all repeating trials, whenever possible. For repeating trials, all ISIs are grouped and further statics represent the outcome of all repetitions per class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import progressbar\n",
    "\n",
    "from tactile_encoding.utils.utils import create_directory\n",
    "from utils.functions import plot_traces_original, plot_isi_original, \\\n",
    "    plot_traces_fix_len, plot_single_isi_fix_len, plot_isi_fix_len\n",
    "from utils.functions import plot_traces_fix_len_param_sweep, \\\n",
    "    plot_single_isi_fix_len_param_sweep, plot_isi_fix_len_param_sweep\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = './plots/original'  # set path to store plots\n",
    "data_path = './data/original_mn_output'\n",
    "create_directory(path)  # create folder if not existent\n",
    "data_types = ['', '_noisy', '_temp_jitter', '_offset', '_noisy_temp_jitter',\n",
    "              '_noisy_offset', '_temp_jitter_offset', '_noisy_temp_jitter_offset']\n",
    "max_trials = 100"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Original data \n",
    "### with noise, temporal jitter, and offset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[========================================================================] 100%\n"
     ]
    }
   ],
   "source": [
    "bar = progressbar.ProgressBar(maxval=len(data_types),\n",
    "                              widgets=[progressbar.Bar('=', '[', ']'), ' ', progressbar.Percentage()])\n",
    "bar.start()\n",
    "\n",
    "for counter, data_type in enumerate(data_types):\n",
    "    # original\n",
    "    if data_type == '':\n",
    "        add_noise = False\n",
    "        temp_jitter = False\n",
    "        add_offset = False\n",
    "    # single\n",
    "    elif data_type == '_noisy':\n",
    "        add_noise = True\n",
    "        temp_jitter = False\n",
    "        add_offset = False\n",
    "    elif data_type == '_temp_jitter':\n",
    "        add_noise = False\n",
    "        temp_jitter = True\n",
    "        add_offset = False\n",
    "    elif data_type == '_offset':\n",
    "        add_noise = False\n",
    "        temp_jitter = False\n",
    "        add_offset = True\n",
    "    # combination of two\n",
    "    elif data_type == '_noisy_temp_jitter':\n",
    "        add_noise = True\n",
    "        temp_jitter = True\n",
    "        add_offset = False\n",
    "    elif data_type == '_noisy_offset':\n",
    "        add_noise = True\n",
    "        temp_jitter = False\n",
    "        add_offset = True\n",
    "    elif data_type == '_temp_jitter_offset':\n",
    "        add_noise = False\n",
    "        temp_jitter = True\n",
    "        add_offset = True\n",
    "    # combination of three\n",
    "    elif data_type == '_noisy_temp_jitter_offset':\n",
    "        add_noise = True\n",
    "        temp_jitter = True\n",
    "        add_offset = True\n",
    "\n",
    "    # load data\n",
    "    filename = 'data_encoding_original' + data_type\n",
    "    infile = open(f\"{data_path}/{filename}.pkl\", 'rb')\n",
    "    data = pickle.load(infile)\n",
    "    infile.close()\n",
    "\n",
    "    # create plots\n",
    "    plot_traces_original(path, data, add_offset=add_offset, add_noise=add_noise,\n",
    "                         temp_jitter=temp_jitter)\n",
    "\n",
    "    plot_isi_original(path, data, add_offset=add_offset, add_noise=add_noise,\n",
    "                      temp_jitter=temp_jitter, norm_count=True, norm_time=True)\n",
    "    bar.update(counter+1)\n",
    "bar.finish()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fix length data (with noise, temporal jitter, and offset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[========================================================================] 100%\n"
     ]
    }
   ],
   "source": [
    "bar = progressbar.ProgressBar(maxval=len(data_types),\n",
    "                              widgets=[progressbar.Bar('=', '[', ']'), ' ', progressbar.Percentage()])\n",
    "bar.start()\n",
    "\n",
    "for _, data_type in enumerate(data_types):\n",
    "    # original\n",
    "    if data_type == '':\n",
    "        add_noise = False\n",
    "        temp_jitter = False\n",
    "        add_offset = False\n",
    "    # single\n",
    "    elif data_type == '_noisy':\n",
    "        add_noise = True\n",
    "        temp_jitter = False\n",
    "        add_offset = False\n",
    "    elif data_type == '_temp_jitter':\n",
    "        add_noise = False\n",
    "        temp_jitter = True\n",
    "        add_offset = False\n",
    "    elif data_type == '_offset':\n",
    "        add_noise = False\n",
    "        temp_jitter = False\n",
    "        add_offset = True\n",
    "    # combination of two\n",
    "    elif data_type == '_noisy_temp_jitter':\n",
    "        add_noise = True\n",
    "        temp_jitter = True\n",
    "        add_offset = False\n",
    "    elif data_type == '_noisy_offset':\n",
    "        add_noise = True\n",
    "        temp_jitter = False\n",
    "        add_offset = True\n",
    "    elif data_type == '_temp_jitter_offset':\n",
    "        add_noise = False\n",
    "        temp_jitter = True\n",
    "        add_offset = True\n",
    "    # combination of three\n",
    "    elif data_type == '_noisy_temp_jitter_offset':\n",
    "        add_noise = True\n",
    "        temp_jitter = True\n",
    "        add_offset = True\n",
    "\n",
    "    filename = 'data_encoding_fix_len' + data_type\n",
    "    infile = open(f\"{data_path}/{filename}.pkl\", 'rb')\n",
    "    data = pickle.load(infile)\n",
    "    infile.close()\n",
    "    # create plots\n",
    "    plot_traces_fix_len(path, data, max_trials=max_trials,\n",
    "                        add_offset=add_offset, add_noise=add_noise, temp_jitter=temp_jitter)\n",
    "\n",
    "    plot_single_isi_fix_len(path, data, max_trials=max_trials,\n",
    "                            add_offset=add_offset, add_noise=add_noise, temp_jitter=temp_jitter, norm_count=True, norm_time=True)\n",
    "\n",
    "    plot_isi_fix_len(path, data, max_trials=max_trials,\n",
    "                     add_offset=add_offset, add_noise=add_noise, temp_jitter=temp_jitter, norm_count=True, norm_time=True)\n",
    "    bar.update(counter+1)\n",
    "bar.finish()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parameter sweep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[                                                                        ]   0%\r"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './data/original_mn_output/data_encoding_fix_len_0.1_noise_10_jitter_0.1_offset.pkl'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 18\u001b[0m\n\u001b[1;32m     16\u001b[0m data_type \u001b[39m=\u001b[39m \u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00mnoise\u001b[39m}\u001b[39;00m\u001b[39m_noise_\u001b[39m\u001b[39m{\u001b[39;00mjitter\u001b[39m}\u001b[39;00m\u001b[39m_jitter_\u001b[39m\u001b[39m{\u001b[39;00moffset\u001b[39m}\u001b[39;00m\u001b[39m_offset\u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m     17\u001b[0m filename \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mdata_encoding_fix_len_\u001b[39m\u001b[39m'\u001b[39m \u001b[39m+\u001b[39m data_type\n\u001b[0;32m---> 18\u001b[0m infile \u001b[39m=\u001b[39m \u001b[39mopen\u001b[39;49m(\u001b[39mf\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m{\u001b[39;49;00mdata_path\u001b[39m}\u001b[39;49;00m\u001b[39m/\u001b[39;49m\u001b[39m{\u001b[39;49;00mfilename\u001b[39m}\u001b[39;49;00m\u001b[39m.pkl\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m'\u001b[39;49m\u001b[39mrb\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[1;32m     19\u001b[0m data \u001b[39m=\u001b[39m pickle\u001b[39m.\u001b[39mload(infile)\n\u001b[1;32m     20\u001b[0m infile\u001b[39m.\u001b[39mclose()\n",
      "File \u001b[0;32m~/miniconda3/envs/learning/lib/python3.11/site-packages/IPython/core/interactiveshell.py:282\u001b[0m, in \u001b[0;36m_modified_open\u001b[0;34m(file, *args, **kwargs)\u001b[0m\n\u001b[1;32m    275\u001b[0m \u001b[39mif\u001b[39;00m file \u001b[39min\u001b[39;00m {\u001b[39m0\u001b[39m, \u001b[39m1\u001b[39m, \u001b[39m2\u001b[39m}:\n\u001b[1;32m    276\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    277\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mIPython won\u001b[39m\u001b[39m'\u001b[39m\u001b[39mt let you open fd=\u001b[39m\u001b[39m{\u001b[39;00mfile\u001b[39m}\u001b[39;00m\u001b[39m by default \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    278\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    279\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39myou can use builtins\u001b[39m\u001b[39m'\u001b[39m\u001b[39m open.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    280\u001b[0m     )\n\u001b[0;32m--> 282\u001b[0m \u001b[39mreturn\u001b[39;00m io_open(file, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './data/original_mn_output/data_encoding_fix_len_0.1_noise_10_jitter_0.1_offset.pkl'"
     ]
    }
   ],
   "source": [
    "noise_levels = [0.0, 0.1, 0.2, 0.5, 1.0, 2, 5, 10]\n",
    "offset_levels = [0.0, 0.1, 0.2, 0.5, 1.0, 2, 5, 10]\n",
    "jitter = 10\n",
    "\n",
    "add_noise = True\n",
    "temp_jitter = True\n",
    "add_offset = True\n",
    "\n",
    "bar = progressbar.ProgressBar(maxval=len(noise_levels)*len(offset_levels),\n",
    "                            widgets=[progressbar.Bar('=', '[', ']'), ' ', progressbar.Percentage()])\n",
    "bar.start()\n",
    "\n",
    "for offset_counter, offset in enumerate(noise_levels):\n",
    "    for noise_counter, noise in enumerate(noise_levels):\n",
    "        # load data\n",
    "        data_type = f'{noise}_noise_{jitter}_jitter_{offset}_offset'\n",
    "        filename = 'data_encoding_fix_len_' + data_type\n",
    "        infile = open(f\"{data_path}/{filename}.pkl\", 'rb')\n",
    "        data = pickle.load(infile)\n",
    "        infile.close()\n",
    "\n",
    "        # create plots\n",
    "        # TODO include param values in figure name!!!\n",
    "        plot_traces_fix_len_param_sweep(path, data, max_trials=max_trials, offset=offset, noise=noise, jitter=jitter,\n",
    "                            add_offset=add_offset, add_noise=add_noise, temp_jitter=temp_jitter)\n",
    "\n",
    "        plot_single_isi_fix_len_param_sweep(path, data, max_trials=max_trials, offset=offset, noise=noise, jitter=jitter,\n",
    "                                add_offset=add_offset, add_noise=add_noise, temp_jitter=temp_jitter, norm_count=True, norm_time=True)\n",
    "\n",
    "        plot_isi_fix_len_param_sweep(path, data, max_trials=max_trials, offset=offset, noise=noise, jitter=jitter,\n",
    "                        add_offset=add_offset, add_noise=add_noise, temp_jitter=temp_jitter, norm_count=True, norm_time=True)\n",
    "        \n",
    "        bar.update(offset_counter*len(noise_levels)+noise_counter)\n",
    "bar.finish()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a rel=\"license\" href=\"http://creativecommons.org/licenses/by/4.0/\"><img alt=\"Creative Commons License\" style=\"border-width:0\" src=\"https://i.creativecommons.org/l/by/4.0/88x31.png\" /></a><br />This work is licensed under a <a rel=\"license\" href=\"http://creativecommons.org/licenses/by/4.0/\">Creative Commons Attribution 4.0 International License</a>."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
